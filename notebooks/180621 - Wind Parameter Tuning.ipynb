{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models import KMeansPartitioner\n",
    "from sklearn import preprocessing\n",
    "from pyFTS.partitioners import Grid, Util as pUtil\n",
    "from pyFTS.models import hofts\n",
    "\n",
    "from models import sthofts\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import dispy\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/petroniocandido/pyFTS\n",
      "  Cloning https://github.com/petroniocandido/pyFTS to /private/var/folders/13/t7d8w0nd0hv6w9_p2rntvym00000gr/T/pip-req-build-qwajmn_5\n",
      "Building wheels for collected packages: pyFTS\n",
      "  Running setup.py bdist_wheel for pyFTS ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /private/var/folders/13/t7d8w0nd0hv6w9_p2rntvym00000gr/T/pip-ephem-wheel-cache-___riyly/wheels/84/d7/1e/a333c7128f25b347640740859808db094c4478e98663cd2297\n",
      "Successfully built pyFTS\n",
      "Installing collected packages: pyFTS\n",
      "  Found existing installation: pyFTS 1.2.2\n",
      "    Uninstalling pyFTS-1.2.2:\n",
      "      Successfully uninstalled pyFTS-1.2.2\n",
      "Successfully installed pyFTS-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/petroniocandido/pyFTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    mindf = df.min()\n",
    "    maxdf = df.max()\n",
    "    return (df-mindf)/(maxdf-mindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, df_clean, df_residual, interval):\n",
    "    sample_df = df.loc[interval]\n",
    "    residual_sample_df = df_residual.loc[interval]\n",
    "    clean_sample_df = df_clean.loc[interval]\n",
    "\n",
    "    norm_residual_sample_df = normalize(residual_sample_df)\n",
    "    norm_clean_sample_df = normalize(clean_sample_df)\n",
    "\n",
    "\n",
    "    week = (sample_df.index.day - 1) // 7 + 1\n",
    "\n",
    "    # PARA OS TESTES:\n",
    "    # 2 SEMANAS PARA TREINAMENTO\n",
    "    train_df = sample_df.loc[week <= 2]\n",
    "    train_residual_df = norm_residual_sample_df.loc[week <= 2]\n",
    "    train_clean_df = norm_clean_sample_df.loc[week <= 2]\n",
    "\n",
    "    # 1 SEMANA PARA VALIDACAO\n",
    "    validation_df = sample_df.loc[week == 3]\n",
    "    validation_residual_df = norm_residual_sample_df.loc[week == 3]\n",
    "    validation_clean_df = norm_clean_sample_df.loc[week == 3]\n",
    "\n",
    "    # 1 SEMANA PARA TESTES\n",
    "    test_df = sample_df.loc[week > 3]\n",
    "    test_residual_df = norm_residual_sample_df.loc[week > 3]\n",
    "    test_clean_df = norm_clean_sample_df.loc[week > 3]\n",
    "    \n",
    "    return (train_df, train_clean_df, train_residual_df, validation_df, validation_clean_df, validation_residual_df, test_df, test_clean_df, test_residual_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"df_wind_speed.pkl\")\n",
    "df_ssa_clean = pd.read_pickle(\"df_wind_speed_ssa_clean.pkl\")\n",
    "df_ssa_residual = pd.read_pickle(\"df_wind_speed_ssa_residual.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entire data split by season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = ((df.index >= '2017-05') & (df.index <= '2017-06'))\n",
    "(train_df, train_clean_df, train_residual_df, \n",
    " validation_df, validation_clean_df, validation_residual_df, \n",
    " test_df, test_clean_df, test_residual_df) = split_data(df, df_ssa_clean, df_ssa_residual, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_station = 'WTG01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neighbor stations with residual correlation greater than .90\n",
    "neighbor_stations_90 = ['WTG01','WTG02','WTG03','WTG05','WTG06']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_sarima_model(train, validation, arima_order, sarima_order):\n",
    "    \n",
    "    whole_data = train.append(validation)\n",
    "    test_data = validation\n",
    "    \n",
    "    training_mod = SARIMAX(whole_data.values, order=arima_order, seasonal_order=sarima_order, disp=True)\n",
    "    training_res = training_mod.fit()\n",
    "    \n",
    "    mod = SARIMAX(whole_data.values, order=arima_order, seasonal_order=sarima_order)\n",
    "    res = mod.filter(training_res.params)\n",
    "    \n",
    "    insample = res.predict()\n",
    "    wlen = len(whole_data)\n",
    "    tlen = len(test_data)\n",
    "\n",
    "    predictions = insample[wlen-tlen:]    \n",
    "    # calculate out of sample error\n",
    "    error = math.sqrt(mean_squared_error(validation, predictions))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "import sys\n",
    "def evaluate_sarima_models(test_name, train_df, validation_df, parameters_list, period_length):\n",
    "\n",
    "    sarima_results = pd.DataFrame(columns=['Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "    for param in parameters_list:\n",
    "        arima_order = (param[0],param[1],param[2])\n",
    "        sarima_order = (param[3],param[4],param[5],period_length)\n",
    "        print('Testing SARIMA%s %s ' % (str(arima_order),str(sarima_order)))\n",
    "        try:\n",
    "            rmse = evaluate_sarima_model(train_df, validation_df, arima_order, sarima_order)\n",
    "            if rmse < best_score:\n",
    "                best_score, best_cfg = rmse, param\n",
    "\n",
    "            res = {'Order' : str(param) ,'RMSE' : rmse}\n",
    "            print('SARIMA%s %s RMSE=%.3f' % (str(arima_order),str(sarima_order),rmse))\n",
    "            sarima_results = sarima_results.append(res, ignore_index=True)\n",
    "            sarima_results.to_csv(test_name+\".csv\")\n",
    "        except:\n",
    "            print(sys.exc_info())\n",
    "            print('Invalid model%s %s ' % (str(arima_order),str(sarima_order)))\n",
    "            continue\n",
    "    print('Best SARIMA%s RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SARIMA(0, 0, 0) (0, 0, 0, 144) \n",
      "(<class 'ValueError'>, ValueError('Number of states in statespace model must be a positive number.',), <traceback object at 0x112f31948>)\n",
      "Invalid model(0, 0, 0) (0, 0, 0, 144) \n",
      "Testing SARIMA(0, 0, 0) (0, 0, 1, 144) \n",
      "SARIMA(0, 0, 0) (0, 0, 1, 144) RMSE=0.364\n",
      "Testing SARIMA(0, 0, 0) (0, 1, 0, 144) \n",
      "(<class 'ValueError'>, ValueError('could not broadcast input array from shape (0,0) into shape (144,144)',), <traceback object at 0x112f0ac08>)\n",
      "Invalid model(0, 0, 0) (0, 1, 0, 144) \n",
      "Testing SARIMA(0, 0, 0) (0, 1, 1, 144) \n"
     ]
    }
   ],
   "source": [
    "p_values = [0,1,2]\n",
    "d_values = [0,1]\n",
    "q_values = [0,1,2]\n",
    "P_values = [0,1]\n",
    "D_Values = [0,1]\n",
    "Q_Values = [0,1]\n",
    "\n",
    "parameters = product(p_values, d_values, q_values, P_values, D_Values, Q_Values)\n",
    "parameters_list = list(parameters)\n",
    "period_length = 144 #de 00:00 as 23:50\n",
    "evaluate_sarima_models(\"wind_sarima-1-clean\",train_clean_df[target_station], validation_clean_df[target_station], parameters_list, period_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_sarima_models(\"wind_sarima-1-residual\",train_residual_df[target_station], validation_residual_df[target_station], parameters_list, period_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Autorregressive - VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import VAR, DynamicVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_VAR_models(test_name, train, validation,target, maxlags_list):\n",
    "    var_results = pd.DataFrame(columns=['Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    \n",
    "    for lgs in maxlags_list:\n",
    "        model = VAR(train)\n",
    "        results = model.fit(maxlags=lgs, ic='aic')\n",
    "        \n",
    "        order = results.k_ar\n",
    "        forecast = []\n",
    "\n",
    "        for i in range(len(validation)-order) :\n",
    "            forecast.extend(results.forecast(validation.values[i:i+order],1))\n",
    "\n",
    "        forecast_df = pd.DataFrame(columns=validation.columns, data=forecast)\n",
    "        rmse = math.sqrt(mean_squared_error(forecast_df[target].values, validation[target].iloc[order:]))\n",
    "\n",
    "        if rmse < best_score:\n",
    "            best_score, best_cfg = rmse, order\n",
    "\n",
    "        res = {'Order' : str(order) ,'RMSE' : rmse}\n",
    "        print('VAR (%s)  RMSE=%.3f' % (str(order),rmse))\n",
    "        var_results = var_results.append(res, ignore_index=True)\n",
    "        var_results.to_csv(test_name+\".csv\")\n",
    "        \n",
    "    print('Best VAR(%s) RMSE=%.3f' % (best_cfg, best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR (1)  RMSE=0.012\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(20) RMSE=0.002\n",
      "VAR (1)  RMSE=0.089\n",
      "VAR (2)  RMSE=0.087\n",
      "VAR (4)  RMSE=0.085\n",
      "VAR (6)  RMSE=0.085\n",
      "VAR (8)  RMSE=0.084\n",
      "VAR (10)  RMSE=0.084\n",
      "VAR (20)  RMSE=0.083\n",
      "VAR (26)  RMSE=0.084\n",
      "Best VAR(20) RMSE=0.083\n"
     ]
    }
   ],
   "source": [
    "maxlags_list = [1,2,4,6,8,10,20,40]\n",
    "evaluate_VAR_models(\"wind_var_clean\", train_clean_df[neighbor_stations_90], validation_clean_df[neighbor_stations_90],target_station, maxlags_list)\n",
    "evaluate_VAR_models(\"wind_var_residual\", train_residual_df[neighbor_stations_90], validation_residual_df[neighbor_stations_90],target_station, maxlags_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Order Fuzzy Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/petroniocandido/pyFTS\n",
      "  Cloning https://github.com/petroniocandido/pyFTS to /private/var/folders/13/t7d8w0nd0hv6w9_p2rntvym00000gr/T/pip-req-build-4e3y8zbt\n",
      "Building wheels for collected packages: pyFTS\n",
      "  Running setup.py bdist_wheel for pyFTS ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /private/var/folders/13/t7d8w0nd0hv6w9_p2rntvym00000gr/T/pip-ephem-wheel-cache-_3kkffbn/wheels/84/d7/1e/a333c7128f25b347640740859808db094c4478e98663cd2297\n",
      "Successfully built pyFTS\n",
      "Installing collected packages: pyFTS\n",
      "  Found existing installation: pyFTS 1.2.2\n",
      "    Uninstalling pyFTS-1.2.2:\n",
      "      Successfully uninstalled pyFTS-1.2.2\n",
      "Successfully installed pyFTS-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/petroniocandido/pyFTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFTS.models.multivariate import common, variable, mvfts\n",
    "from pyFTS.models.seasonal import partitioner as seasonal\n",
    "from pyFTS.models.seasonal.common import DateTime\n",
    "from pyFTS.partitioners import Grid, Entropy, Util as pUtil\n",
    "from pyFTS.models.multivariate import common, variable, mvfts\n",
    "from pyFTS.models import hofts\n",
    "from pyFTS.common import Transformations\n",
    "tdiff = Transformations.Differential(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hofts_models(test_name, train, validation, partitioners_list, order_list, partitions_list):\n",
    "    \n",
    "    hofts_results = pd.DataFrame(columns=['Partitioner','Partitions','Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "\n",
    "    for _partitioner in partitioners_list:\n",
    "        for _order in order_list:\n",
    "            for npartitions in partitions_list:\n",
    "                fuzzy_sets = _partitioner(data=train.values, npart=npartitions)\n",
    "                model_simple_hofts = hofts.HighOrderFTS()\n",
    "\n",
    "                #model_simple_hofts.append_transformation(Transformations.Differential(1))\n",
    "                model_simple_hofts.fit(train.values, order=_order, partitioner=fuzzy_sets)\n",
    "\n",
    "                forecast = model_simple_hofts.predict(validation.values)\n",
    "\n",
    "                rmse = math.sqrt(mean_squared_error(validation.iloc[_order:], forecast[:-1]))\n",
    "\n",
    "                if rmse < best_score:\n",
    "                    best_score, best_cfg = rmse, (_order,npartitions,_partitioner)\n",
    "\n",
    "                res = {'Partitioner':str(_partitioner), 'Partitions':npartitions, 'Order' : str(_order) ,'RMSE' : rmse}\n",
    "                print('HOFTS %s - %s - %s  RMSE=%.3f' % (str(_partitioner), npartitions, str(_order),rmse))\n",
    "                hofts_results = hofts_results.append(res, ignore_index=True)\n",
    "                hofts_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best HOFTS(%s) RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 1  RMSE=0.077\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 1  RMSE=0.048\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 1  RMSE=0.037\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 1  RMSE=0.029\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 1  RMSE=0.026\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 1  RMSE=0.021\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 1  RMSE=0.022\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 1  RMSE=0.020\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 1  RMSE=0.018\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 2  RMSE=0.074\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 2  RMSE=0.041\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 2  RMSE=0.031\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 2  RMSE=0.023\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 2  RMSE=0.018\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 2  RMSE=0.017\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 2  RMSE=0.016\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 2  RMSE=0.013\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 2  RMSE=0.012\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 3  RMSE=0.073\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 3  RMSE=0.036\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 3  RMSE=0.027\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 3  RMSE=0.020\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 3  RMSE=0.015\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 3  RMSE=0.015\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 3  RMSE=0.013\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 3  RMSE=0.011\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 3  RMSE=0.011\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 4  RMSE=0.073\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 4  RMSE=0.032\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 4  RMSE=0.024\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 4  RMSE=0.016\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 4  RMSE=0.013\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 4  RMSE=0.014\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 4  RMSE=0.012\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 4  RMSE=0.011\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 4  RMSE=0.011\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 1  RMSE=0.076\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 1  RMSE=0.049\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 1  RMSE=0.032\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 1  RMSE=0.032\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 1  RMSE=0.031\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 1  RMSE=0.021\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 1  RMSE=0.021\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 1  RMSE=0.021\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 1  RMSE=0.021\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 2  RMSE=0.075\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 2  RMSE=0.049\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 2  RMSE=0.031\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 2  RMSE=0.030\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 2  RMSE=0.030\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 2  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 2  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 2  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 2  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 3  RMSE=0.075\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 3  RMSE=0.048\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 3  RMSE=0.030\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 3  RMSE=0.030\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 3  RMSE=0.030\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 3  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 3  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 3  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 3  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 4  RMSE=0.075\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 4  RMSE=0.048\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 4  RMSE=0.030\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 4  RMSE=0.029\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 4  RMSE=0.030\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 4  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 4  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 4  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 4  RMSE=0.019\n",
      "Best HOFTS((3, 80, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)) RMSE=0.011\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 1  RMSE=0.094\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 1  RMSE=0.093\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 1  RMSE=0.095\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 1  RMSE=0.094\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 1  RMSE=0.096\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 1  RMSE=0.096\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 1  RMSE=0.098\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 1  RMSE=0.096\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 1  RMSE=0.096\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 2  RMSE=0.096\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 2  RMSE=0.100\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 2  RMSE=0.100\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 2  RMSE=0.099\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 2  RMSE=0.101\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 2  RMSE=0.100\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 2  RMSE=0.102\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 2  RMSE=0.101\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 2  RMSE=0.103\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 3  RMSE=0.094\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 3  RMSE=0.100\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 3  RMSE=0.103\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 3  RMSE=0.103\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 3  RMSE=0.107\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 3  RMSE=0.109\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 3  RMSE=0.112\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 3  RMSE=0.112\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 3  RMSE=0.114\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 4  RMSE=0.095\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 4  RMSE=0.101\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 4  RMSE=0.105\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 4  RMSE=0.108\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 4  RMSE=0.111\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 4  RMSE=0.113\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 4  RMSE=0.114\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 4  RMSE=0.114\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 4  RMSE=0.114\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 1  RMSE=0.092\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 1  RMSE=0.092\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 1  RMSE=0.092\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 1  RMSE=0.092\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 1  RMSE=0.092\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 1  RMSE=0.091\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 1  RMSE=0.091\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 1  RMSE=0.091\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 1  RMSE=0.091\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 2  RMSE=0.092\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 2  RMSE=0.091\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 2  RMSE=0.091\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 2  RMSE=0.092\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 2  RMSE=0.093\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 2  RMSE=0.099\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 2  RMSE=0.102\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 2  RMSE=0.102\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 2  RMSE=0.102\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 3  RMSE=0.092\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 3  RMSE=0.093\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 3  RMSE=0.101\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 3  RMSE=0.104\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 3  RMSE=0.105\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 3  RMSE=0.110\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 3  RMSE=0.110\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 3  RMSE=0.110\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 3  RMSE=0.110\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 4  RMSE=0.090\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 4  RMSE=0.099\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 4  RMSE=0.109\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 4  RMSE=0.109\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 4  RMSE=0.109\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 4  RMSE=0.111\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 4  RMSE=0.111\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 4  RMSE=0.111\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 4  RMSE=0.111\n",
      "Best HOFTS((4, 10, <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'>)) RMSE=0.090\n"
     ]
    }
   ],
   "source": [
    "partitioners_list = [Grid.GridPartitioner, Entropy.EntropyPartitioner]\n",
    "order_list = np.arange(1,5)\n",
    "partitions_list = np.arange(10,100,10)\n",
    "\n",
    "evaluate_hofts_models(\"hofts_wind_clean\", train_clean_df[target_station], validation_clean_df[target_station], partitioners_list, order_list, partitions_list)\n",
    "evaluate_hofts_models(\"hofts_wind_residual\", train_residual_df[target_station], validation_residual_df[target_station], partitioners_list, order_list, partitions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Order NonStationary FTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFTS.models.nonstationary import cvfts\n",
    "from pyFTS.models.nonstationary import partitioners as nspartitioners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pyFTS.models.nonstationary.honsfts' from '/Users/cseveriano/anaconda3/lib/python3.6/site-packages/pyFTS/models/nonstationary/honsfts.py'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(honsfts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_honsfts_models(test_name, train, validation, partitioners_list, order_list, partitions_list):\n",
    "    \n",
    "    honsfts_results = pd.DataFrame(columns=['Partitioner','Partitions','Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "\n",
    "    for _partitioner in partitioners_list:\n",
    "        for _order in order_list:\n",
    "            for npartitions in partitions_list:\n",
    "                    fuzzy_sets =  nspartitioners.PolynomialNonStationaryPartitioner(data=train.values, part=_partitioner(data=train.values, npart=npartitions), degree=2)\n",
    "                    \n",
    "                    model_cvfts = cvfts.ConditionalVarianceFTS()\n",
    "                    \n",
    "                    model_cvfts.fit(train.values, order=_order, parameters=1, partitioner=fuzzy_sets)\n",
    "\n",
    "                    forecast = model_cvfts.predict(validation.values)\n",
    "\n",
    "                    rmse = math.sqrt(mean_squared_error(validation.iloc[_order:], forecast[:-1]))\n",
    "                    params = (_order,npartitions,_partitioner)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, params\n",
    "\n",
    "                    res = {'Partitioner':str(_partitioner), 'Partitions':npartitions, 'Order' : str(_order) ,'RMSE' : rmse}\n",
    "                    print('CVFTS %s  RMSE=%.3f' % (params,rmse))\n",
    "                    honsfts_results = honsfts_results.append(res, ignore_index=True)\n",
    "                    honsfts_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best CVFTS(%s) RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cseveriano/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVFTS (1, 80, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.096\n",
      "CVFTS (1, 90, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.096\n",
      "CVFTS (1, 100, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.096\n",
      "CVFTS (1, 80, <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'>)  RMSE=0.091\n",
      "CVFTS (1, 90, <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'>)  RMSE=0.091\n",
      "CVFTS (1, 100, <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'>)  RMSE=0.090\n",
      "Best CVFTS((1, 100, <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'>)) RMSE=0.090\n"
     ]
    }
   ],
   "source": [
    "partitioners_list = [Grid.GridPartitioner, Entropy.EntropyPartitioner]\n",
    "order_list = np.arange(1,2)\n",
    "partitions_list = np.arange(80,110,10)\n",
    "\n",
    "evaluate_honsfts_models(\"cvfts_wind_clean\", train_clean_df[target_station], validation_clean_df[target_station], partitioners_list, order_list, partitions_list)\n",
    "evaluate_honsfts_models(\"cvfts_wind_residual\", train_residual_df[target_station], validation_residual_df[target_station], partitioners_list, order_list, partitions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-term Memory LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-term Memory LSTM - Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multivariate_lstm_models(test_name, train_df, validation_df, neurons_list, order_list, epochs_list):\n",
    "    \n",
    "    lstm_results = pd.DataFrame(columns=['Neurons','Order','Epochs','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    \n",
    "    nfeat = len(train_df.columns)\n",
    "    nsteps = 1\n",
    "    \n",
    "    for _neurons in neurons_list:\n",
    "        for _order in order_list:\n",
    "            for epochs in epochs_list:\n",
    "                    \n",
    "                    nobs = nfeat * _order\n",
    "                    \n",
    "                    train_reshaped_df = series_to_supervised(train_df, n_in=_order, n_out=nsteps)\n",
    "                    train_X, train_Y = train_reshaped_df.iloc[:,:nobs].values, train_reshaped_df.iloc[:,-nfeat].values\n",
    "                    train_X = train_X.reshape((train_X.shape[0], _order, nfeat))                    \n",
    "                    \n",
    "                    val_reshaped_df = series_to_supervised(validation_df, n_in=_order, n_out=nsteps)\n",
    "                    validation_X, validation_Y = val_reshaped_df.iloc[:,:nobs].values, val_reshaped_df.iloc[:,-nfeat].values\n",
    "                    validation_X = validation_X.reshape((validation_X.shape[0], _order, nfeat))\n",
    "                    \n",
    "                    # design network\n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(_neurons, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "                    model.add(Dense(1))\n",
    "                    model.compile(loss='mae', optimizer='adam')\n",
    "                    \n",
    "                    # fit network\n",
    "                    history = model.fit(train_X, train_Y, epochs=epochs, batch_size=72, verbose=False, shuffle=False)\n",
    "                    forecast = model.predict(validation_X)\n",
    "                    \n",
    "                    rmse = math.sqrt(mean_squared_error(validation_Y, forecast))\n",
    "                    params = (_neurons, _order,epochs)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, params\n",
    "\n",
    "                    res = {'Neurons':_neurons, 'Order':_order, 'Epochs' : epochs ,'RMSE' : rmse}\n",
    "                    print('LSTM %s  RMSE=%.3f' % (params,rmse))\n",
    "                    lstm_results = lstm_results.append(res, ignore_index=True)\n",
    "                    lstm_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best LSTM(%s) RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM (10, 1, 100)  RMSE=0.021\n",
      "LSTM (10, 2, 100)  RMSE=0.026\n",
      "LSTM (10, 3, 100)  RMSE=0.029\n",
      "LSTM (10, 4, 100)  RMSE=0.030\n",
      "LSTM (20, 1, 100)  RMSE=0.015\n",
      "LSTM (20, 2, 100)  RMSE=0.026\n",
      "LSTM (20, 3, 100)  RMSE=0.029\n",
      "LSTM (20, 4, 100)  RMSE=0.030\n",
      "LSTM (30, 1, 100)  RMSE=0.015\n",
      "LSTM (30, 2, 100)  RMSE=0.016\n",
      "LSTM (30, 3, 100)  RMSE=0.029\n",
      "LSTM (30, 4, 100)  RMSE=0.017\n",
      "LSTM (40, 1, 100)  RMSE=0.019\n",
      "LSTM (40, 2, 100)  RMSE=0.019\n",
      "LSTM (40, 3, 100)  RMSE=0.013\n",
      "LSTM (40, 4, 100)  RMSE=0.011\n",
      "LSTM (50, 1, 100)  RMSE=0.016\n",
      "LSTM (50, 2, 100)  RMSE=0.017\n",
      "LSTM (50, 3, 100)  RMSE=0.012\n",
      "LSTM (50, 4, 100)  RMSE=0.011\n",
      "LSTM (60, 1, 100)  RMSE=0.015\n",
      "LSTM (60, 2, 100)  RMSE=0.019\n",
      "LSTM (60, 3, 100)  RMSE=0.017\n",
      "LSTM (60, 4, 100)  RMSE=0.011\n",
      "LSTM (70, 1, 100)  RMSE=0.014\n",
      "LSTM (70, 2, 100)  RMSE=0.018\n",
      "LSTM (70, 3, 100)  RMSE=0.013\n",
      "LSTM (70, 4, 100)  RMSE=0.010\n",
      "LSTM (80, 1, 100)  RMSE=0.016\n",
      "LSTM (80, 2, 100)  RMSE=0.015\n",
      "LSTM (80, 3, 100)  RMSE=0.016\n",
      "LSTM (80, 4, 100)  RMSE=0.011\n",
      "LSTM (90, 1, 100)  RMSE=0.016\n",
      "LSTM (90, 2, 100)  RMSE=0.017\n",
      "LSTM (90, 3, 100)  RMSE=0.011\n",
      "LSTM (90, 4, 100)  RMSE=0.009\n",
      "LSTM (100, 1, 100)  RMSE=0.014\n",
      "LSTM (100, 2, 100)  RMSE=0.014\n",
      "LSTM (100, 3, 100)  RMSE=0.011\n",
      "LSTM (100, 4, 100)  RMSE=0.009\n",
      "Best LSTM((100, 4, 100)) RMSE=0.009\n",
      "LSTM (10, 1, 100)  RMSE=0.089\n",
      "LSTM (10, 2, 100)  RMSE=0.087\n",
      "LSTM (10, 3, 100)  RMSE=0.084\n",
      "LSTM (10, 4, 100)  RMSE=0.084\n",
      "LSTM (20, 1, 100)  RMSE=0.089\n",
      "LSTM (20, 2, 100)  RMSE=0.087\n",
      "LSTM (20, 3, 100)  RMSE=0.084\n",
      "LSTM (20, 4, 100)  RMSE=0.084\n",
      "LSTM (30, 1, 100)  RMSE=0.089\n",
      "LSTM (30, 2, 100)  RMSE=0.087\n",
      "LSTM (30, 3, 100)  RMSE=0.085\n",
      "LSTM (30, 4, 100)  RMSE=0.084\n",
      "LSTM (40, 1, 100)  RMSE=0.089\n",
      "LSTM (40, 2, 100)  RMSE=0.087\n",
      "LSTM (40, 3, 100)  RMSE=0.084\n",
      "LSTM (40, 4, 100)  RMSE=0.084\n",
      "LSTM (50, 1, 100)  RMSE=0.089\n",
      "LSTM (50, 2, 100)  RMSE=0.087\n",
      "LSTM (50, 3, 100)  RMSE=0.085\n",
      "LSTM (50, 4, 100)  RMSE=0.085\n",
      "LSTM (60, 1, 100)  RMSE=0.089\n",
      "LSTM (60, 2, 100)  RMSE=0.087\n",
      "LSTM (60, 3, 100)  RMSE=0.085\n",
      "LSTM (60, 4, 100)  RMSE=0.085\n",
      "LSTM (70, 1, 100)  RMSE=0.089\n",
      "LSTM (70, 2, 100)  RMSE=0.087\n",
      "LSTM (70, 3, 100)  RMSE=0.084\n",
      "LSTM (70, 4, 100)  RMSE=0.084\n",
      "LSTM (80, 1, 100)  RMSE=0.089\n",
      "LSTM (80, 2, 100)  RMSE=0.087\n",
      "LSTM (80, 3, 100)  RMSE=0.085\n",
      "LSTM (80, 4, 100)  RMSE=0.084\n",
      "LSTM (90, 1, 100)  RMSE=0.089\n",
      "LSTM (90, 2, 100)  RMSE=0.087\n",
      "LSTM (90, 3, 100)  RMSE=0.085\n",
      "LSTM (90, 4, 100)  RMSE=0.085\n",
      "LSTM (100, 1, 100)  RMSE=0.089\n",
      "LSTM (100, 2, 100)  RMSE=0.087\n",
      "LSTM (100, 3, 100)  RMSE=0.085\n",
      "LSTM (100, 4, 100)  RMSE=0.084\n",
      "Best LSTM((20, 4, 100)) RMSE=0.084\n"
     ]
    }
   ],
   "source": [
    "neurons_list = np.arange(10,110,10)\n",
    "order_list = np.arange(1,5)\n",
    "epochs_list = [100]\n",
    "\n",
    "evaluate_multivariate_lstm_models(\"lstm_multi_wind_clean\", train_clean_df[neighbor_stations_90], validation_clean_df[neighbor_stations_90], neurons_list, order_list, epochs_list)\n",
    "evaluate_multivariate_lstm_models(\"lstm_multi_wind_residual\", train_residual_df[neighbor_stations_90], validation_residual_df[neighbor_stations_90], neurons_list, order_list, epochs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM (10, 1, 100)  RMSE=0.012\n",
      "LSTM (10, 2, 100)  RMSE=0.018\n",
      "LSTM (10, 3, 100)  RMSE=0.023\n",
      "LSTM (10, 4, 100)  RMSE=0.022\n",
      "LSTM (20, 1, 100)  RMSE=0.012\n",
      "LSTM (20, 2, 100)  RMSE=0.019\n",
      "LSTM (20, 3, 100)  RMSE=0.024\n",
      "LSTM (20, 4, 100)  RMSE=0.026\n",
      "LSTM (30, 1, 100)  RMSE=0.013\n",
      "LSTM (30, 2, 100)  RMSE=0.019\n",
      "LSTM (30, 3, 100)  RMSE=0.022\n",
      "LSTM (30, 4, 100)  RMSE=0.023\n",
      "LSTM (40, 1, 100)  RMSE=0.013\n",
      "LSTM (40, 2, 100)  RMSE=0.019\n",
      "LSTM (40, 3, 100)  RMSE=0.021\n",
      "LSTM (40, 4, 100)  RMSE=0.022\n",
      "LSTM (50, 1, 100)  RMSE=0.013\n",
      "LSTM (50, 2, 100)  RMSE=0.019\n",
      "LSTM (50, 3, 100)  RMSE=0.022\n",
      "LSTM (50, 4, 100)  RMSE=0.018\n",
      "LSTM (60, 1, 100)  RMSE=0.013\n",
      "LSTM (60, 2, 100)  RMSE=0.019\n",
      "LSTM (60, 3, 100)  RMSE=0.022\n",
      "LSTM (60, 4, 100)  RMSE=0.017\n",
      "LSTM (70, 1, 100)  RMSE=0.013\n",
      "LSTM (70, 2, 100)  RMSE=0.019\n",
      "LSTM (70, 3, 100)  RMSE=0.023\n",
      "LSTM (70, 4, 100)  RMSE=0.021\n",
      "LSTM (80, 1, 100)  RMSE=0.013\n",
      "LSTM (80, 2, 100)  RMSE=0.019\n",
      "LSTM (80, 3, 100)  RMSE=0.022\n",
      "LSTM (80, 4, 100)  RMSE=0.017\n",
      "LSTM (90, 1, 100)  RMSE=0.013\n",
      "LSTM (90, 2, 100)  RMSE=0.020\n",
      "LSTM (90, 3, 100)  RMSE=0.022\n",
      "LSTM (90, 4, 100)  RMSE=0.018\n",
      "LSTM (100, 1, 100)  RMSE=0.013\n",
      "LSTM (100, 2, 100)  RMSE=0.019\n",
      "LSTM (100, 3, 100)  RMSE=0.023\n",
      "LSTM (100, 4, 100)  RMSE=0.015\n",
      "Best LSTM((20, 1, 100)) RMSE=0.012\n",
      "LSTM (10, 1, 100)  RMSE=0.090\n",
      "LSTM (10, 2, 100)  RMSE=0.089\n",
      "LSTM (10, 3, 100)  RMSE=0.087\n",
      "LSTM (10, 4, 100)  RMSE=0.086\n",
      "LSTM (20, 1, 100)  RMSE=0.090\n",
      "LSTM (20, 2, 100)  RMSE=0.089\n",
      "LSTM (20, 3, 100)  RMSE=0.086\n",
      "LSTM (20, 4, 100)  RMSE=0.086\n",
      "LSTM (30, 1, 100)  RMSE=0.090\n",
      "LSTM (30, 2, 100)  RMSE=0.089\n",
      "LSTM (30, 3, 100)  RMSE=0.086\n",
      "LSTM (30, 4, 100)  RMSE=0.086\n",
      "LSTM (40, 1, 100)  RMSE=0.090\n",
      "LSTM (40, 2, 100)  RMSE=0.089\n",
      "LSTM (40, 3, 100)  RMSE=0.086\n",
      "LSTM (40, 4, 100)  RMSE=0.086\n",
      "LSTM (50, 1, 100)  RMSE=0.090\n",
      "LSTM (50, 2, 100)  RMSE=0.089\n",
      "LSTM (50, 3, 100)  RMSE=0.086\n",
      "LSTM (50, 4, 100)  RMSE=0.085\n",
      "LSTM (60, 1, 100)  RMSE=0.090\n",
      "LSTM (60, 2, 100)  RMSE=0.089\n",
      "LSTM (60, 3, 100)  RMSE=0.086\n",
      "LSTM (60, 4, 100)  RMSE=0.086\n",
      "LSTM (70, 1, 100)  RMSE=0.090\n",
      "LSTM (70, 2, 100)  RMSE=0.089\n",
      "LSTM (70, 3, 100)  RMSE=0.086\n",
      "LSTM (70, 4, 100)  RMSE=0.086\n",
      "LSTM (80, 1, 100)  RMSE=0.090\n",
      "LSTM (80, 2, 100)  RMSE=0.089\n",
      "LSTM (80, 3, 100)  RMSE=0.087\n",
      "LSTM (80, 4, 100)  RMSE=0.086\n",
      "LSTM (90, 1, 100)  RMSE=0.090\n",
      "LSTM (90, 2, 100)  RMSE=0.088\n",
      "LSTM (90, 3, 100)  RMSE=0.087\n",
      "LSTM (90, 4, 100)  RMSE=0.086\n",
      "LSTM (100, 1, 100)  RMSE=0.090\n",
      "LSTM (100, 2, 100)  RMSE=0.089\n",
      "LSTM (100, 3, 100)  RMSE=0.086\n",
      "LSTM (100, 4, 100)  RMSE=0.086\n",
      "Best LSTM((50, 4, 100)) RMSE=0.085\n"
     ]
    }
   ],
   "source": [
    "neurons_list = np.arange(10,110,10)\n",
    "order_list = np.arange(1,5)\n",
    "epochs_list = [100]\n",
    "\n",
    "evaluate_multivariate_lstm_models(\"lstm_uni_wind_clean\", train_clean_df[[target_station]], validation_clean_df[[target_station]], neurons_list, order_list, epochs_list)\n",
    "evaluate_multivariate_lstm_models(\"lstm_uni_wind_residual\", train_residual_df[[target_station]], validation_residual_df[[target_station]], neurons_list, order_list, epochs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multivariate_mlp_models(test_name, train_df, validation_df, neurons_list, order_list, epochs_list):\n",
    "    \n",
    "    lstm_results = pd.DataFrame(columns=['Neurons','Order','Epochs','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    \n",
    "    nfeat = len(train_df.columns)\n",
    "    nsteps = 1\n",
    "    \n",
    "    for _neurons in neurons_list:\n",
    "        for _order in order_list:\n",
    "            for epochs in epochs_list:\n",
    "                    \n",
    "                    nobs = nfeat * _order\n",
    "                    \n",
    "                    train_reshaped_df = series_to_supervised(train_df, n_in=_order, n_out=nsteps)\n",
    "                    train_X, train_Y = train_reshaped_df.iloc[:,:nobs].values, train_reshaped_df.iloc[:,-nfeat].values\n",
    "                    \n",
    "                    val_reshaped_df = series_to_supervised(validation_df, n_in=_order, n_out=nsteps)\n",
    "                    validation_X, validation_Y = val_reshaped_df.iloc[:,:nobs].values, val_reshaped_df.iloc[:,-nfeat].values\n",
    "                    \n",
    "                    \n",
    "                    # design network\n",
    "                    model = Sequential()\n",
    "                    model.add(Dense(_neurons, activation='relu', input_dim=train_X.shape[1]))\n",
    "                    model.add(Dense(1))\n",
    "                    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "                    \n",
    "                    # fit network\n",
    "                    history = model.fit(train_X, train_Y, epochs=epochs, batch_size=72, verbose=False, shuffle=False)\n",
    "                    forecast = model.predict(validation_X)\n",
    "                    \n",
    "                    rmse = math.sqrt(mean_squared_error(validation_Y, forecast))\n",
    "                    params = (_neurons, _order,epochs)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, params\n",
    "\n",
    "                    res = {'Neurons':_neurons, 'Order':_order, 'Epochs' : epochs ,'RMSE' : rmse}\n",
    "                    print('MLP %s  RMSE=%.3f' % (params,rmse))\n",
    "                    lstm_results = lstm_results.append(res, ignore_index=True)\n",
    "                    lstm_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best MLP(%s) RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP - Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP (10, 1, 100)  RMSE=0.017\n",
      "MLP (10, 2, 100)  RMSE=0.017\n",
      "MLP (10, 3, 100)  RMSE=0.013\n",
      "MLP (10, 4, 100)  RMSE=0.028\n",
      "MLP (20, 1, 100)  RMSE=0.024\n",
      "MLP (20, 2, 100)  RMSE=0.013\n",
      "MLP (20, 3, 100)  RMSE=0.013\n",
      "MLP (20, 4, 100)  RMSE=0.019\n",
      "MLP (30, 1, 100)  RMSE=0.015\n",
      "MLP (30, 2, 100)  RMSE=0.012\n",
      "MLP (30, 3, 100)  RMSE=0.013\n",
      "MLP (30, 4, 100)  RMSE=0.021\n",
      "MLP (40, 1, 100)  RMSE=0.018\n",
      "MLP (40, 2, 100)  RMSE=0.017\n",
      "MLP (40, 3, 100)  RMSE=0.013\n",
      "MLP (40, 4, 100)  RMSE=0.012\n",
      "MLP (50, 1, 100)  RMSE=0.013\n",
      "MLP (50, 2, 100)  RMSE=0.017\n",
      "MLP (50, 3, 100)  RMSE=0.012\n",
      "MLP (50, 4, 100)  RMSE=0.014\n",
      "MLP (60, 1, 100)  RMSE=0.017\n",
      "MLP (60, 2, 100)  RMSE=0.015\n",
      "MLP (60, 3, 100)  RMSE=0.012\n",
      "MLP (60, 4, 100)  RMSE=0.014\n",
      "MLP (70, 1, 100)  RMSE=0.016\n",
      "MLP (70, 2, 100)  RMSE=0.011\n",
      "MLP (70, 3, 100)  RMSE=0.011\n",
      "MLP (70, 4, 100)  RMSE=0.012\n",
      "MLP (80, 1, 100)  RMSE=0.014\n",
      "MLP (80, 2, 100)  RMSE=0.019\n",
      "MLP (80, 3, 100)  RMSE=0.011\n",
      "MLP (80, 4, 100)  RMSE=0.013\n",
      "MLP (90, 1, 100)  RMSE=0.017\n",
      "MLP (90, 2, 100)  RMSE=0.018\n",
      "MLP (90, 3, 100)  RMSE=0.010\n",
      "MLP (90, 4, 100)  RMSE=0.017\n",
      "MLP (100, 1, 100)  RMSE=0.014\n",
      "MLP (100, 2, 100)  RMSE=0.014\n",
      "MLP (100, 3, 100)  RMSE=0.013\n",
      "MLP (100, 4, 100)  RMSE=0.012\n",
      "Best MLP((90, 3, 100)) RMSE=0.010\n",
      "MLP (10, 1, 100)  RMSE=0.088\n",
      "MLP (10, 2, 100)  RMSE=0.092\n",
      "MLP (10, 3, 100)  RMSE=0.086\n",
      "MLP (10, 4, 100)  RMSE=0.085\n",
      "MLP (20, 1, 100)  RMSE=0.089\n",
      "MLP (20, 2, 100)  RMSE=0.088\n",
      "MLP (20, 3, 100)  RMSE=0.086\n",
      "MLP (20, 4, 100)  RMSE=0.086\n",
      "MLP (30, 1, 100)  RMSE=0.089\n",
      "MLP (30, 2, 100)  RMSE=0.088\n",
      "MLP (30, 3, 100)  RMSE=0.086\n",
      "MLP (30, 4, 100)  RMSE=0.085\n",
      "MLP (40, 1, 100)  RMSE=0.089\n",
      "MLP (40, 2, 100)  RMSE=0.087\n",
      "MLP (40, 3, 100)  RMSE=0.086\n",
      "MLP (40, 4, 100)  RMSE=0.086\n",
      "MLP (50, 1, 100)  RMSE=0.089\n",
      "MLP (50, 2, 100)  RMSE=0.088\n",
      "MLP (50, 3, 100)  RMSE=0.086\n",
      "MLP (50, 4, 100)  RMSE=0.085\n",
      "MLP (60, 1, 100)  RMSE=0.089\n",
      "MLP (60, 2, 100)  RMSE=0.088\n",
      "MLP (60, 3, 100)  RMSE=0.087\n",
      "MLP (60, 4, 100)  RMSE=0.087\n",
      "MLP (70, 1, 100)  RMSE=0.089\n",
      "MLP (70, 2, 100)  RMSE=0.087\n",
      "MLP (70, 3, 100)  RMSE=0.086\n",
      "MLP (70, 4, 100)  RMSE=0.086\n",
      "MLP (80, 1, 100)  RMSE=0.089\n",
      "MLP (80, 2, 100)  RMSE=0.088\n",
      "MLP (80, 3, 100)  RMSE=0.086\n",
      "MLP (80, 4, 100)  RMSE=0.086\n",
      "MLP (90, 1, 100)  RMSE=0.089\n",
      "MLP (90, 2, 100)  RMSE=0.088\n",
      "MLP (90, 3, 100)  RMSE=0.086\n",
      "MLP (90, 4, 100)  RMSE=0.086\n",
      "MLP (100, 1, 100)  RMSE=0.089\n",
      "MLP (100, 2, 100)  RMSE=0.088\n",
      "MLP (100, 3, 100)  RMSE=0.086\n",
      "MLP (100, 4, 100)  RMSE=0.086\n",
      "Best MLP((30, 4, 100)) RMSE=0.085\n"
     ]
    }
   ],
   "source": [
    "neurons_list = np.arange(10,110,10)\n",
    "order_list = np.arange(1,5)\n",
    "epochs_list = [100]\n",
    "\n",
    "evaluate_multivariate_mlp_models(\"mlp_multi_wind_clean\", train_clean_df[neighbor_stations_90], validation_clean_df[neighbor_stations_90], neurons_list, order_list, epochs_list)\n",
    "evaluate_multivariate_mlp_models(\"mlp_multi_wind_residual\", train_residual_df[neighbor_stations_90], validation_residual_df[neighbor_stations_90], neurons_list, order_list, epochs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP - Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP (10, 1, 100)  RMSE=0.012\n",
      "MLP (10, 2, 100)  RMSE=0.016\n",
      "MLP (10, 3, 100)  RMSE=0.012\n",
      "MLP (10, 4, 100)  RMSE=0.032\n",
      "MLP (20, 1, 100)  RMSE=0.012\n",
      "MLP (20, 2, 100)  RMSE=0.016\n",
      "MLP (20, 3, 100)  RMSE=0.019\n",
      "MLP (20, 4, 100)  RMSE=0.029\n",
      "MLP (30, 1, 100)  RMSE=0.012\n",
      "MLP (30, 2, 100)  RMSE=0.017\n",
      "MLP (30, 3, 100)  RMSE=0.023\n",
      "MLP (30, 4, 100)  RMSE=0.011\n",
      "MLP (40, 1, 100)  RMSE=0.012\n",
      "MLP (40, 2, 100)  RMSE=0.016\n",
      "MLP (40, 3, 100)  RMSE=0.011\n",
      "MLP (40, 4, 100)  RMSE=0.011\n",
      "MLP (50, 1, 100)  RMSE=0.012\n",
      "MLP (50, 2, 100)  RMSE=0.020\n",
      "MLP (50, 3, 100)  RMSE=0.017\n",
      "MLP (50, 4, 100)  RMSE=0.010\n",
      "MLP (60, 1, 100)  RMSE=0.012\n",
      "MLP (60, 2, 100)  RMSE=0.015\n",
      "MLP (60, 3, 100)  RMSE=0.011\n",
      "MLP (60, 4, 100)  RMSE=0.009\n",
      "MLP (70, 1, 100)  RMSE=0.012\n",
      "MLP (70, 2, 100)  RMSE=0.014\n",
      "MLP (70, 3, 100)  RMSE=0.011\n",
      "MLP (70, 4, 100)  RMSE=0.011\n",
      "MLP (80, 1, 100)  RMSE=0.012\n",
      "MLP (80, 2, 100)  RMSE=0.012\n",
      "MLP (80, 3, 100)  RMSE=0.015\n",
      "MLP (80, 4, 100)  RMSE=0.008\n",
      "MLP (90, 1, 100)  RMSE=0.012\n",
      "MLP (90, 2, 100)  RMSE=0.016\n",
      "MLP (90, 3, 100)  RMSE=0.013\n",
      "MLP (90, 4, 100)  RMSE=0.011\n",
      "MLP (100, 1, 100)  RMSE=0.012\n",
      "MLP (100, 2, 100)  RMSE=0.018\n",
      "MLP (100, 3, 100)  RMSE=0.010\n",
      "MLP (100, 4, 100)  RMSE=0.011\n",
      "Best MLP((80, 4, 100)) RMSE=0.008\n",
      "MLP (10, 1, 100)  RMSE=0.090\n",
      "MLP (10, 2, 100)  RMSE=0.089\n",
      "MLP (10, 3, 100)  RMSE=0.089\n",
      "MLP (10, 4, 100)  RMSE=0.087\n",
      "MLP (20, 1, 100)  RMSE=0.090\n",
      "MLP (20, 2, 100)  RMSE=0.089\n",
      "MLP (20, 3, 100)  RMSE=0.087\n",
      "MLP (20, 4, 100)  RMSE=0.086\n",
      "MLP (30, 1, 100)  RMSE=0.090\n",
      "MLP (30, 2, 100)  RMSE=0.089\n",
      "MLP (30, 3, 100)  RMSE=0.087\n",
      "MLP (30, 4, 100)  RMSE=0.086\n",
      "MLP (40, 1, 100)  RMSE=0.090\n",
      "MLP (40, 2, 100)  RMSE=0.090\n",
      "MLP (40, 3, 100)  RMSE=0.087\n",
      "MLP (40, 4, 100)  RMSE=0.086\n",
      "MLP (50, 1, 100)  RMSE=0.090\n",
      "MLP (50, 2, 100)  RMSE=0.089\n",
      "MLP (50, 3, 100)  RMSE=0.087\n",
      "MLP (50, 4, 100)  RMSE=0.085\n",
      "MLP (60, 1, 100)  RMSE=0.090\n",
      "MLP (60, 2, 100)  RMSE=0.090\n",
      "MLP (60, 3, 100)  RMSE=0.087\n",
      "MLP (60, 4, 100)  RMSE=0.086\n",
      "MLP (70, 1, 100)  RMSE=0.090\n",
      "MLP (70, 2, 100)  RMSE=0.089\n",
      "MLP (70, 3, 100)  RMSE=0.087\n",
      "MLP (70, 4, 100)  RMSE=0.086\n",
      "MLP (80, 1, 100)  RMSE=0.090\n",
      "MLP (80, 2, 100)  RMSE=0.089\n",
      "MLP (80, 3, 100)  RMSE=0.087\n",
      "MLP (80, 4, 100)  RMSE=0.086\n",
      "MLP (90, 1, 100)  RMSE=0.090\n",
      "MLP (90, 2, 100)  RMSE=0.090\n",
      "MLP (90, 3, 100)  RMSE=0.087\n",
      "MLP (90, 4, 100)  RMSE=0.086\n",
      "MLP (100, 1, 100)  RMSE=0.090\n",
      "MLP (100, 2, 100)  RMSE=0.089\n",
      "MLP (100, 3, 100)  RMSE=0.087\n",
      "MLP (100, 4, 100)  RMSE=0.086\n",
      "Best MLP((50, 4, 100)) RMSE=0.085\n"
     ]
    }
   ],
   "source": [
    "neurons_list = np.arange(10,110,10)\n",
    "order_list = np.arange(1,5)\n",
    "epochs_list = [100]\n",
    "\n",
    "evaluate_multivariate_mlp_models(\"mlp_uni_wind_clean\", train_clean_df[[target_station]], validation_clean_df[[target_station]], neurons_list, order_list, epochs_list)\n",
    "evaluate_multivariate_mlp_models(\"mlp_uni_wind_residual\", train_residual_df[[target_station]], validation_residual_df[[target_station]], neurons_list, order_list, epochs_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
