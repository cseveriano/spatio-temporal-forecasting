{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models import KMeansPartitioner\n",
    "from sklearn import preprocessing\n",
    "from pyFTS.partitioners import Grid, Util as pUtil\n",
    "from pyFTS.models import hofts\n",
    "\n",
    "from models import sthofts\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import dispy\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/petroniocandido/pyFTS\n",
      "  Cloning https://github.com/petroniocandido/pyFTS to /private/var/folders/13/t7d8w0nd0hv6w9_p2rntvym00000gr/T/pip-req-build-q6ysgwex\n",
      "Building wheels for collected packages: pyFTS\n",
      "  Running setup.py bdist_wheel for pyFTS ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /private/var/folders/13/t7d8w0nd0hv6w9_p2rntvym00000gr/T/pip-ephem-wheel-cache-3inasz9v/wheels/84/d7/1e/a333c7128f25b347640740859808db094c4478e98663cd2297\n",
      "Successfully built pyFTS\n",
      "Installing collected packages: pyFTS\n",
      "  Found existing installation: pyFTS 1.2.2\n",
      "    Uninstalling pyFTS-1.2.2:\n",
      "      Successfully uninstalled pyFTS-1.2.2\n",
      "Successfully installed pyFTS-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/petroniocandido/pyFTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    mindf = df.min()\n",
    "    maxdf = df.max()\n",
    "    return (df-mindf)/(maxdf-mindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, df_clean, df_residual, interval):\n",
    "    sample_df = df.loc[interval]\n",
    "    residual_sample_df = df_residual.loc[interval]\n",
    "    clean_sample_df = df_clean.loc[interval]\n",
    "\n",
    "    norm_residual_sample_df = normalize(residual_sample_df)\n",
    "    norm_clean_sample_df = normalize(clean_sample_df)\n",
    "\n",
    "\n",
    "    week = (sample_df.index.day - 1) // 7 + 1\n",
    "\n",
    "    # PARA OS TESTES:\n",
    "    # 2 SEMANAS PARA TREINAMENTO\n",
    "    train_df = sample_df.loc[week <= 2]\n",
    "    train_residual_df = norm_residual_sample_df.loc[week <= 2]\n",
    "    train_clean_df = norm_clean_sample_df.loc[week <= 2]\n",
    "\n",
    "    # 1 SEMANA PARA VALIDACAO\n",
    "    validation_df = sample_df.loc[week == 3]\n",
    "    validation_residual_df = norm_residual_sample_df.loc[week == 3]\n",
    "    validation_clean_df = norm_clean_sample_df.loc[week == 3]\n",
    "\n",
    "    # 1 SEMANA PARA TESTES\n",
    "    test_df = sample_df.loc[week > 3]\n",
    "    test_residual_df = norm_residual_sample_df.loc[week > 3]\n",
    "    test_clean_df = norm_clean_sample_df.loc[week > 3]\n",
    "    \n",
    "    return (train_df, train_clean_df, train_residual_df, validation_df, validation_clean_df, validation_residual_df, test_df, test_clean_df, test_residual_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_dispy_cluster(method, nodes):\n",
    "    import dispy, dispy.httpd, logging\n",
    "\n",
    "    cluster = dispy.JobCluster(method, nodes=nodes, loglevel=logging.DEBUG, ping_interval=1000)\n",
    "\n",
    "    http_server = dispy.httpd.DispyHTTPServer(cluster)\n",
    "\n",
    "    return cluster, http_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_dispy_cluster(cluster, http_server):\n",
    "    cluster.wait()  # wait for all jobs to finish\n",
    "\n",
    "    cluster.print_status()\n",
    "\n",
    "    http_server.shutdown()  # this waits until browser gets all updates\n",
    "    cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"df_oahu.pkl\")\n",
    "df_ssa_clean = pd.read_pickle(\"df_ssa_clean.pkl\")\n",
    "df_ssa_residual = pd.read_pickle(\"df_ssa_residual.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['AP_1', 'AP_7'], inplace=True)\n",
    "df_ssa_clean.drop(columns=['AP_1', 'AP_7'], inplace=True)\n",
    "df_ssa_residual.drop(columns=['AP_1', 'AP_7'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entire data split by season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = ((df.index >= '2010-11') & (df.index <= '2010-12'))\n",
    "(train_df, train_clean_df, train_residual_df, \n",
    " validation_df, validation_clean_df, validation_residual_df, \n",
    " test_df, test_clean_df, test_residual_df) = split_data(df, df_ssa_clean, df_ssa_residual, interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Winter (Dec-Jan-Feb), ii) Spring (Mar-Apr-May), iii)\n",
    "Summer (Jun-Jul-Aug) and iv) Autumn (Sep-Oct-Nov)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_interval = ((df.index >= '2010-06') & (df.index <= '2010-09'))\n",
    "(summer_train_df, summer_train_clean_df, summer_train_residual_df, \n",
    " summer_validation_df, summer_validation_clean_df, summer_validation_residual_df, \n",
    " summer_test_df, summer_test_clean_df, summer_test_residual_df) = split_data(df, df_ssa_clean, df_ssa_residual, summer_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "autumn_interval = ((df.index >= '2010-09') & (df.index <= '2010-12'))\n",
    "(autumn_train_df, autumn_train_clean_df, autumn_train_residual_df, \n",
    " autumn_validation_df, autumn_validation_clean_df, autumn_validation_residual_df, \n",
    " autumn_test_df, autumn_test_clean_df, autumn_test_residual_df) = split_data(df, df_ssa_clean, df_ssa_residual, autumn_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_interval = ((df.index >= '2010-12') & (df.index <= '2011-03'))\n",
    "(winter_train_df, winter_train_clean_df, winter_train_residual_df, \n",
    "winter_validation_df, winter_validation_clean_df, winter_validation_residual_df, \n",
    "winter_test_df, winter_test_clean_df, winter_test_residual_df) = split_data(df, df_ssa_clean, df_ssa_residual, winter_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_interval = ((df.index >= '2011-03') & (df.index <= '2011-06'))\n",
    "(spring_train_df, spring_train_clean_df, spring_train_residual_df, \n",
    " spring_validation_df, spring_validation_clean_df, spring_validation_residual_df, \n",
    " spring_test_df, spring_test_clean_df, spring_test_residual_df) = split_data(df, df_ssa_clean, df_ssa_residual, spring_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_station = 'DHHL_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All neighbor stations with residual correlation greater than .90\n",
    "neighbor_stations_90 = ['DHHL_3',  'DHHL_4','DHHL_5','DHHL_10','DHHL_11','DHHL_9','DHHL_2', 'DHHL_6','DHHL_7','DHHL_8']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(train, validation, arima_order):\n",
    "\n",
    "    whole_data = train.append(validation)\n",
    "    test_data = validation\n",
    "    \n",
    "    training_mod = SARIMAX(whole_data.values, order=arima_order, seasonal_order=(0,0,0,0))\n",
    "    training_res = training_mod.fit()\n",
    "    \n",
    "    mod = SARIMAX(whole_data.values, order=arima_order, seasonal_order=(0,0,0,0))\n",
    "    res = mod.filter(training_res.params)\n",
    "    \n",
    "    insample = res.predict()\n",
    "    wlen = len(whole_data)\n",
    "    tlen = len(test_data)\n",
    "\n",
    "    predictions = insample[wlen-tlen:]    \n",
    "    \n",
    "    error = math.sqrt(mean_squared_error(validation, predictions))\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(test_name, train_df, validation_df, p_values, d_values, q_values):\n",
    "    arima_results = pd.DataFrame(columns=['Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                print('Testing ARIMA%s ' % str(order))\n",
    "                #try:\n",
    "                rmse = evaluate_arima_model(train_df, validation_df, order)\n",
    "                if rmse < best_score:\n",
    "                    best_score, best_cfg = rmse, order\n",
    "\n",
    "                res = {'Order' : str(order) ,'RMSE' : rmse}\n",
    "                print('ARIMA%s RMSE=%.3f' % (order,rmse))\n",
    "                arima_results = arima_results.append(res, ignore_index=True)\n",
    "                arima_results.to_csv(test_name+\".csv\")\n",
    "                #except:\n",
    "                print('Invalid model%s ' % str(order))\n",
    "                continue\n",
    "    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def distributed_arima_evaluate_models(eval_method, test_name, train_df, validation_df, p_values, d_values, q_values):\n",
    "\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    method = eval_method\n",
    "    nodes=['192.168.1.3']\n",
    "    cluster, http_server = start_dispy_cluster(method, nodes)\n",
    "    jobs = []\n",
    "    job_count = 1\n",
    "\n",
    "    arima_results = pd.DataFrame(columns=['Order','RMSE'])\n",
    "\n",
    "    for p in p_values:\n",
    "        for d in d_values:\n",
    "            for q in q_values:\n",
    "                order = (p,d,q)\n",
    "                print('Testing ARIMA%s ' % str(order))\n",
    "                job = cluster.submit(train_df, validation_df, order)\n",
    "                job.id = job_count  # associate an ID to identify jobs (if needed later)\n",
    "                jobs.append(job)\n",
    "                job_count += 1\n",
    "                \n",
    "    for job in jobs:\n",
    "        print(\"[{0: %H:%M:%S}] Processing batch \".format(datetime.datetime.now()) + str(job.id))\n",
    "        rmse = job()\n",
    "        if job.status == dispy.DispyJob.Finished and rmse is not None:\n",
    "            if rmse < best_score:\n",
    "                best_score, best_cfg = rmse, order\n",
    "\n",
    "            res = {'Order' : str(order) ,'RMSE' : rmse}\n",
    "            print('ARIMA%s RMSE=%.3f' % (order,rmse))\n",
    "            arima_results = arima_results.append(res, ignore_index=True)\n",
    "            arima_results.to_csv(test_name+\".csv\")\n",
    "        else:\n",
    "            print(job.exception)\n",
    "            print(job.stdout)\n",
    "\n",
    "        print(\"[{0: %H:%M:%S}] Finished batch \".format(datetime.datetime.now()) + str(job.id))\n",
    "\n",
    "    print(\"[{0: %H:%M:%S}] Distributed Tuning Finished\".format(datetime.datetime.now()))            \n",
    "    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))\n",
    "    stop_dispy_cluster(cluster, http_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-13 16:11:47 pycos - version 4.6.5 with kqueue I/O notifier\n",
      "2018-06-13 16:11:47 dispy - dispy client version: 4.8.7\n",
      "2018-06-13 16:11:48 dispy - Storing fault recovery information in \"_dispy_20180613161147\"\n",
      "2018-06-13 16:11:48 dispy - dispy client at 192.168.1.3:51347\n",
      "2018-06-13 16:11:48 dispy - Started HTTP server at ('0.0.0.0', 8181)\n",
      "Testing ARIMA(0, 0, 0) \n",
      "Testing ARIMA(0, 0, 1) \n",
      "Testing ARIMA(0, 0, 2) \n",
      "Testing ARIMA(0, 1, 0) \n",
      "Testing ARIMA(0, 1, 1) \n",
      "Testing ARIMA(0, 1, 2) \n",
      "Testing ARIMA(1, 0, 0) \n",
      "Testing ARIMA(1, 0, 1) \n",
      "Testing ARIMA(1, 0, 2) \n",
      "Testing ARIMA(1, 1, 0) \n",
      "Testing ARIMA(1, 1, 1) \n",
      "Testing ARIMA(1, 1, 2) \n",
      "Testing ARIMA(2, 0, 0) \n",
      "Testing ARIMA(2, 0, 1) \n",
      "Testing ARIMA(2, 0, 2) \n",
      "Testing ARIMA(2, 1, 0) \n",
      "Testing ARIMA(2, 1, 1) \n",
      "Testing ARIMA(2, 1, 2) \n",
      "[ 16:11:48] Processing batch 1\n",
      "2018-06-13 16:11:48 dispy - Discovered 192.168.1.3:51348 (minds-imac-1.local) with 3 cpus\n",
      "2018-06-13 16:11:48 dispy - Running job 112091245808 on 192.168.1.3\n",
      "2018-06-13 16:11:48 dispy - Running job 112091245568 on 192.168.1.3\n",
      "2018-06-13 16:11:48 dispy - Running job 112091245688 on 192.168.1.3\n",
      "2018-06-13 16:11:48 dispy - Running job 3 / 112091245808 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:48 dispy - Running job 1 / 112091245568 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:48 dispy - Running job 2 / 112091245688 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:56 dispy - Received reply for job 3 / 112091245808 from 192.168.1.3\n",
      "2018-06-13 16:11:56 dispy - Running job 112091245928 on 192.168.1.3\n",
      "2018-06-13 16:11:56 dispy - Received reply for job 2 / 112091245688 from 192.168.1.3\n",
      "2018-06-13 16:11:56 dispy - Received reply for job 1 / 112091245568 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:11:56] Finished batch 1\n",
      "[ 16:11:56] Processing batch 2\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:11:56] Finished batch 2\n",
      "[ 16:11:56] Processing batch 3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:11:56] Finished batch 3\n",
      "[ 16:11:56] Processing batch 4\n",
      "2018-06-13 16:11:56 dispy - Running job 112091246048 on 192.168.1.3\n",
      "2018-06-13 16:11:56 dispy - Running job 112091246168 on 192.168.1.3\n",
      "2018-06-13 16:11:56 dispy - Running job 4 / 112091245928 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:56 dispy - Running job 6 / 112091246168 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:56 dispy - Running job 5 / 112091246048 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:58 dispy - Received reply for job 4 / 112091245928 from 192.168.1.3\n",
      "2018-06-13 16:11:58 dispy - Running job 112091246288 on 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:11:58] Finished batch 4\n",
      "[ 16:11:58] Processing batch 5\n",
      "2018-06-13 16:11:58 dispy - Running job 7 / 112091246288 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:58 dispy - Received reply for job 5 / 112091246048 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "2018-06-13 16:11:58 dispy - Received reply for job 6 / 112091246168 from 192.168.1.3\n",
      "\n",
      "[ 16:11:58] Finished batch 5\n",
      "[ 16:11:58] Processing batch 6\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "2018-06-13 16:11:58 dispy - Running job 112091246408 on 192.168.1.3\n",
      "[ 16:11:58] Finished batch 6\n",
      "[ 16:11:58] Processing batch 7\n",
      "2018-06-13 16:11:58 dispy - Running job 112083333192 on 192.168.1.3\n",
      "2018-06-13 16:11:58 dispy - Running job 8 / 112091246408 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:58 dispy - Running job 9 / 112083333192 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:59 dispy - Received reply for job 8 / 112091246408 from 192.168.1.3\n",
      "2018-06-13 16:11:59 dispy - Running job 112083333312 on 192.168.1.3\n",
      "2018-06-13 16:11:59 dispy - Running job 10 / 112083333312 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:59 dispy - Received reply for job 7 / 112091246288 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:11:59] Finished batch 7\n",
      "[ 16:11:59] Processing batch 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "2018-06-13 16:11:59 dispy - Received reply for job 9 / 112083333192 from 192.168.1.3\n",
      "\n",
      "[ 16:11:59] Finished batch 8\n",
      "[ 16:11:59] Processing batch 9\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:11:59] Finished batch 9\n",
      "[ 16:11:59] Processing batch 10\n",
      "2018-06-13 16:11:59 dispy - Running job 112083333432 on 192.168.1.3\n",
      "2018-06-13 16:11:59 dispy - Running job 112083333552 on 192.168.1.3\n",
      "2018-06-13 16:11:59 dispy - Running job 11 / 112083333432 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:11:59 dispy - Running job 12 / 112083333552 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:01 dispy - Received reply for job 12 / 112083333552 from 192.168.1.3\n",
      "2018-06-13 16:12:01 dispy - Running job 112083333672 on 192.168.1.3\n",
      "2018-06-13 16:12:01 dispy - Running job 13 / 112083333672 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:01 dispy - Received reply for job 10 / 112083333312 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:01] Finished batch 10\n",
      "[ 16:12:01] Processing batch 11\n",
      "2018-06-13 16:12:01 dispy - Received reply for job 11 / 112083333432 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:01] Finished batch 11\n",
      "[ 16:12:01] Processing batch 12\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:01] Finished batch 12\n",
      "[ 16:12:01] Processing batch 13\n",
      "2018-06-13 16:12:01 dispy - Running job 112083333792 on 192.168.1.3\n",
      "2018-06-13 16:12:01 dispy - Running job 112083333912 on 192.168.1.3\n",
      "2018-06-13 16:12:01 dispy - Running job 14 / 112083333792 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:01 dispy - Running job 15 / 112083333912 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:02 dispy - Received reply for job 13 / 112083333672 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "2018-06-13 16:12:02 dispy - Running job 112083334032 on 192.168.1.3\n",
      "\n",
      "\n",
      "[ 16:12:02] Finished batch 13\n",
      "[ 16:12:02] Processing batch 14\n",
      "2018-06-13 16:12:02 dispy - Running job 16 / 112083334032 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:02 dispy - Received reply for job 14 / 112083333792 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "2018-06-13 16:12:02 dispy - Received reply for job 15 / 112083333912 from 192.168.1.3\n",
      "\n",
      "[ 16:12:02] Finished batch 14\n",
      "[ 16:12:02] Processing batch 15\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:02] Finished batch 15\n",
      "[ 16:12:02] Processing batch 16\n",
      "2018-06-13 16:12:02 dispy - Running job 112083334152 on 192.168.1.3\n",
      "2018-06-13 16:12:02 dispy - Running job 112083334272 on 192.168.1.3\n",
      "2018-06-13 16:12:02 dispy - Running job 17 / 112083334152 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:02 dispy - Running job 18 / 112083334272 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:03 dispy - Received reply for job 16 / 112083334032 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:03] Finished batch 16\n",
      "[ 16:12:03] Processing batch 17\n",
      "2018-06-13 16:12:03 dispy - Received reply for job 17 / 112083334152 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:03] Finished batch 17\n",
      "[ 16:12:03] Processing batch 18\n",
      "2018-06-13 16:12:03 dispy - Received reply for job 18 / 112083334272 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:03] Finished batch 18\n",
      "[ 16:12:03] Distributed Tuning Finished\n",
      "Best ARIMANone RMSE=inf\n",
      "\n",
      "                           Node |  CPUs |    Jobs |    Sec/Job | Node Time Sec\n",
      "------------------------------------------------------------------------------\n",
      " 192.168.1.3 (minds-imac-1.loca |     3 |      18 |      2.483 |        44.690\n",
      "\n",
      "Total job time: 44.690 sec, wall time: 15.146 sec, speedup: 2.951\n",
      "\n",
      "2018-06-13 16:12:03 dispy - HTTP server waiting for 10 seconds for client updates before quitting\n",
      "2018-06-13 16:12:13 dispy - Closing node 192.168.1.3 for evaluate_arima_model / 1528917108100\n",
      "2018-06-13 16:12:13 dispy - Started HTTP server at ('0.0.0.0', 8181)\n",
      "Testing ARIMA(0, 0, 0) \n",
      "Testing ARIMA(0, 0, 1) \n",
      "Testing ARIMA(0, 0, 2) 2018-06-13 16:12:13 dispy - Running job 112091245808 on 192.168.1.3\n",
      "2018-06-13 16:12:13 dispy - Running job 112091246168 on 192.168.1.3\n",
      "\n",
      "Testing ARIMA(0, 1, 0) \n",
      "2018-06-13 16:12:13 dispy - Running job 112091245568 on 192.168.1.3\n",
      "Testing ARIMA(0, 1, 1) \n",
      "Testing ARIMA(0, 1, 2) \n",
      "2018-06-13 16:12:13 dispy - Running job 2 / 112091245808 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:13 dispy - Running job 1 / 112091246168 on 192.168.1.3 (busy: 3 / 3)\n",
      "Testing ARIMA(1, 0, 0) \n",
      "Testing ARIMA(1, 0, 1) \n",
      "Testing ARIMA(1, 0, 2) \n",
      "Testing ARIMA(1, 1, 0) \n",
      "Testing ARIMA(1, 1, 1) \n",
      "Testing ARIMA(1, 1, 2) \n",
      "Testing ARIMA(2, 0, 0) \n",
      "Testing ARIMA(2, 0, 1) \n",
      "Testing ARIMA(2, 0, 2) \n",
      "2018-06-13 16:12:13 dispy - Running job 3 / 112091245568 on 192.168.1.3 (busy: 3 / 3)\n",
      "Testing ARIMA(2, 1, 0) \n",
      "Testing ARIMA(2, 1, 1) \n",
      "Testing ARIMA(2, 1, 2) \n",
      "[ 16:12:13] Processing batch 1\n",
      "2018-06-13 16:12:14 dispy - Received reply for job 2 / 112091245808 from 192.168.1.3\n",
      "2018-06-13 16:12:14 dispy - Running job 112083334272 on 192.168.1.3\n",
      "2018-06-13 16:12:14 dispy - Running job 4 / 112083334272 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:14 dispy - Received reply for job 3 / 112091245568 from 192.168.1.3\n",
      "2018-06-13 16:12:14 dispy - Received reply for job 1 / 112091246168 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:14] Finished batch 1\n",
      "[ 16:12:14] Processing batch 22018-06-13 16:12:14 dispy - Running job 112083333912 on 192.168.1.3\n",
      "2018-06-13 16:12:14 dispy - Running job 112083334032 on 192.168.1.3\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:14] Finished batch 2\n",
      "[ 16:12:14] Processing batch 3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:14] Finished batch 3\n",
      "[ 16:12:14] Processing batch 4\n",
      "2018-06-13 16:12:14 dispy - Running job 6 / 112083333912 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:14 dispy - Running job 5 / 112083334032 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:15 dispy - Received reply for job 4 / 112083334272 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "2018-06-13 16:12:15 dispy - Running job 112083333792 on 192.168.1.3\n",
      "\n",
      "\n",
      "[ 16:12:15] Finished batch 4\n",
      "[ 16:12:15] Processing batch 5\n",
      "2018-06-13 16:12:15 dispy - Running job 7 / 112083333792 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:15 dispy - Received reply for job 6 / 112083333912 from 192.168.1.3\n",
      "2018-06-13 16:12:15 dispy - Running job 112083333672 on 192.168.1.3\n",
      "2018-06-13 16:12:15 dispy - Received reply for job 5 / 112083334032 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "2018-06-13 16:12:15 dispy - Running job 112083333432 on 192.168.1.3\n",
      "\n",
      "\n",
      "[ 16:12:15] Finished batch 5\n",
      "[ 16:12:15] Processing batch 6\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:15] Finished batch 6\n",
      "[ 16:12:15] Processing batch 7\n",
      "2018-06-13 16:12:15 dispy - Running job 8 / 112083333672 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:15 dispy - Running job 9 / 112083333432 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:15 dispy - Received reply for job 7 / 112083333792 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:15] Finished batch 7\n",
      "[ 16:12:15] Processing batch 8\n",
      "2018-06-13 16:12:15 dispy - Running job 112083333312 on 192.168.1.3\n",
      "2018-06-13 16:12:15 dispy - Running job 10 / 112083333312 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:16 dispy - Received reply for job 8 / 112083333672 from 192.168.1.3\n",
      "2018-06-13 16:12:16 dispy - Running job 112083333552 on 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:16] Finished batch 8\n",
      "[ 16:12:16] Processing batch 9\n",
      "2018-06-13 16:12:16 dispy - Running job 11 / 112083333552 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:16 dispy - Received reply for job 9 / 112083333432 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:16] Finished batch 9\n",
      "[ 16:12:16] Processing batch 10\n",
      "2018-06-13 16:12:16 dispy - Running job 112083333192 on 192.168.1.3\n",
      "2018-06-13 16:12:16 dispy - Running job 12 / 112083333192 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:17 dispy - Received reply for job 12 / 112083333192 from 192.168.1.3\n",
      "2018-06-13 16:12:17 dispy - Running job 112083334512 on 192.168.1.3\n",
      "2018-06-13 16:12:17 dispy - Running job 13 / 112083334512 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:17 dispy - Received reply for job 10 / 112083333312 from 192.168.1.3\n",
      "2018-06-13 16:12:17 dispy - Running job 112083334632 on 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:17] Finished batch 10\n",
      "[ 16:12:17] Processing batch 11\n",
      "2018-06-13 16:12:17 dispy - Running job 14 / 112083334632 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:17 dispy - Received reply for job 11 / 112083333552 from 192.168.1.3\n",
      "2018-06-13 16:12:17 dispy - Running job 112083334752 on 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:17] Finished batch 11\n",
      "[ 16:12:17] Processing batch 12\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:17] Finished batch 12\n",
      "[ 16:12:17] Processing batch 13\n",
      "2018-06-13 16:12:17 dispy - Running job 15 / 112083334752 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:18 dispy - Received reply for job 13 / 112083334512 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:18] Finished batch 13\n",
      "[ 16:12:18] Processing batch 14\n",
      "2018-06-13 16:12:18 dispy - Running job 112083334872 on 192.168.1.3\n",
      "2018-06-13 16:12:18 dispy - Running job 16 / 112083334872 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:18 dispy - Received reply for job 14 / 112083334632 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:18] Finished batch 14\n",
      "[ 16:12:18] Processing batch 15\n",
      "2018-06-13 16:12:18 dispy - Running job 112083334992 on 192.168.1.3\n",
      "2018-06-13 16:12:18 dispy - Running job 17 / 112083334992 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:18 dispy - Received reply for job 15 / 112083334752 from 192.168.1.3\n",
      "2018-06-13 16:12:18 dispy - Running job 112083335112 on 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:18] Finished batch 15\n",
      "[ 16:12:18] Processing batch 16\n",
      "2018-06-13 16:12:18 dispy - Running job 18 / 112083335112 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:12:19 dispy - Received reply for job 16 / 112083334872 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:19] Finished batch 16\n",
      "[ 16:12:19] Processing batch 17\n",
      "2018-06-13 16:12:19 dispy - Received reply for job 17 / 112083334992 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:19] Finished batch 17\n",
      "[ 16:12:19] Processing batch 18\n",
      "2018-06-13 16:12:19 dispy - Received reply for job 18 / 112083335112 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 9, in evaluate_arima_model\n",
      "AttributeError: 'ARIMA' object has no attribute 'filter'\n",
      "\n",
      "\n",
      "[ 16:12:19] Finished batch 18\n",
      "[ 16:12:19] Distributed Tuning Finished\n",
      "Best ARIMANone RMSE=inf\n",
      "\n",
      "                           Node |  CPUs |    Jobs |    Sec/Job | Node Time Sec\n",
      "------------------------------------------------------------------------------\n",
      " 192.168.1.3 (minds-imac-1.loca |     3 |      18 |      0.979 |        17.623\n",
      "\n",
      "Total job time: 17.623 sec, wall time: 5.984 sec, speedup: 2.945\n",
      "\n",
      "2018-06-13 16:12:19 dispy - HTTP server waiting for 10 seconds for client updates before quitting\n",
      "2018-06-13 16:12:29 dispy - Closing node 192.168.1.3 for evaluate_arima_model / 1528917108101\n"
     ]
    }
   ],
   "source": [
    "# evaluate parameters\n",
    "p_values = [0,1,2]\n",
    "d_values = [0,1]\n",
    "q_values = [0,1,2]\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "distributed_arima_evaluate_models(evaluate_arima_model,\"arima-oahu-clean\",train_clean_df[target_station], validation_clean_df[target_station], p_values, d_values, q_values)\n",
    "distributed_arima_evaluate_models(evaluate_arima_model,\"arima-oahu-residual\",train_residual_df[target_station], validation_residual_df[target_station], p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testar outros datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ARIMA(0, 0, 0) \n",
      "ARIMA(0, 0, 0) RMSE=0.279\n",
      "Testing ARIMA(0, 0, 1) \n",
      "ARIMA(0, 0, 1) RMSE=0.140\n",
      "Testing ARIMA(0, 0, 2) \n",
      "Invalid model(0, 0, 2) \n",
      "Testing ARIMA(0, 1, 0) \n",
      "ARIMA(0, 1, 0) RMSE=0.034\n",
      "Testing ARIMA(0, 1, 1) \n",
      "ARIMA(0, 1, 1) RMSE=0.019\n",
      "Testing ARIMA(0, 1, 2) \n",
      "Invalid model(0, 1, 2) \n",
      "Testing ARIMA(1, 0, 0) \n",
      "ARIMA(1, 0, 0) RMSE=0.034\n",
      "Testing ARIMA(1, 0, 1) \n",
      "Invalid model(1, 0, 1) \n",
      "Testing ARIMA(1, 0, 2) \n",
      "Invalid model(1, 0, 2) \n",
      "Testing ARIMA(1, 1, 0) \n",
      "ARIMA(1, 1, 0) RMSE=0.011\n",
      "Testing ARIMA(1, 1, 1) \n",
      "ARIMA(1, 1, 1) RMSE=0.009\n",
      "Testing ARIMA(1, 1, 2) \n",
      "ARIMA(1, 1, 2) RMSE=0.010\n",
      "Testing ARIMA(2, 0, 0) \n",
      "Invalid model(2, 0, 0) \n",
      "Testing ARIMA(2, 0, 1) \n",
      "ARIMA(2, 0, 1) RMSE=0.009\n",
      "Testing ARIMA(2, 0, 2) \n",
      "Invalid model(2, 0, 2) \n",
      "Testing ARIMA(2, 1, 0) \n",
      "ARIMA(2, 1, 0) RMSE=0.010\n",
      "Testing ARIMA(2, 1, 1) \n",
      "ARIMA(2, 1, 1) RMSE=0.010\n",
      "Testing ARIMA(2, 1, 2) \n",
      "ARIMA(2, 1, 2) RMSE=0.010\n",
      "Best ARIMA(2, 0, 1) RMSE=0.009\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'autumn_train_clean_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-32ce457d7197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mevaluate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arima-spring-clean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspring_train_clean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspring_validation_clean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arima-autumn-clean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mautumn_train_clean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautumn_validation_clean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mevaluate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arima-winter-clean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwinter_train_clean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinter_validation_clean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mevaluate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arima-summer-residual\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummer_train_residual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummer_validation_residual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'autumn_train_clean_df' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_models(\"arima-spring-clean\",spring_train_clean_df[target_station], spring_validation_clean_df[target_station], p_values, d_values, q_values)\n",
    "evaluate_models(\"arima-autumn-clean\",autumn_train_clean_df[target_station], autumn_validation_clean_df[target_station], p_values, d_values, q_values)\n",
    "evaluate_models(\"arima-winter-clean\",winter_train_clean_df[target_station], winter_validation_clean_df[target_station], p_values, d_values, q_values)\n",
    "\n",
    "evaluate_models(\"arima-summer-residual\",summer_train_residual_df[target_station], summer_validation_residual_df[target_station], p_values, d_values, q_values)\n",
    "evaluate_models(\"arima-spring-residual\",spring_train_residual_df[target_station], spring_validation_residual_df[target_station], p_values, d_values, q_values)\n",
    "evaluate_models(\"arima-autumn-residual\",autumn_train_residual_df[target_station], autumn_validation_residual_df[target_station], p_values, d_values, q_values)\n",
    "evaluate_models(\"arima-winter-residual\",winter_train_residual_df[target_station], winter_validation_residual_df[target_station], p_values, d_values, q_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-13 12:15:33 dispy - Started HTTP server at ('0.0.0.0', 8181)\n",
      "Testing ARIMA(0, 0, 0) \n",
      "2018-06-13 12:15:33 dispy - Running job 120614657264 on 192.168.1.3\n",
      "Testing ARIMA(0, 0, 1) \n",
      "Testing ARIMA(0, 0, 2) \n",
      "2018-06-13 12:15:33 dispy - Running job 120614656664 on 192.168.1.3\n",
      "Testing ARIMA(0, 1, 0) \n",
      "Testing ARIMA(0, 1, 1) \n",
      "2018-06-13 12:15:33 dispy - Running job 120614656544 on 192.168.1.3\n",
      "Testing ARIMA(0, 1, 2) \n",
      "2018-06-13 12:15:33 dispy - Running job 1 / 120614657264 on 192.168.1.3 (busy: 3 / 3)\n",
      "Testing ARIMA(1, 0, 0) \n",
      "Testing ARIMA(1, 0, 1) \n",
      "2018-06-13 12:15:33 dispy - Running job 2 / 120614656664 on 192.168.1.3 (busy: 3 / 3)\n",
      "Testing ARIMA(1, 0, 2) \n",
      "Testing ARIMA(1, 1, 0) \n",
      "Testing ARIMA(1, 1, 1) \n",
      "Testing ARIMA(1, 1, 2) \n",
      "2018-06-13 12:15:33 dispy - Running job 3 / 120614656544 on 192.168.1.3 (busy: 3 / 3)\n",
      "Testing ARIMA(2, 0, 0) \n",
      "Testing ARIMA(2, 0, 1) \n",
      "Testing ARIMA(2, 0, 2) \n",
      "Testing ARIMA(2, 1, 0) \n",
      "Testing ARIMA(2, 1, 1) \n",
      "Testing ARIMA(2, 1, 2) \n",
      "[ 12:15:33] Processing batch 1\n",
      "2018-06-13 12:15:35 dispy - Received reply for job 3 / 120614656544 from 192.168.1.3\n",
      "2018-06-13 12:15:35 dispy - Running job 120614655344 on 192.168.1.3\n",
      "2018-06-13 12:15:35 dispy - Running job 4 / 120614655344 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:15:41 dispy - Received reply for job 1 / 120614657264 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.285\n",
      "2018-06-13 12:15:41 dispy - Running job 120614656064 on 192.168.1.3\n",
      "2018-06-13 12:15:41 dispy - Running job 5 / 120614656064 on 192.168.1.3 (busy: 3 / 3)\n",
      "[ 12:15:41] Finished batch 1\n",
      "[ 12:15:41] Processing batch 2\n",
      "2018-06-13 12:15:45 dispy - Received reply for job 4 / 120614655344 from 192.168.1.3\n",
      "2018-06-13 12:15:45 dispy - Running job 120615067960 on 192.168.1.3\n",
      "2018-06-13 12:15:45 dispy - Running job 6 / 120615067960 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:15:46 dispy - Received reply for job 6 / 120615067960 from 192.168.1.3\n",
      "2018-06-13 12:15:46 dispy - Running job 120615067720 on 192.168.1.3\n",
      "2018-06-13 12:15:46 dispy - Running job 7 / 120615067720 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:16:40 dispy - Received reply for job 7 / 120615067720 from 192.168.1.3\n",
      "2018-06-13 12:16:40 dispy - Running job 120615067840 on 192.168.1.3\n",
      "2018-06-13 12:16:40 dispy - Running job 8 / 120615067840 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:16:42 dispy - Received reply for job 8 / 120615067840 from 192.168.1.3\n",
      "2018-06-13 12:16:42 dispy - Running job 120615068200 on 192.168.1.3\n",
      "2018-06-13 12:16:42 dispy - Running job 9 / 120615068200 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:16:43 dispy - Received reply for job 9 / 120615068200 from 192.168.1.3\n",
      "2018-06-13 12:16:43 dispy - Running job 120615068440 on 192.168.1.3\n",
      "2018-06-13 12:16:43 dispy - Running job 10 / 120615068440 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:17:54 dispy - Received reply for job 10 / 120615068440 from 192.168.1.3\n",
      "2018-06-13 12:17:54 dispy - Running job 120615068560 on 192.168.1.3\n",
      "2018-06-13 12:17:54 dispy - Running job 11 / 120615068560 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:24:15 dispy - Received reply for job 5 / 120614656064 from 192.168.1.3\n",
      "2018-06-13 12:24:15 dispy - Running job 120615068680 on 192.168.1.3\n",
      "2018-06-13 12:24:15 dispy - Running job 12 / 120615068680 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:24:40 dispy - Received reply for job 2 / 120614656664 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.143\n",
      "2018-06-13 12:24:40 dispy - Running job 120615068800 on 192.168.1.3\n",
      "2018-06-13 12:24:40 dispy - Running job 13 / 120615068800 on 192.168.1.3 (busy: 3 / 3)\n",
      "[ 12:24:40] Finished batch 2\n",
      "[ 12:24:40] Processing batch 3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 12:24:40] Finished batch 3\n",
      "[ 12:24:40] Processing batch 4\n",
      "ARIMA(2, 1, 2) RMSE=0.032\n",
      "[ 12:24:40] Finished batch 4\n",
      "[ 12:24:40] Processing batch 5\n",
      "ARIMA(2, 1, 2) RMSE=0.017\n",
      "[ 12:24:40] Finished batch 5\n",
      "[ 12:24:40] Processing batch 6\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 1151, in fit\n",
      "    callback, start_ar_lags, **kwargs)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 12:24:40] Finished batch 6\n",
      "[ 12:24:40] Processing batch 7\n",
      "ARIMA(2, 1, 2) RMSE=0.032\n",
      "[ 12:24:40] Finished batch 7\n",
      "[ 12:24:40] Processing batch 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 12:24:40] Finished batch 8\n",
      "[ 12:24:40] Processing batch 9\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 12:24:40] Finished batch 9\n",
      "[ 12:24:40] Processing batch 10\n",
      "ARIMA(2, 1, 2) RMSE=0.006\n",
      "[ 12:24:40] Finished batch 10\n",
      "[ 12:24:40] Processing batch 11\n",
      "2018-06-13 12:25:00 dispy - Received reply for job 13 / 120615068800 from 192.168.1.3\n",
      "2018-06-13 12:25:00 dispy - Running job 120615068920 on 192.168.1.3\n",
      "2018-06-13 12:25:00 dispy - Running job 14 / 120615068920 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:33:20 dispy - Received reply for job 11 / 120615068560 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.004\n",
      "2018-06-13 12:33:20 dispy - Running job 120615069040 on 192.168.1.3\n",
      "2018-06-13 12:33:20 dispy - Running job 15 / 120615069040 on 192.168.1.3 (busy: 3 / 3)\n",
      "[ 12:33:20] Finished batch 11\n",
      "[ 12:33:20] Processing batch 12\n",
      "2018-06-13 12:39:19 dispy - Received reply for job 12 / 120615068680 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.004\n",
      "2018-06-13 12:39:19 dispy - Running job 120615069160 on 192.168.1.3\n",
      "[ 12:39:19] Finished batch 12\n",
      "[ 12:39:19] Processing batch 13\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 557, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial AR coefficients are not \"\n",
      "ValueError: The computed initial AR coefficients are not stationary\n",
      "You should induce stationarity, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 12:39:19] Finished batch 13\n",
      "[ 12:39:19] Processing batch 14\n",
      "2018-06-13 12:39:19 dispy - Running job 16 / 120615069160 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:48:11 dispy - Received reply for job 16 / 120615069160 from 192.168.1.3\n",
      "2018-06-13 12:48:11 dispy - Running job 120615069280 on 192.168.1.3\n",
      "2018-06-13 12:48:11 dispy - Running job 17 / 120615069280 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 12:55:05 dispy - Received reply for job 14 / 120615068920 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 969, in fit\n",
      "    callback=callback, **kwargs)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py\", line 451, in fit\n",
      "    full_output=full_output)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/base/optimizer.py\", line 184, in _fit\n",
      "    hess=hessian)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/base/optimizer.py\", line 378, in _fit_lbfgs\n",
      "    **extra_kwargs)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 199, in fmin_l_bfgs_b\n",
      "    **opts)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 335, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 280, in func_and_grad\n",
      "    f = fun(x, *args)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\", line 292, in function_wrapper\n",
      "    return function(*(wrapper_args + args))\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py\", line 429, in <lambda>\n",
      "    f = lambda params, *args: -self.loglike(params, *args) / nobs\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 790, in loglike\n",
      "    return self.loglike_kalman(params, set_sigma2)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 800, in loglike_kalman\n",
      "    return KalmanFilter.loglike(params, self, set_sigma2)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/kalmanf/kalmanfilter.py\", line 649, in loglike\n",
      "    R_mat, T_mat)\n",
      "  File \"statsmodels\\tsa\\kalmanf\\kalman_loglike.pyx\", line 342, in statsmodels.tsa.kalmanf.kalman_loglike.kalman_loglike_double (statsmodels/tsa/kalmanf/kalman_loglike.c:6510)\n",
      "  File \"statsmodels\\tsa\\kalmanf\\kalman_loglike.pyx\", line 74, in statsmodels.tsa.kalmanf.kalman_loglike.kalman_filter_double (statsmodels/tsa/kalmanf/kalman_loglike.c:3560)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\", line 1647, in pinv\n",
      "    u, s, vt = svd(a, 0)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\", line 1389, in svd\n",
      "    u, s, vt = gufunc(a, signature=signature, extobj=extobj)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\", line 99, in _raise_linalgerror_svd_nonconvergence\n",
      "    raise LinAlgError(\"SVD did not converge\")\n",
      "numpy.linalg.linalg.LinAlgError: SVD did not converge\n",
      "2018-06-13 12:55:05 dispy - Running job 120615069400 on 192.168.1.3\n",
      "\n",
      "\n",
      "[ 12:55:05] Finished batch 14\n",
      "[ 12:55:05] Processing batch 15\n",
      "2018-06-13 12:55:05 dispy - Running job 18 / 120615069400 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:10:36 dispy - Received reply for job 17 / 120615069280 from 192.168.1.3\n",
      "2018-06-13 13:18:13 dispy - Received reply for job 18 / 120615069400 from 192.168.1.3\n",
      "2018-06-13 13:38:29 dispy - Received reply for job 15 / 120615069040 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.004\n",
      "[ 13:38:29] Finished batch 15\n",
      "[ 13:38:29] Processing batch 16\n",
      "ARIMA(2, 1, 2) RMSE=0.003\n",
      "[ 13:38:29] Finished batch 16\n",
      "[ 13:38:29] Processing batch 17\n",
      "ARIMA(2, 1, 2) RMSE=0.003\n",
      "[ 13:38:29] Finished batch 17\n",
      "[ 13:38:29] Processing batch 18\n",
      "ARIMA(2, 1, 2) RMSE=0.003\n",
      "[ 13:38:29] Finished batch 18\n",
      "[ 13:38:29] Distributed Tuning Finished\n",
      "Best ARIMA(2, 1, 2) RMSE=0.003\n",
      "\n",
      "                           Node |  CPUs |    Jobs |    Sec/Job | Node Time Sec\n",
      "------------------------------------------------------------------------------\n",
      " 192.168.1.3 (minds-imac-1.loca |     3 |      18 |    668.815 |     12038.671\n",
      "\n",
      "Total job time: 12038.671 sec, wall time: 4976.183 sec, speedup: 2.419\n",
      "\n",
      "2018-06-13 13:38:29 dispy - HTTP server waiting for 10 seconds for client updates before quitting\n",
      "2018-06-13 13:38:40 dispy - Closing node 192.168.1.3 for evaluate_arima_model / 1528898883427\n",
      "2018-06-13 13:38:40 dispy - Started HTTP server at ('0.0.0.0', 8181)\n",
      "Testing ARIMA(0, 0, 0) \n",
      "2018-06-13 13:38:40 dispy - Running job 120614657384 on 192.168.1.3\n",
      "Testing ARIMA(0, 0, 1) \n",
      "Testing ARIMA(0, 0, 2) \n",
      "Testing ARIMA(0, 1, 0) \n",
      "2018-06-13 13:38:40 dispy - Running job 120614656544 on 192.168.1.3\n",
      "2018-06-13 13:38:40 dispy - Running job 120614657864 on 192.168.1.3\n",
      "Testing ARIMA(0, 1, 1) 2018-06-13 13:38:40 dispy - Running job 1 / 120614657384 on 192.168.1.3 (busy: 3 / 3)\n",
      "\n",
      "Testing ARIMA(0, 1, 2) \n",
      "Testing ARIMA(1, 0, 0) \n",
      "Testing ARIMA(1, 0, 1) \n",
      "Testing ARIMA(1, 0, 2) \n",
      "Testing ARIMA(1, 1, 0) \n",
      "2018-06-13 13:38:40 dispy - Running job 2 / 120614656544 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:38:40 dispy - Running job 3 / 120614657864 on 192.168.1.3 (busy: 3 / 3)\n",
      "Testing ARIMA(1, 1, 1) \n",
      "Testing ARIMA(1, 1, 2) \n",
      "Testing ARIMA(2, 0, 0) \n",
      "Testing ARIMA(2, 0, 1) \n",
      "Testing ARIMA(2, 0, 2) \n",
      "Testing ARIMA(2, 1, 0) \n",
      "Testing ARIMA(2, 1, 1) \n",
      "Testing ARIMA(2, 1, 2) \n",
      "[ 13:38:40] Processing batch 1\n",
      "2018-06-13 13:38:43 dispy - Received reply for job 3 / 120614657864 from 192.168.1.3\n",
      "2018-06-13 13:38:43 dispy - Running job 120614656184 on 192.168.1.3\n",
      "2018-06-13 13:38:43 dispy - Running job 4 / 120614656184 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:38:50 dispy - Received reply for job 1 / 120614657384 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.3022018-06-13 13:38:50 dispy - Running job 120615069280 on 192.168.1.3\n",
      "\n",
      "[ 13:38:50] Finished batch 1\n",
      "[ 13:38:50] Processing batch 2\n",
      "2018-06-13 13:38:50 dispy - Running job 5 / 120615069280 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:38:54 dispy - Received reply for job 4 / 120614656184 from 192.168.1.3\n",
      "2018-06-13 13:38:54 dispy - Running job 120615068920 on 192.168.1.3\n",
      "2018-06-13 13:38:54 dispy - Running job 6 / 120615068920 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:38:55 dispy - Received reply for job 6 / 120615068920 from 192.168.1.3\n",
      "2018-06-13 13:38:55 dispy - Running job 120615069160 on 192.168.1.3\n",
      "2018-06-13 13:38:55 dispy - Running job 7 / 120615069160 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:39:54 dispy - Received reply for job 7 / 120615069160 from 192.168.1.3\n",
      "2018-06-13 13:39:54 dispy - Running job 120615068680 on 192.168.1.3\n",
      "2018-06-13 13:39:54 dispy - Running job 8 / 120615068680 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:39:56 dispy - Received reply for job 8 / 120615068680 from 192.168.1.3\n",
      "2018-06-13 13:39:56 dispy - Running job 120615068560 on 192.168.1.3\n",
      "2018-06-13 13:39:56 dispy - Running job 9 / 120615068560 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:39:58 dispy - Received reply for job 9 / 120615068560 from 192.168.1.3\n",
      "2018-06-13 13:39:58 dispy - Running job 120615068800 on 192.168.1.3\n",
      "2018-06-13 13:39:58 dispy - Running job 10 / 120615068800 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:41:15 dispy - Received reply for job 10 / 120615068800 from 192.168.1.3\n",
      "2018-06-13 13:41:15 dispy - Running job 120615068440 on 192.168.1.3\n",
      "2018-06-13 13:41:15 dispy - Running job 11 / 120615068440 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:46:27 dispy - Received reply for job 2 / 120614656544 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.152\n",
      "2018-06-13 13:46:27 dispy - Running job 120615068200 on 192.168.1.3\n",
      "2018-06-13 13:46:27 dispy - Running job 12 / 120615068200 on 192.168.1.3 (busy: 3 / 3)\n",
      "[ 13:46:27] Finished batch 2\n",
      "[ 13:46:27] Processing batch 3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 13:46:27] Finished batch 3\n",
      "[ 13:46:27] Processing batch 4\n",
      "ARIMA(2, 1, 2) RMSE=0.034\n",
      "[ 13:46:27] Finished batch 4\n",
      "[ 13:46:27] Processing batch 5\n",
      "2018-06-13 13:46:37 dispy - Received reply for job 5 / 120615069280 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.0182018-06-13 13:46:37 dispy - Running job 120615067840 on 192.168.1.3\n",
      "\n",
      "[ 13:46:37] Finished batch 5\n",
      "[ 13:46:37] Processing batch 6\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 1151, in fit\n",
      "    callback, start_ar_lags, **kwargs)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 13:46:37] Finished batch 6\n",
      "[ 13:46:37] Processing batch 7\n",
      "ARIMA(2, 1, 2) RMSE=0.034\n",
      "[ 13:46:37] Finished batch 7\n",
      "[ 13:46:37] Processing batch 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 13:46:37] Finished batch 8\n",
      "[ 13:46:37] Processing batch 9\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 13:46:37] Finished batch 9\n",
      "[ 13:46:37] Processing batch 10\n",
      "ARIMA(2, 1, 2) RMSE=0.006\n",
      "2018-06-13 13:46:37 dispy - Running job 13 / 120615067840 on 192.168.1.3 (busy: 3 / 3)\n",
      "[ 13:46:37] Finished batch 10\n",
      "[ 13:46:37] Processing batch 11\n",
      "2018-06-13 13:47:00 dispy - Received reply for job 13 / 120615067840 from 192.168.1.3\n",
      "2018-06-13 13:47:00 dispy - Running job 120615067720 on 192.168.1.3\n",
      "2018-06-13 13:47:00 dispy - Running job 14 / 120615067720 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 13:58:38 dispy - Received reply for job 11 / 120615068440 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.005\n",
      "2018-06-13 13:58:38 dispy - Running job 120615067960 on 192.168.1.3\n",
      "[ 13:58:38] Finished batch 11\n",
      "[ 13:58:38] Processing batch 12\n",
      "2018-06-13 13:58:38 dispy - Running job 15 / 120615067960 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 14:03:17 dispy - Received reply for job 12 / 120615068200 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.004\n",
      "2018-06-13 14:03:17 dispy - Running job 120615068080 on 192.168.1.3\n",
      "[ 14:03:17] Finished batch 12\n",
      "[ 14:03:17] Processing batch 13\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 557, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial AR coefficients are not \"\n",
      "ValueError: The computed initial AR coefficients are not stationary\n",
      "You should induce stationarity, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 14:03:17] Finished batch 13\n",
      "[ 14:03:17] Processing batch 14\n",
      "2018-06-13 14:03:17 dispy - Running job 16 / 120615068080 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 14:12:08 dispy - Received reply for job 16 / 120615068080 from 192.168.1.3\n",
      "2018-06-13 14:12:08 dispy - Running job 120615069520 on 192.168.1.3\n",
      "2018-06-13 14:12:08 dispy - Running job 17 / 120615069520 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 14:33:43 dispy - Received reply for job 17 / 120615069520 from 192.168.1.3\n",
      "2018-06-13 14:33:43 dispy - Running job 120615069640 on 192.168.1.3\n",
      "2018-06-13 14:33:43 dispy - Running job 18 / 120615069640 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 14:42:34 dispy - Received reply for job 14 / 120615067720 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.004\n",
      "[ 14:42:34] Finished batch 14\n",
      "[ 14:42:34] Processing batch 15\n",
      "2018-06-13 14:58:06 dispy - Received reply for job 18 / 120615069640 from 192.168.1.3\n",
      "2018-06-13 15:01:53 dispy - Received reply for job 15 / 120615067960 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.004\n",
      "[ 15:01:53] Finished batch 15\n",
      "[ 15:01:53] Processing batch 16\n",
      "ARIMA(2, 1, 2) RMSE=0.004\n",
      "[ 15:01:53] Finished batch 16\n",
      "[ 15:01:53] Processing batch 17\n",
      "ARIMA(2, 1, 2) RMSE=0.004\n",
      "[ 15:01:53] Finished batch 17\n",
      "[ 15:01:53] Processing batch 18\n",
      "ARIMA(2, 1, 2) RMSE=0.004\n",
      "[ 15:01:53] Finished batch 18\n",
      "[ 15:01:53] Distributed Tuning Finished\n",
      "Best ARIMA(2, 1, 2) RMSE=0.004\n",
      "\n",
      "                           Node |  CPUs |    Jobs |    Sec/Job | Node Time Sec\n",
      "------------------------------------------------------------------------------\n",
      " 192.168.1.3 (minds-imac-1.loca |     3 |      18 |    755.216 |     13593.882\n",
      "\n",
      "Total job time: 13593.882 sec, wall time: 4993.805 sec, speedup: 2.722\n",
      "\n",
      "2018-06-13 15:01:53 dispy - HTTP server waiting for 10 seconds for client updates before quitting\n",
      "2018-06-13 15:02:03 dispy - Closing node 192.168.1.3 for evaluate_arima_model / 1528898883428\n",
      "2018-06-13 15:02:04 dispy - Started HTTP server at ('0.0.0.0', 8181)\n",
      "Testing ARIMA(0, 0, 0) \n",
      "2018-06-13 15:02:04 dispy - Running job 120614657264 on 192.168.1.3\n",
      "Testing ARIMA(0, 0, 1) \n",
      "Testing ARIMA(0, 0, 2) \n",
      "2018-06-13 15:02:04 dispy - Running job 120615067960 on 192.168.1.3\n",
      "Testing ARIMA(0, 1, 0) \n",
      "2018-06-13 15:02:04 dispy - Running job 120615067720 on 192.168.1.3\n",
      "2018-06-13 15:02:04 dispy - Running job 1 / 120614657264 on 192.168.1.3 (busy: 3 / 3)\n",
      "Testing ARIMA(0, 1, 1) \n",
      "Testing ARIMA(0, 1, 2) \n",
      "Testing ARIMA(1, 0, 0) \n",
      "2018-06-13 15:02:04 dispy - Running job 2 / 120615067960 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:02:04 dispy - Running job 3 / 120615067720 on 192.168.1.3 (busy: 3 / 3)\n",
      "Testing ARIMA(1, 0, 1) \n",
      "Testing ARIMA(1, 0, 2) \n",
      "Testing ARIMA(1, 1, 0) \n",
      "Testing ARIMA(1, 1, 1) \n",
      "Testing ARIMA(1, 1, 2) \n",
      "Testing ARIMA(2, 0, 0) \n",
      "Testing ARIMA(2, 0, 1) \n",
      "Testing ARIMA(2, 0, 2) \n",
      "Testing ARIMA(2, 1, 0) \n",
      "Testing ARIMA(2, 1, 1) \n",
      "Testing ARIMA(2, 1, 2) \n",
      "[ 15:02:04] Processing batch 1\n",
      "2018-06-13 15:02:16 dispy - Received reply for job 3 / 120615067720 from 192.168.1.3\n",
      "2018-06-13 15:02:16 dispy - Running job 120615068080 on 192.168.1.3\n",
      "2018-06-13 15:02:16 dispy - Running job 4 / 120615068080 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:02:23 dispy - Received reply for job 1 / 120614657264 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.297\n",
      "2018-06-13 15:02:23 dispy - Running job 120615068440 on 192.168.1.3\n",
      "[ 15:02:23] Finished batch 1\n",
      "[ 15:02:23] Processing batch 2\n",
      "2018-06-13 15:02:23 dispy - Running job 5 / 120615068440 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:02:28 dispy - Received reply for job 4 / 120615068080 from 192.168.1.3\n",
      "2018-06-13 15:02:28 dispy - Running job 120615067840 on 192.168.1.3\n",
      "2018-06-13 15:02:28 dispy - Running job 6 / 120615067840 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:02:30 dispy - Received reply for job 6 / 120615067840 from 192.168.1.3\n",
      "2018-06-13 15:02:30 dispy - Running job 120615069280 on 192.168.1.3\n",
      "2018-06-13 15:02:30 dispy - Running job 7 / 120615069280 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:03:26 dispy - Received reply for job 7 / 120615069280 from 192.168.1.3\n",
      "2018-06-13 15:03:26 dispy - Running job 120615069400 on 192.168.1.3\n",
      "2018-06-13 15:03:26 dispy - Running job 8 / 120615069400 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:03:29 dispy - Received reply for job 8 / 120615069400 from 192.168.1.3\n",
      "2018-06-13 15:03:29 dispy - Running job 120615068800 on 192.168.1.3\n",
      "2018-06-13 15:03:29 dispy - Running job 9 / 120615068800 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:03:30 dispy - Received reply for job 9 / 120615068800 from 192.168.1.3\n",
      "2018-06-13 15:03:30 dispy - Running job 120615068560 on 192.168.1.3\n",
      "2018-06-13 15:03:30 dispy - Running job 10 / 120615068560 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:04:46 dispy - Received reply for job 10 / 120615068560 from 192.168.1.3\n",
      "2018-06-13 15:04:46 dispy - Running job 120615068680 on 192.168.1.3\n",
      "2018-06-13 15:04:46 dispy - Running job 11 / 120615068680 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:10:04 dispy - Received reply for job 2 / 120615067960 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.149\n",
      "2018-06-13 15:10:04 dispy - Running job 120615069160 on 192.168.1.3\n",
      "[ 15:10:04] Finished batch 2\n",
      "[ 15:10:04] Processing batch 32018-06-13 15:10:04 dispy - Running job 12 / 120615069160 on 192.168.1.3 (busy: 3 / 3)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 15:10:04] Finished batch 3\n",
      "[ 15:10:04] Processing batch 4\n",
      "ARIMA(2, 1, 2) RMSE=0.032\n",
      "[ 15:10:04] Finished batch 4\n",
      "[ 15:10:04] Processing batch 5\n",
      "2018-06-13 15:10:27 dispy - Received reply for job 5 / 120615068440 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.017\n",
      "2018-06-13 15:10:27 dispy - Running job 120615068920 on 192.168.1.3\n",
      "[ 15:10:27] Finished batch 5\n",
      "[ 15:10:27] Processing batch 6\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 1151, in fit\n",
      "    callback, start_ar_lags, **kwargs)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 15:10:27] Finished batch 6\n",
      "[ 15:10:27] Processing batch 7\n",
      "ARIMA(2, 1, 2) RMSE=0.032\n",
      "2018-06-13 15:10:27 dispy - Running job 13 / 120615068920 on 192.168.1.3 (busy: 3 / 3)\n",
      "[ 15:10:27] Finished batch 7\n",
      "[ 15:10:27] Processing batch 8\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 15:10:27] Finished batch 8\n",
      "[ 15:10:27] Processing batch 9\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 564, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial MA coefficients are not \"\n",
      "ValueError: The computed initial MA coefficients are not invertible\n",
      "You should induce invertibility, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 15:10:27] Finished batch 9\n",
      "[ 15:10:27] Processing batch 10\n",
      "ARIMA(2, 1, 2) RMSE=0.006\n",
      "[ 15:10:27] Finished batch 10\n",
      "[ 15:10:27] Processing batch 11\n",
      "2018-06-13 15:10:43 dispy - Received reply for job 13 / 120615068920 from 192.168.1.3\n",
      "2018-06-13 15:10:43 dispy - Running job 120615069040 on 192.168.1.3\n",
      "2018-06-13 15:10:43 dispy - Running job 14 / 120615069040 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:22:19 dispy - Received reply for job 11 / 120615068680 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.004\n",
      "2018-06-13 15:22:19 dispy - Running job 120615069760 on 192.168.1.3\n",
      "2018-06-13 15:22:19 dispy - Running job 15 / 120615069760 on 192.168.1.3 (busy: 3 / 3)\n",
      "[ 15:22:19] Finished batch 11\n",
      "[ 15:22:19] Processing batch 12\n",
      "2018-06-13 15:27:41 dispy - Received reply for job 12 / 120615069160 from 192.168.1.3\n",
      "ARIMA(2, 1, 2) RMSE=0.003\n",
      "2018-06-13 15:27:41 dispy - Running job 120615069880 on 192.168.1.3\n",
      "[ 15:27:41] Finished batch 12\n",
      "[ 15:27:41] Processing batch 13\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 12, in evaluate_arima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 956, in fit\n",
      "    start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 578, in _fit_start_params\n",
      "    start_params = self._fit_start_params_hr(order, start_ar_lags)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/arima_model.py\", line 557, in _fit_start_params_hr\n",
      "    raise ValueError(\"The computed initial AR coefficients are not \"\n",
      "ValueError: The computed initial AR coefficients are not stationary\n",
      "You should induce stationarity, choose a different model order, or you can\n",
      "pass your own start_params.\n",
      "\n",
      "\n",
      "[ 15:27:41] Finished batch 13\n",
      "[ 15:27:41] Processing batch 14\n",
      "2018-06-13 15:27:41 dispy - Running job 16 / 120615069880 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:37:17 dispy - Received reply for job 16 / 120615069880 from 192.168.1.3\n",
      "2018-06-13 15:37:17 dispy - Running job 120615070000 on 192.168.1.3\n",
      "2018-06-13 15:37:17 dispy - Running job 17 / 120615070000 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 15:59:21 dispy - Received reply for job 17 / 120615070000 from 192.168.1.3\n",
      "2018-06-13 15:59:21 dispy - Running job 120615070120 on 192.168.1.3\n",
      "2018-06-13 15:59:21 dispy - Running job 18 / 120615070120 on 192.168.1.3 (busy: 3 / 3)\n"
     ]
    }
   ],
   "source": [
    "distributed_arima_evaluate_models(evaluate_arima_model,\"arima-spring-clean\",spring_train_clean_df[target_station], spring_validation_clean_df[target_station], p_values, d_values, q_values)\n",
    "distributed_arima_evaluate_models(evaluate_arima_model,\"arima-autumn-clean\",autumn_train_clean_df[target_station], autumn_validation_clean_df[target_station], p_values, d_values, q_values)\n",
    "distributed_arima_evaluate_models(evaluate_arima_model,\"arima-winter-clean\",winter_train_clean_df[target_station], winter_validation_clean_df[target_station], p_values, d_values, q_values)\n",
    "\n",
    "distributed_arima_evaluate_models(evaluate_arima_model,\"arima-summer-residual\",summer_train_residual_df[target_station], summer_validation_residual_df[target_station], p_values, d_values, q_values)\n",
    "distributed_arima_evaluate_models(evaluate_arima_model,\"arima-spring-residual\",spring_train_residual_df[target_station], spring_validation_residual_df[target_station], p_values, d_values, q_values)\n",
    "distributed_arima_evaluate_models(evaluate_arima_model,\"arima-autumn-residual\",autumn_train_residual_df[target_station], autumn_validation_residual_df[target_station], p_values, d_values, q_values)\n",
    "distributed_arima_evaluate_models(evaluate_arima_model,\"arima-winter-residual\",winter_train_residual_df[target_station], winter_validation_residual_df[target_station], p_values, d_values, q_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_sarima_model(train, validation, arima_order, sarima_order):\n",
    "    \n",
    "    whole_data = train.append(validation)\n",
    "    test_data = validation\n",
    "    \n",
    "    training_mod = SARIMAX(whole_data.values, order=arima_order, seasonal_order=sarima_order, disp=True)\n",
    "    training_res = training_mod.fit()\n",
    "    \n",
    "    mod = SARIMAX(whole_data.values, order=arima_order, seasonal_order=sarima_order)\n",
    "    res = mod.filter(training_res.params)\n",
    "    \n",
    "    insample = res.predict()\n",
    "    wlen = len(whole_data)\n",
    "    tlen = len(test_data)\n",
    "\n",
    "    predictions = insample[wlen-tlen:]    \n",
    "    # calculate out of sample error\n",
    "    error = math.sqrt(mean_squared_error(validation, predictions))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "import sys\n",
    "def evaluate_sarima_models(test_name, train_df, validation_df, parameters_list, period_length):\n",
    "\n",
    "    sarima_results = pd.DataFrame(columns=['Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "    for param in parameters_list:\n",
    "        arima_order = (param[0],param[1],param[2])\n",
    "        sarima_order = (param[3],param[4],param[5],period_length)\n",
    "        print('Testing SARIMA%s %s ' % (str(arima_order),str(sarima_order)))\n",
    "        try:\n",
    "            rmse = evaluate_sarima_model(train_df, validation_df, arima_order, sarima_order)\n",
    "            if rmse < best_score:\n",
    "                best_score, best_cfg = rmse, param\n",
    "\n",
    "            res = {'Order' : str(param) ,'RMSE' : rmse}\n",
    "            print('SARIMA%s %s RMSE=%.3f' % (str(arima_order),str(sarima_order),rmse))\n",
    "            sarima_results = sarima_results.append(res, ignore_index=True)\n",
    "            sarima_results.to_csv(test_name+\".csv\")\n",
    "        except:\n",
    "            print(sys.exc_info())\n",
    "            print('Invalid model%s %s ' % (str(arima_order),str(sarima_order)))\n",
    "            continue\n",
    "    print('Best SARIMA%s RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-13 16:49:13 dispy - Removing node 192.168.1.3\n",
      "2018-06-13 16:49:23 dispy - Discovered 192.168.1.3:51348 (minds-imac-1.local) with 3 cpus\n"
     ]
    }
   ],
   "source": [
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def distributed_sarima_evaluate_models(eval_method, test_name, train_df, validation_df, parameters_list, period_length):\n",
    "\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    method = eval_method\n",
    "    nodes=['192.168.1.3']\n",
    "    cluster, http_server = start_dispy_cluster(method, nodes)\n",
    "    jobs = []\n",
    "    job_count = 1\n",
    "\n",
    "    sarima_results = pd.DataFrame(columns=['Order','RMSE'])\n",
    "\n",
    "    for param in parameters_list:\n",
    "        arima_order = (param[0],param[1],param[2])\n",
    "        sarima_order = (param[3],param[4],param[5],period_length)\n",
    "        \n",
    "        print('Testing SARIMA%s %s ' % (str(arima_order),str(sarima_order)))\n",
    "        job = cluster.submit(train_df, validation_df, arima_order,sarima_order)\n",
    "        job.id = job_count  # associate an ID to identify jobs (if needed later)\n",
    "        jobs.append(job)\n",
    "        job_count += 1\n",
    "                \n",
    "    for job in jobs:\n",
    "        print(\"[{0: %H:%M:%S}] Processing batch \".format(datetime.datetime.now()) + str(job.id))\n",
    "        rmse = job()\n",
    "        if job.status == dispy.DispyJob.Finished and rmse is not None:\n",
    "            if rmse < best_score:\n",
    "                best_score, best_cfg = rmse, param\n",
    "\n",
    "            res = {'Order' : str(param) ,'RMSE' : rmse}\n",
    "            print('SARIMA%s %s RMSE=%.3f' % (str(arima_order),str(sarima_order),rmse))\n",
    "            sarima_results = sarima_results.append(res, ignore_index=True)\n",
    "            sarima_results.to_csv(test_name+\".csv\")\n",
    "        else:\n",
    "            print(job.exception)\n",
    "            print(job.stdout)\n",
    "\n",
    "        print(\"[{0: %H:%M:%S}] Finished batch \".format(datetime.datetime.now()) + str(job.id))\n",
    "\n",
    "    print(\"[{0: %H:%M:%S}] Distributed Tuning Finished\".format(datetime.datetime.now()))            \n",
    "    print('Best SARIMA%s RMSE=%.3f' % (best_cfg, best_score))\n",
    "    \n",
    "    stop_dispy_cluster(cluster, http_server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-13 16:50:33 dispy - Started HTTP server at ('0.0.0.0', 8181)\n",
      "Testing SARIMA(0, 0, 0) (0, 0, 0, 61) \n",
      "2018-06-13 16:50:33 dispy - Running job 112204522744 on 192.168.1.3\n",
      "Testing SARIMA(0, 0, 0) (0, 0, 1, 61) \n",
      "Testing SARIMA(0, 0, 0) (0, 1, 0, 61) \n",
      "2018-06-13 16:50:33 dispy - Running job 112204523104 on 192.168.1.3\n",
      "Testing SARIMA(0, 0, 0) (0, 1, 1, 61) \n",
      "Testing SARIMA(0, 0, 0) (1, 0, 0, 61) \n",
      "2018-06-13 16:50:33 dispy - Running job 112204522984 on 192.168.1.3\n",
      "Testing SARIMA(0, 0, 0) (1, 0, 1, 61) \n",
      "2018-06-13 16:50:33 dispy - Running job 1 / 112204522744 on 192.168.1.3 (busy: 3 / 3)\n",
      "Testing SARIMA(0, 0, 0) (1, 1, 0, 61) \n",
      "Testing SARIMA(0, 0, 0) (1, 1, 1, 61) \n",
      "Testing SARIMA(0, 0, 1) (0, 0, 0, 61) 2018-06-13 16:50:33 dispy - Running job 2 / 112204523104 on 192.168.1.3 (busy: 3 / 3)\n",
      "\n",
      "Testing SARIMA(0, 0, 1) (0, 0, 1, 61) \n",
      "Testing SARIMA(0, 0, 1) (0, 1, 0, 61) \n",
      "Testing SARIMA(0, 0, 1) (0, 1, 1, 61) \n",
      "Testing SARIMA(0, 0, 1) (1, 0, 0, 61) \n",
      "2018-06-13 16:50:33 dispy - Running job 3 / 112204522984 on 192.168.1.3 (busy: 3 / 3)\n",
      "Testing SARIMA(0, 0, 1) (1, 0, 1, 61) \n",
      "Testing SARIMA(0, 0, 1) (1, 1, 0, 61) \n",
      "Testing SARIMA(0, 0, 1) (1, 1, 1, 61) \n",
      "Testing SARIMA(0, 0, 2) (0, 0, 0, 61) \n",
      "Testing SARIMA(0, 0, 2) (0, 0, 1, 61) \n",
      "Testing SARIMA(0, 0, 2) (0, 1, 0, 61) \n",
      "Testing SARIMA(0, 0, 2) (0, 1, 1, 61) \n",
      "Testing SARIMA(0, 0, 2) (1, 0, 0, 61) \n",
      "Testing SARIMA(0, 0, 2) (1, 0, 1, 61) \n",
      "Testing SARIMA(0, 0, 2) (1, 1, 0, 61) \n",
      "Testing SARIMA(0, 0, 2) (1, 1, 1, 61) \n",
      "Testing SARIMA(0, 1, 0) (0, 0, 0, 61) \n",
      "Testing SARIMA(0, 1, 0) (0, 0, 1, 61) \n",
      "Testing SARIMA(0, 1, 0) (0, 1, 0, 61) \n",
      "Testing SARIMA(0, 1, 0) (0, 1, 1, 61) \n",
      "Testing SARIMA(0, 1, 0) (1, 0, 0, 61) \n",
      "Testing SARIMA(0, 1, 0) (1, 0, 1, 61) \n",
      "Testing SARIMA(0, 1, 0) (1, 1, 0, 61) \n",
      "Testing SARIMA(0, 1, 0) (1, 1, 1, 61) \n",
      "Testing SARIMA(0, 1, 1) (0, 0, 0, 61) \n",
      "Testing SARIMA(0, 1, 1) (0, 0, 1, 61) \n",
      "Testing SARIMA(0, 1, 1) (0, 1, 0, 61) \n",
      "Testing SARIMA(0, 1, 1) (0, 1, 1, 61) \n",
      "Testing SARIMA(0, 1, 1) (1, 0, 0, 61) \n",
      "Testing SARIMA(0, 1, 1) (1, 0, 1, 61) \n",
      "Testing SARIMA(0, 1, 1) (1, 1, 0, 61) \n",
      "Testing SARIMA(0, 1, 1) (1, 1, 1, 61) \n",
      "Testing SARIMA(0, 1, 2) (0, 0, 0, 61) \n",
      "Testing SARIMA(0, 1, 2) (0, 0, 1, 61) \n",
      "Testing SARIMA(0, 1, 2) (0, 1, 0, 61) \n",
      "Testing SARIMA(0, 1, 2) (0, 1, 1, 61) \n",
      "Testing SARIMA(0, 1, 2) (1, 0, 0, 61) \n",
      "Testing SARIMA(0, 1, 2) (1, 0, 1, 61) \n",
      "Testing SARIMA(0, 1, 2) (1, 1, 0, 61) \n",
      "Testing SARIMA(0, 1, 2) (1, 1, 1, 61) \n",
      "Testing SARIMA(1, 0, 0) (0, 0, 0, 61) \n",
      "Testing SARIMA(1, 0, 0) (0, 0, 1, 61) \n",
      "Testing SARIMA(1, 0, 0) (0, 1, 0, 61) \n",
      "Testing SARIMA(1, 0, 0) (0, 1, 1, 61) \n",
      "Testing SARIMA(1, 0, 0) (1, 0, 0, 61) \n",
      "Testing SARIMA(1, 0, 0) (1, 0, 1, 61) \n",
      "Testing SARIMA(1, 0, 0) (1, 1, 0, 61) \n",
      "Testing SARIMA(1, 0, 0) (1, 1, 1, 61) \n",
      "Testing SARIMA(1, 0, 1) (0, 0, 0, 61) \n",
      "Testing SARIMA(1, 0, 1) (0, 0, 1, 61) \n",
      "Testing SARIMA(1, 0, 1) (0, 1, 0, 61) \n",
      "Testing SARIMA(1, 0, 1) (0, 1, 1, 61) \n",
      "Testing SARIMA(1, 0, 1) (1, 0, 0, 61) \n",
      "Testing SARIMA(1, 0, 1) (1, 0, 1, 61) \n",
      "Testing SARIMA(1, 0, 1) (1, 1, 0, 61) \n",
      "Testing SARIMA(1, 0, 1) (1, 1, 1, 61) \n",
      "Testing SARIMA(1, 0, 2) (0, 0, 0, 61) \n",
      "Testing SARIMA(1, 0, 2) (0, 0, 1, 61) \n",
      "Testing SARIMA(1, 0, 2) (0, 1, 0, 61) \n",
      "Testing SARIMA(1, 0, 2) (0, 1, 1, 61) \n",
      "Testing SARIMA(1, 0, 2) (1, 0, 0, 61) \n",
      "Testing SARIMA(1, 0, 2) (1, 0, 1, 61) \n",
      "Testing SARIMA(1, 0, 2) (1, 1, 0, 61) \n",
      "Testing SARIMA(1, 0, 2) (1, 1, 1, 61) \n",
      "Testing SARIMA(1, 1, 0) (0, 0, 0, 61) \n",
      "Testing SARIMA(1, 1, 0) (0, 0, 1, 61) \n",
      "Testing SARIMA(1, 1, 0) (0, 1, 0, 61) \n",
      "Testing SARIMA(1, 1, 0) (0, 1, 1, 61) \n",
      "Testing SARIMA(1, 1, 0) (1, 0, 0, 61) \n",
      "Testing SARIMA(1, 1, 0) (1, 0, 1, 61) \n",
      "Testing SARIMA(1, 1, 0) (1, 1, 0, 61) \n",
      "Testing SARIMA(1, 1, 0) (1, 1, 1, 61) \n",
      "Testing SARIMA(1, 1, 1) (0, 0, 0, 61) \n",
      "Testing SARIMA(1, 1, 1) (0, 0, 1, 61) \n",
      "Testing SARIMA(1, 1, 1) (0, 1, 0, 61) \n",
      "Testing SARIMA(1, 1, 1) (0, 1, 1, 61) \n",
      "Testing SARIMA(1, 1, 1) (1, 0, 0, 61) \n",
      "Testing SARIMA(1, 1, 1) (1, 0, 1, 61) \n",
      "Testing SARIMA(1, 1, 1) (1, 1, 0, 61) \n",
      "Testing SARIMA(1, 1, 1) (1, 1, 1, 61) \n",
      "Testing SARIMA(1, 1, 2) (0, 0, 0, 61) \n",
      "Testing SARIMA(1, 1, 2) (0, 0, 1, 61) \n",
      "Testing SARIMA(1, 1, 2) (0, 1, 0, 61) \n",
      "Testing SARIMA(1, 1, 2) (0, 1, 1, 61) \n",
      "Testing SARIMA(1, 1, 2) (1, 0, 0, 61) \n",
      "Testing SARIMA(1, 1, 2) (1, 0, 1, 61) \n",
      "Testing SARIMA(1, 1, 2) (1, 1, 0, 61) \n",
      "Testing SARIMA(1, 1, 2) (1, 1, 1, 61) \n",
      "Testing SARIMA(2, 0, 0) (0, 0, 0, 61) \n",
      "Testing SARIMA(2, 0, 0) (0, 0, 1, 61) \n",
      "Testing SARIMA(2, 0, 0) (0, 1, 0, 61) \n",
      "Testing SARIMA(2, 0, 0) (0, 1, 1, 61) \n",
      "Testing SARIMA(2, 0, 0) (1, 0, 0, 61) \n",
      "Testing SARIMA(2, 0, 0) (1, 0, 1, 61) \n",
      "Testing SARIMA(2, 0, 0) (1, 1, 0, 61) \n",
      "Testing SARIMA(2, 0, 0) (1, 1, 1, 61) \n",
      "Testing SARIMA(2, 0, 1) (0, 0, 0, 61) \n",
      "Testing SARIMA(2, 0, 1) (0, 0, 1, 61) \n",
      "Testing SARIMA(2, 0, 1) (0, 1, 0, 61) \n",
      "Testing SARIMA(2, 0, 1) (0, 1, 1, 61) \n",
      "Testing SARIMA(2, 0, 1) (1, 0, 0, 61) \n",
      "Testing SARIMA(2, 0, 1) (1, 0, 1, 61) \n",
      "Testing SARIMA(2, 0, 1) (1, 1, 0, 61) \n",
      "Testing SARIMA(2, 0, 1) (1, 1, 1, 61) \n",
      "Testing SARIMA(2, 0, 2) (0, 0, 0, 61) \n",
      "Testing SARIMA(2, 0, 2) (0, 0, 1, 61) \n",
      "Testing SARIMA(2, 0, 2) (0, 1, 0, 61) \n",
      "Testing SARIMA(2, 0, 2) (0, 1, 1, 61) \n",
      "Testing SARIMA(2, 0, 2) (1, 0, 0, 61) \n",
      "Testing SARIMA(2, 0, 2) (1, 0, 1, 61) \n",
      "Testing SARIMA(2, 0, 2) (1, 1, 0, 61) \n",
      "Testing SARIMA(2, 0, 2) (1, 1, 1, 61) \n",
      "Testing SARIMA(2, 1, 0) (0, 0, 0, 61) \n",
      "Testing SARIMA(2, 1, 0) (0, 0, 1, 61) \n",
      "Testing SARIMA(2, 1, 0) (0, 1, 0, 61) \n",
      "Testing SARIMA(2, 1, 0) (0, 1, 1, 61) \n",
      "Testing SARIMA(2, 1, 0) (1, 0, 0, 61) \n",
      "Testing SARIMA(2, 1, 0) (1, 0, 1, 61) \n",
      "Testing SARIMA(2, 1, 0) (1, 1, 0, 61) \n",
      "Testing SARIMA(2, 1, 0) (1, 1, 1, 61) \n",
      "Testing SARIMA(2, 1, 1) (0, 0, 0, 61) \n",
      "Testing SARIMA(2, 1, 1) (0, 0, 1, 61) \n",
      "Testing SARIMA(2, 1, 1) (0, 1, 0, 61) \n",
      "Testing SARIMA(2, 1, 1) (0, 1, 1, 61) \n",
      "Testing SARIMA(2, 1, 1) (1, 0, 0, 61) \n",
      "Testing SARIMA(2, 1, 1) (1, 0, 1, 61) \n",
      "Testing SARIMA(2, 1, 1) (1, 1, 0, 61) \n",
      "Testing SARIMA(2, 1, 1) (1, 1, 1, 61) \n",
      "Testing SARIMA(2, 1, 2) (0, 0, 0, 61) \n",
      "Testing SARIMA(2, 1, 2) (0, 0, 1, 61) \n",
      "Testing SARIMA(2, 1, 2) (0, 1, 0, 61) \n",
      "Testing SARIMA(2, 1, 2) (0, 1, 1, 61) \n",
      "Testing SARIMA(2, 1, 2) (1, 0, 0, 61) \n",
      "Testing SARIMA(2, 1, 2) (1, 0, 1, 61) \n",
      "Testing SARIMA(2, 1, 2) (1, 1, 0, 61) \n",
      "Testing SARIMA(2, 1, 2) (1, 1, 1, 61) \n",
      "[ 16:50:33] Processing batch 1\n",
      "2018-06-13 16:50:45 dispy - Received reply for job 3 / 112204522984 from 192.168.1.3\n",
      "2018-06-13 16:50:45 dispy - Running job 112204523464 on 192.168.1.3\n",
      "2018-06-13 16:50:45 dispy - Running job 4 / 112204523464 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:50:45 dispy - Received reply for job 1 / 112204522744 from 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 6, in evaluate_sarima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/sarimax.py\", line 510, in __init__\n",
      "    endog, exog=exog, k_states=k_states, k_posdef=k_posdef, **kwargs\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 97, in __init__\n",
      "    self.initialize_statespace(**kwargs)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 130, in initialize_statespace\n",
      "    self.ssm = KalmanSmoother(endog.shape[0], self.k_states, **kwargs)\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_smoother.py\", line 343, in __init__\n",
      "    k_endog, k_states, k_posdef, results_class=results_class, **kwargs\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\", line 213, in __init__\n",
      "    k_endog, k_states, k_posdef, **kwargs\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/representation.py\", line 278, in __init__\n",
      "    raise ValueError('Number of states in statespace model must be a'\n",
      "ValueError: Number of states in statespace model must be a positive number.\n",
      "\n",
      "2018-06-13 16:50:45 dispy - Running job 112204523584 on 192.168.1.3\n",
      "\n",
      "[ 16:50:45] Finished batch 1\n",
      "[ 16:50:45] Processing batch 2\n",
      "2018-06-13 16:50:45 dispy - Running job 5 / 112204523584 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:50:46 dispy - Received reply for job 2 / 112204523104 from 192.168.1.3\n",
      "2018-06-13 16:50:46 dispy - Running job 112204523824 on 192.168.1.3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 7, in evaluate_sarima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\", line 403, in fit\n",
      "    start_params = self.start_params\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/sarimax.py\", line 1033, in start_params\n",
      "    raise ValueError('non-invertible starting seasonal moving average'\n",
      "ValueError: non-invertible starting seasonal moving average parameters found with `enforce_invertibility` set to True.\n",
      "\n",
      "\n",
      "[ 16:50:46] Finished batch 2\n",
      "[ 16:50:46] Processing batch 3\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/dispy/dispynode.py\", line 197, in _dispy_job_func\n",
      "    __dispy_job_name, globals())\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 6, in evaluate_sarima_model\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/sarimax.py\", line 524, in __init__\n",
      "    self.ssm.transition = self.initial_transition\n",
      "  File \"/Users/cseveriano/anaconda3/lib/python3.6/site-packages/statsmodels/tsa/statespace/sarimax.py\", line 795, in initial_transition\n",
      "    transition[start:end, start:end] = companion_matrix(self._k_order)\n",
      "ValueError: could not broadcast input array from shape (0,0) into shape (61,61)\n",
      "\n",
      "\n",
      "[ 16:50:46] Finished batch 3\n",
      "[ 16:50:46] Processing batch 4\n",
      "2018-06-13 16:50:46 dispy - Running job 6 / 112204523824 on 192.168.1.3 (busy: 3 / 3)\n",
      "2018-06-13 16:51:06 dispy - Received reply for job 5 / 112204523584 from 192.168.1.3\n",
      "2018-06-13 16:51:06 dispy - Running job 112204523944 on 192.168.1.3\n",
      "2018-06-13 16:51:06 dispy - Running job 7 / 112204523944 on 192.168.1.3 (busy: 3 / 3)\n"
     ]
    }
   ],
   "source": [
    "p_values = [0,1,2]\n",
    "d_values = [0,1]\n",
    "q_values = [0,1,2]\n",
    "P_values = [0,1]\n",
    "D_Values = [0,1]\n",
    "Q_Values = [0,1]\n",
    "\n",
    "parameters = product(p_values, d_values, q_values, P_values, D_Values, Q_Values)\n",
    "parameters_list = list(parameters)\n",
    "period_length = 61 #de 5:00 as 20:00\n",
    "distributed_sarima_evaluate_models(evaluate_sarima_model, \"dist-sarima-summer-clean\",summer_train_clean_df[target_station], summer_validation_clean_df[target_station], parameters_list, period_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_sarima_models(\"sarima-spring-clean\",spring_train_clean_df[target_station], spring_validation_clean_df[target_station], parameters_list, period_length)\n",
    "evaluate_sarima_models(\"sarima-autumn-clean\",autumn_train_clean_df[target_station], autumn_validation_clean_df[target_station], parameters_list, period_length)\n",
    "evaluate_sarima_models(\"sarima-winter-clean\",winter_train_clean_df[target_station], winter_validation_clean_df[target_station], parameters_list, period_length)\n",
    "\n",
    "evaluate_sarima_models(\"sarima-summer-residual\",spring_train_residual_df[target_station], spring_validation_residual_df[target_station], parameters_list, period_length)\n",
    "evaluate_sarima_models(\"sarima-spring-residual\",spring_train_residual_df[target_station], spring_validation_residual_df[target_station], parameters_list, period_length)\n",
    "evaluate_sarima_models(\"sarima-autumn-residual\",autumn_train_residual_df[target_station], autumn_validation_residual_df[target_station], parameters_list, period_length)\n",
    "evaluate_sarima_models(\"sarima-winter-residual\",winter_train_residual_df[target_station], winter_validation_residual_df[target_station], parameters_list, period_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Autorregressive - VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR, DynamicVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_VAR_models(test_name, train, validation,target, maxlags_list):\n",
    "    var_results = pd.DataFrame(columns=['Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    \n",
    "    for lgs in maxlags_list:\n",
    "        model = VAR(train)\n",
    "        results = model.fit(maxlags=lgs, ic='aic')\n",
    "        \n",
    "        order = results.k_ar\n",
    "        forecast = []\n",
    "\n",
    "        for i in range(len(validation)-order) :\n",
    "            forecast.extend(results.forecast(validation.values[i:i+order],1))\n",
    "\n",
    "        forecast_df = pd.DataFrame(columns=validation.columns, data=forecast)\n",
    "        rmse = math.sqrt(mean_squared_error(forecast_df[target].values, validation[target].iloc[order:]))\n",
    "\n",
    "        if rmse < best_score:\n",
    "            best_score, best_cfg = rmse, order\n",
    "\n",
    "        res = {'Order' : str(order) ,'RMSE' : rmse}\n",
    "        print('VAR (%s)  RMSE=%.3f' % (str(order),rmse))\n",
    "        var_results = var_results.append(res, ignore_index=True)\n",
    "        var_results.to_csv(test_name+\".csv\")\n",
    "        \n",
    "    print('Best VAR(%s) RMSE=%.3f' % (best_cfg, best_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR (1)  RMSE=0.056\n",
      "VAR (2)  RMSE=0.006\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.004\n",
      "VAR (8)  RMSE=0.004\n",
      "VAR (10)  RMSE=0.004\n",
      "VAR (14)  RMSE=0.004\n",
      "VAR (14)  RMSE=0.004\n",
      "Best VAR(4) RMSE=0.003\n",
      "VAR (1)  RMSE=0.074\n",
      "VAR (2)  RMSE=0.072\n",
      "VAR (4)  RMSE=0.075\n",
      "VAR (6)  RMSE=0.075\n",
      "VAR (8)  RMSE=0.075\n",
      "VAR (10)  RMSE=0.075\n",
      "VAR (20)  RMSE=0.080\n",
      "VAR (40)  RMSE=0.087\n",
      "Best VAR(2) RMSE=0.072\n"
     ]
    }
   ],
   "source": [
    "maxlags_list = [1,2,4,6,8,10,20,40]\n",
    "evaluate_VAR_models(\"var_oahu_clean\", train_clean_df[neighbor_stations_90], validation_clean_df[neighbor_stations_90],target_station, maxlags_list)\n",
    "evaluate_VAR_models(\"var_oahu_residual\", train_residual_df[neighbor_stations_90], validation_residual_df[neighbor_stations_90],target_station, maxlags_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Order Fuzzy Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/petroniocandido/pyFTS\n",
      "  Cloning https://github.com/petroniocandido/pyFTS to /private/var/folders/13/t7d8w0nd0hv6w9_p2rntvym00000gr/T/pip-req-build-4e3y8zbt\n",
      "Building wheels for collected packages: pyFTS\n",
      "  Running setup.py bdist_wheel for pyFTS ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /private/var/folders/13/t7d8w0nd0hv6w9_p2rntvym00000gr/T/pip-ephem-wheel-cache-_3kkffbn/wheels/84/d7/1e/a333c7128f25b347640740859808db094c4478e98663cd2297\n",
      "Successfully built pyFTS\n",
      "Installing collected packages: pyFTS\n",
      "  Found existing installation: pyFTS 1.2.2\n",
      "    Uninstalling pyFTS-1.2.2:\n",
      "      Successfully uninstalled pyFTS-1.2.2\n",
      "Successfully installed pyFTS-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/petroniocandido/pyFTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFTS.models.multivariate import common, variable, mvfts\n",
    "from pyFTS.models.seasonal import partitioner as seasonal\n",
    "from pyFTS.models.seasonal.common import DateTime\n",
    "from pyFTS.partitioners import Grid, Entropy, Util as pUtil\n",
    "from pyFTS.models.multivariate import common, variable, mvfts\n",
    "from pyFTS.models import hofts\n",
    "from pyFTS.common import Transformations\n",
    "tdiff = Transformations.Differential(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hofts_models(test_name, train, validation, partitioners_list, order_list, partitions_list):\n",
    "    \n",
    "    hofts_results = pd.DataFrame(columns=['Partitioner','Partitions','Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "\n",
    "    for _partitioner in partitioners_list:\n",
    "        for _order in order_list:\n",
    "            for npartitions in partitions_list:\n",
    "                fuzzy_sets = _partitioner(data=train.values, npart=npartitions)\n",
    "                model_simple_hofts = hofts.HighOrderFTS()\n",
    "\n",
    "                #model_simple_hofts.append_transformation(Transformations.Differential(1))\n",
    "                model_simple_hofts.fit(train.values, order=_order, partitioner=fuzzy_sets)\n",
    "\n",
    "                forecast = model_simple_hofts.predict(validation.values)\n",
    "\n",
    "                rmse = math.sqrt(mean_squared_error(validation.iloc[_order:], forecast[:-1]))\n",
    "\n",
    "                if rmse < best_score:\n",
    "                    best_score, best_cfg = rmse, (_order,npartitions,_partitioner)\n",
    "\n",
    "                res = {'Partitioner':str(_partitioner), 'Partitions':npartitions, 'Order' : str(_order) ,'RMSE' : rmse}\n",
    "                print('HOFTS %s - %s - %s  RMSE=%.3f' % (str(_partitioner), npartitions, str(_order),rmse))\n",
    "                hofts_results = hofts_results.append(res, ignore_index=True)\n",
    "                hofts_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best HOFTS(%s) RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 1  RMSE=0.082\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 1  RMSE=0.049\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 1  RMSE=0.043\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 1  RMSE=0.038\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 1  RMSE=0.037\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 1  RMSE=0.036\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 1  RMSE=0.035\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 1  RMSE=0.034\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 1  RMSE=0.034\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 2  RMSE=0.076\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 2  RMSE=0.045\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 2  RMSE=0.034\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 2  RMSE=0.025\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 2  RMSE=0.020\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 2  RMSE=0.016\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 2  RMSE=0.017\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 2  RMSE=0.014\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 2  RMSE=0.014\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 1  RMSE=0.108\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 1  RMSE=0.052\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 1  RMSE=0.050\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 1  RMSE=0.039\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 1  RMSE=0.039\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 1  RMSE=0.036\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 1  RMSE=0.035\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 1  RMSE=0.035\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 1  RMSE=0.035\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 2  RMSE=0.105\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 2  RMSE=0.051\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 2  RMSE=0.044\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 2  RMSE=0.028\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 2  RMSE=0.026\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 2  RMSE=0.019\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 2  RMSE=0.016\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 2  RMSE=0.016\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 2  RMSE=0.016\n",
      "Best HOFTS((2, 90, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)) RMSE=0.014\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 1  RMSE=0.077\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 1  RMSE=0.078\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 1  RMSE=0.077\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 1  RMSE=0.077\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 1  RMSE=0.076\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 1  RMSE=0.078\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 1  RMSE=0.077\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 1  RMSE=0.079\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 1  RMSE=0.078\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 10 - 2  RMSE=0.077\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 20 - 2  RMSE=0.081\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 30 - 2  RMSE=0.083\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 40 - 2  RMSE=0.086\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 50 - 2  RMSE=0.088\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 60 - 2  RMSE=0.090\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 70 - 2  RMSE=0.091\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 80 - 2  RMSE=0.090\n",
      "HOFTS <class 'pyFTS.partitioners.Grid.GridPartitioner'> - 90 - 2  RMSE=0.091\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 1  RMSE=0.075\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 1  RMSE=0.075\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 1  RMSE=0.075\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 1  RMSE=0.075\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 1  RMSE=0.075\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 1  RMSE=0.074\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 1  RMSE=0.074\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 1  RMSE=0.074\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 1  RMSE=0.074\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 10 - 2  RMSE=0.075\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 20 - 2  RMSE=0.075\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 30 - 2  RMSE=0.077\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 40 - 2  RMSE=0.079\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 50 - 2  RMSE=0.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cseveriano/anaconda3/lib/python3.6/site-packages/pyFTS/common/flrg.py:52: RuntimeWarning: Mean of empty slice\n",
      "  self.midpoint = np.nanmean(self.get_midpoints(sets))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 60 - 2  RMSE=0.076\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 70 - 2  RMSE=0.077\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 80 - 2  RMSE=0.077\n",
      "HOFTS <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'> - 90 - 2  RMSE=0.077\n",
      "Best HOFTS((1, 70, <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'>)) RMSE=0.074\n"
     ]
    }
   ],
   "source": [
    "partitioners_list = [Grid.GridPartitioner, Entropy.EntropyPartitioner]\n",
    "order_list = np.arange(1,3)\n",
    "partitions_list = np.arange(10,100,10)\n",
    "\n",
    "evaluate_hofts_models(\"hofts_oahu_clean\", train_clean_df[target_station], validation_clean_df[target_station], partitioners_list, order_list, partitions_list)\n",
    "evaluate_hofts_models(\"hofts_oahu_residual\", train_residual_df[target_station], validation_residual_df[target_station], partitioners_list, order_list, partitions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Order NonStationary FTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyFTS.models.nonstationary import honsfts\n",
    "from pyFTS.models.nonstationary import cvfts\n",
    "from pyFTS.models.nonstationary import partitioners as nspartitioners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pyFTS.models.nonstationary.honsfts' from '/Users/cseveriano/anaconda3/lib/python3.6/site-packages/pyFTS/models/nonstationary/honsfts.py'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(honsfts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_fs1 = Grid.GridPartitioner(data=train1[:50], npart=10)\n",
    "\n",
    "fs1 = partitioners.PolynomialNonStationaryPartitioner(train1, tmp_fs1, window_size=ws, degree=1)\n",
    "\n",
    "nsfts1 = nsfts.NonStationaryFTS(\"\", partitioner=fs1)\n",
    "\n",
    "nsfts1.fit(train1, parameters=ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_honsfts_models(test_name, train, validation, partitioners_list, order_list, partitions_list):\n",
    "    \n",
    "    honsfts_results = pd.DataFrame(columns=['Partitioner','Partitions','Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "\n",
    "    for _partitioner in partitioners_list:\n",
    "        for _order in order_list:\n",
    "            for npartitions in partitions_list:\n",
    "                    fuzzy_sets =  nspartitioners.PolynomialNonStationaryPartitioner(data=train.values, part=_partitioner(data=train.values, npart=npartitions), degree=2)\n",
    "                    \n",
    "                    model_cvfts = honsfts.HighOrderNonStationaryFTS(method='fuzzy')\n",
    "                    \n",
    "                    model_cvfts.fit(train.values, order=_order, parameters=1, partitioner=fuzzy_sets)\n",
    "\n",
    "                    forecast = model_cvfts.predict(validation.values)\n",
    "\n",
    "                    rmse = math.sqrt(mean_squared_error(validation.iloc[_order:], forecast[:-1]))\n",
    "                    params = (_order,npartitions,_partitioner)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, params\n",
    "\n",
    "                    res = {'Partitioner':str(_partitioner), 'Partitions':npartitions, 'Order' : str(_order) ,'RMSE' : rmse}\n",
    "                    print('CVFTS %s  RMSE=%.3f' % (params,rmse))\n",
    "                    honsfts_results = honsfts_results.append(res, ignore_index=True)\n",
    "                    honsfts_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best CVFTS(%s) RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cseveriano/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVFTS (1, 10, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.569\n",
      "CVFTS (1, 20, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.553\n",
      "CVFTS (1, 30, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.549\n",
      "CVFTS (2, 10, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.569\n",
      "CVFTS (2, 20, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.554\n",
      "CVFTS (2, 30, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.552\n",
      "CVFTS (3, 10, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.571\n",
      "CVFTS (3, 20, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.558\n",
      "CVFTS (3, 30, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.556\n",
      "CVFTS (4, 10, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.573\n",
      "CVFTS (4, 20, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.562\n",
      "CVFTS (4, 30, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.560\n",
      "CVFTS (5, 10, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.576\n",
      "CVFTS (5, 20, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.566\n",
      "CVFTS (5, 30, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.564\n",
      "CVFTS (6, 10, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.580\n",
      "CVFTS (6, 20, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.570\n",
      "CVFTS (6, 30, <class 'pyFTS.partitioners.Grid.GridPartitioner'>)  RMSE=0.569\n",
      "CVFTS (1, 10, <class 'pyFTS.partitioners.Entropy.EntropyPartitioner'>)  RMSE=0.471\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-48fcbf86a96d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwindow_size_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mevaluate_honsfts_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"honsfts_oahu_clean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_clean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_clean_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioners_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mevaluate_honsfts_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"honsfts_oahu_residual\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_residual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_residual_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_station\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioners_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-137-918a29fd95fd>\u001b[0m in \u001b[0;36mevaluate_honsfts_models\u001b[0;34m(test_name, train, validation, partitioners_list, order_list, partitions_list)\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mmodel_cvfts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfuzzy_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cvfts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyFTS/common/fts.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msteps_ahead\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msteps_ahead\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'point'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'interval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecast_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyFTS/models/nonstationary/honsfts.py\u001b[0m in \u001b[0;36mforecast\u001b[0;34m(self, ndata, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             affected_flrgs, affected_flrgs_memberships = self._affected_flrgs(sample, k,\n\u001b[0;32m--> 166\u001b[0;31m                                                                               time_displacement, window_size)\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m#print([str(k) for k in affected_flrgs])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyFTS/models/nonstationary/honsfts.py\u001b[0m in \u001b[0;36m_affected_flrgs\u001b[0;34m(self, sample, k, time_displacement, window_size)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtime_displacement\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLHS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmembership\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "partitioners_list = [Grid.GridPartitioner, Entropy.EntropyPartitioner]\n",
    "order_list = np.arange(1,7)\n",
    "partitions_list = np.arange(10,40,10)\n",
    "window_size_list = np.arange(1,5)\n",
    "\n",
    "evaluate_honsfts_models(\"honsfts_oahu_clean\", train_clean_df[target_station], validation_clean_df[target_station], partitioners_list, order_list, partitions_list)\n",
    "evaluate_honsfts_models(\"honsfts_oahu_residual\", train_residual_df[target_station], validation_residual_df[target_station], partitioners_list, order_list, partitions_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-term Memory LSTM - Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=False, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_univariate_lstm_models(test_name, train_df, validation_df, neurons_list, order_list, epochs_list):\n",
    "    \n",
    "    lstm_results = pd.DataFrame(columns=['Neurons','Order','Epochs','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    \n",
    "\n",
    "    for _neurons in neurons_list:\n",
    "        for _order in order_list:\n",
    "            for epochs in epochs_list:\n",
    "                    \n",
    "                    train = timeseries_to_supervised(train_df.values, lag=_order).values\n",
    "                    validation = timeseries_to_supervised(validation_df.values, lag=_order).values                    \n",
    "\n",
    "                    # fit the model \n",
    "                    lstm_model = fit_lstm(train, 1, epochs, _neurons)\n",
    "                    \n",
    "                    trainX = train[:, 0:-1]\n",
    "                    train_reshaped = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "                    lstm_model.predict(train_reshaped, batch_size=1)                    \n",
    "                    forecast = []\n",
    "\n",
    "                    for i in range(len(validation)):\n",
    "                        # make one-step forecast\n",
    "                        X, y = validation[i, 0:-1], validation[i, -1]\n",
    "                        yhat = forecast_lstm(lstm_model, 1, X)\n",
    "                        forecast.append(yhat)\n",
    "                        \n",
    "                    y_obs = validation[:, -1]\n",
    "                    \n",
    "                    rmse = math.sqrt(mean_squared_error(y_obs, forecast))\n",
    "                    params = (_neurons, _order,epochs)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, params\n",
    "\n",
    "                    res = {'Neurons':_neurons, 'Order':_order, 'Epochs' : epochs ,'RMSE' : rmse}\n",
    "                    print('LSTM %s  RMSE=%.3f' % (params,rmse))\n",
    "                    lstm_results = lstm_results.append(res, ignore_index=True)\n",
    "                    lstm_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best LSTM(%s) RMSE=%.3f' % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM (10, 1, 100)  RMSE=0.047\n",
      "LSTM (10, 2, 100)  RMSE=0.012\n",
      "LSTM (10, 3, 100)  RMSE=0.014\n",
      "LSTM (10, 4, 100)  RMSE=0.028\n",
      "LSTM (20, 1, 100)  RMSE=0.037\n",
      "LSTM (20, 2, 100)  RMSE=0.011\n",
      "LSTM (20, 3, 100)  RMSE=0.040\n",
      "LSTM (20, 4, 100)  RMSE=0.043\n",
      "LSTM (30, 1, 100)  RMSE=0.052\n",
      "LSTM (30, 2, 100)  RMSE=0.039\n"
     ]
    }
   ],
   "source": [
    "neurons_list = np.arange(10,110,10)\n",
    "order_list = np.arange(1,5)\n",
    "epochs_list = [100]\n",
    "\n",
    "evaluate_univariate_lstm_models(\"lstm_univ_oahu_clean\", train_clean_df[target_station], validation_clean_df[target_station], neurons_list, order_list, epochs_list)\n",
    "evaluate_univariate_lstm_models(\"lstm_univ_oahu_residual\", train_residual_df[target_station], validation_residual_df[target_station], neurons_list, order_list, epochs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-term Memory LSTM - Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat = len(train_clean_df[neighbor_stations_90].columns)\n",
    "nlags = 2\n",
    "nsteps = 1\n",
    "reshaped_df = series_to_supervised(train_clean_df[neighbor_stations_90], n_in=nlags, n_out=nsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var6(t-2)</th>\n",
       "      <th>var7(t-2)</th>\n",
       "      <th>var8(t-2)</th>\n",
       "      <th>var9(t-2)</th>\n",
       "      <th>var10(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var9(t-1)</th>\n",
       "      <th>var10(t-1)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-11-01 05:30:00</th>\n",
       "      <td>0.032268</td>\n",
       "      <td>0.032775</td>\n",
       "      <td>0.033418</td>\n",
       "      <td>0.030716</td>\n",
       "      <td>0.029538</td>\n",
       "      <td>0.034313</td>\n",
       "      <td>0.036917</td>\n",
       "      <td>0.031167</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.029590</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.032403</td>\n",
       "      <td>0.033381</td>\n",
       "      <td>0.030563</td>\n",
       "      <td>0.029318</td>\n",
       "      <td>0.033496</td>\n",
       "      <td>0.036665</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>0.037285</td>\n",
       "      <td>0.028936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 05:45:00</th>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.032403</td>\n",
       "      <td>0.033381</td>\n",
       "      <td>0.030563</td>\n",
       "      <td>0.029318</td>\n",
       "      <td>0.033496</td>\n",
       "      <td>0.036665</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>0.037285</td>\n",
       "      <td>0.028936</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>0.030643</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>0.029033</td>\n",
       "      <td>0.027722</td>\n",
       "      <td>0.031662</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.028735</td>\n",
       "      <td>0.035647</td>\n",
       "      <td>0.027221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 06:00:00</th>\n",
       "      <td>0.030912</td>\n",
       "      <td>0.030643</td>\n",
       "      <td>0.031807</td>\n",
       "      <td>0.029033</td>\n",
       "      <td>0.027722</td>\n",
       "      <td>0.031662</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.028735</td>\n",
       "      <td>0.035647</td>\n",
       "      <td>0.027221</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>0.026518</td>\n",
       "      <td>0.027374</td>\n",
       "      <td>0.025704</td>\n",
       "      <td>0.025196</td>\n",
       "      <td>0.027489</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>0.031331</td>\n",
       "      <td>0.024780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 06:15:00</th>\n",
       "      <td>0.026961</td>\n",
       "      <td>0.026518</td>\n",
       "      <td>0.027374</td>\n",
       "      <td>0.025704</td>\n",
       "      <td>0.025196</td>\n",
       "      <td>0.027489</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>0.031331</td>\n",
       "      <td>0.024780</td>\n",
       "      <td>0.020411</td>\n",
       "      <td>0.019889</td>\n",
       "      <td>0.020225</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>0.020590</td>\n",
       "      <td>0.021382</td>\n",
       "      <td>0.020044</td>\n",
       "      <td>0.024133</td>\n",
       "      <td>0.020141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 06:30:00</th>\n",
       "      <td>0.020411</td>\n",
       "      <td>0.019889</td>\n",
       "      <td>0.020225</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>0.020644</td>\n",
       "      <td>0.020590</td>\n",
       "      <td>0.021382</td>\n",
       "      <td>0.020044</td>\n",
       "      <td>0.024133</td>\n",
       "      <td>0.020141</td>\n",
       "      <td>0.014629</td>\n",
       "      <td>0.014738</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>0.015727</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.014613</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.015479</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.015190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 06:45:00</th>\n",
       "      <td>0.014629</td>\n",
       "      <td>0.014738</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>0.015727</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.014613</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.015479</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.012350</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.014047</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>0.011183</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.013773</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.013415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 07:00:00</th>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.012350</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.014047</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>0.011183</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.013773</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.013415</td>\n",
       "      <td>0.012748</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.012166</td>\n",
       "      <td>0.016840</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.016919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 07:15:00</th>\n",
       "      <td>0.012748</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.012166</td>\n",
       "      <td>0.016840</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>0.016231</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.016919</td>\n",
       "      <td>0.020101</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>0.025921</td>\n",
       "      <td>0.027364</td>\n",
       "      <td>0.017612</td>\n",
       "      <td>0.020780</td>\n",
       "      <td>0.024922</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.026634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 07:30:00</th>\n",
       "      <td>0.020101</td>\n",
       "      <td>0.022542</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>0.025921</td>\n",
       "      <td>0.027364</td>\n",
       "      <td>0.017612</td>\n",
       "      <td>0.020780</td>\n",
       "      <td>0.024922</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.026634</td>\n",
       "      <td>0.040105</td>\n",
       "      <td>0.043592</td>\n",
       "      <td>0.041342</td>\n",
       "      <td>0.047447</td>\n",
       "      <td>0.048437</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.045936</td>\n",
       "      <td>0.045803</td>\n",
       "      <td>0.047621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 07:45:00</th>\n",
       "      <td>0.040105</td>\n",
       "      <td>0.043592</td>\n",
       "      <td>0.041342</td>\n",
       "      <td>0.047447</td>\n",
       "      <td>0.048437</td>\n",
       "      <td>0.036437</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.045936</td>\n",
       "      <td>0.045803</td>\n",
       "      <td>0.047621</td>\n",
       "      <td>0.073831</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>0.077749</td>\n",
       "      <td>0.082244</td>\n",
       "      <td>0.081812</td>\n",
       "      <td>0.069991</td>\n",
       "      <td>0.081825</td>\n",
       "      <td>0.080165</td>\n",
       "      <td>0.083828</td>\n",
       "      <td>0.080798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 08:00:00</th>\n",
       "      <td>0.073831</td>\n",
       "      <td>0.079248</td>\n",
       "      <td>0.077749</td>\n",
       "      <td>0.082244</td>\n",
       "      <td>0.081812</td>\n",
       "      <td>0.069991</td>\n",
       "      <td>0.081825</td>\n",
       "      <td>0.080165</td>\n",
       "      <td>0.083828</td>\n",
       "      <td>0.080798</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.124425</td>\n",
       "      <td>0.124007</td>\n",
       "      <td>0.125547</td>\n",
       "      <td>0.123085</td>\n",
       "      <td>0.113103</td>\n",
       "      <td>0.131692</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.132828</td>\n",
       "      <td>0.121976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 08:15:00</th>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.124425</td>\n",
       "      <td>0.124007</td>\n",
       "      <td>0.125547</td>\n",
       "      <td>0.123085</td>\n",
       "      <td>0.113103</td>\n",
       "      <td>0.131692</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.132828</td>\n",
       "      <td>0.121976</td>\n",
       "      <td>0.164904</td>\n",
       "      <td>0.175740</td>\n",
       "      <td>0.176726</td>\n",
       "      <td>0.174910</td>\n",
       "      <td>0.170643</td>\n",
       "      <td>0.162863</td>\n",
       "      <td>0.188161</td>\n",
       "      <td>0.171817</td>\n",
       "      <td>0.188591</td>\n",
       "      <td>0.169461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 08:30:00</th>\n",
       "      <td>0.164904</td>\n",
       "      <td>0.175740</td>\n",
       "      <td>0.176726</td>\n",
       "      <td>0.174910</td>\n",
       "      <td>0.170643</td>\n",
       "      <td>0.162863</td>\n",
       "      <td>0.188161</td>\n",
       "      <td>0.171817</td>\n",
       "      <td>0.188591</td>\n",
       "      <td>0.169461</td>\n",
       "      <td>0.221257</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>0.231856</td>\n",
       "      <td>0.226432</td>\n",
       "      <td>0.220433</td>\n",
       "      <td>0.250997</td>\n",
       "      <td>0.228340</td>\n",
       "      <td>0.250682</td>\n",
       "      <td>0.225126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 08:45:00</th>\n",
       "      <td>0.221257</td>\n",
       "      <td>0.234301</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>0.231856</td>\n",
       "      <td>0.226432</td>\n",
       "      <td>0.220433</td>\n",
       "      <td>0.250997</td>\n",
       "      <td>0.228340</td>\n",
       "      <td>0.250682</td>\n",
       "      <td>0.225126</td>\n",
       "      <td>0.284905</td>\n",
       "      <td>0.299676</td>\n",
       "      <td>0.303037</td>\n",
       "      <td>0.296080</td>\n",
       "      <td>0.289875</td>\n",
       "      <td>0.285498</td>\n",
       "      <td>0.319654</td>\n",
       "      <td>0.292186</td>\n",
       "      <td>0.318916</td>\n",
       "      <td>0.288570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 09:00:00</th>\n",
       "      <td>0.284905</td>\n",
       "      <td>0.299676</td>\n",
       "      <td>0.303037</td>\n",
       "      <td>0.296080</td>\n",
       "      <td>0.289875</td>\n",
       "      <td>0.285498</td>\n",
       "      <td>0.319654</td>\n",
       "      <td>0.292186</td>\n",
       "      <td>0.318916</td>\n",
       "      <td>0.288570</td>\n",
       "      <td>0.353067</td>\n",
       "      <td>0.369163</td>\n",
       "      <td>0.373142</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.358404</td>\n",
       "      <td>0.355426</td>\n",
       "      <td>0.391699</td>\n",
       "      <td>0.360824</td>\n",
       "      <td>0.391097</td>\n",
       "      <td>0.357233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 09:15:00</th>\n",
       "      <td>0.353067</td>\n",
       "      <td>0.369163</td>\n",
       "      <td>0.373142</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>0.358404</td>\n",
       "      <td>0.355426</td>\n",
       "      <td>0.391699</td>\n",
       "      <td>0.360824</td>\n",
       "      <td>0.391097</td>\n",
       "      <td>0.357233</td>\n",
       "      <td>0.421526</td>\n",
       "      <td>0.438338</td>\n",
       "      <td>0.442255</td>\n",
       "      <td>0.434234</td>\n",
       "      <td>0.428124</td>\n",
       "      <td>0.425813</td>\n",
       "      <td>0.462135</td>\n",
       "      <td>0.430196</td>\n",
       "      <td>0.462465</td>\n",
       "      <td>0.427252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 09:30:00</th>\n",
       "      <td>0.421526</td>\n",
       "      <td>0.438338</td>\n",
       "      <td>0.442255</td>\n",
       "      <td>0.434234</td>\n",
       "      <td>0.428124</td>\n",
       "      <td>0.425813</td>\n",
       "      <td>0.462135</td>\n",
       "      <td>0.430196</td>\n",
       "      <td>0.462465</td>\n",
       "      <td>0.427252</td>\n",
       "      <td>0.485745</td>\n",
       "      <td>0.502506</td>\n",
       "      <td>0.505560</td>\n",
       "      <td>0.499493</td>\n",
       "      <td>0.494683</td>\n",
       "      <td>0.491748</td>\n",
       "      <td>0.525652</td>\n",
       "      <td>0.495661</td>\n",
       "      <td>0.527622</td>\n",
       "      <td>0.494202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 09:45:00</th>\n",
       "      <td>0.485745</td>\n",
       "      <td>0.502506</td>\n",
       "      <td>0.505560</td>\n",
       "      <td>0.499493</td>\n",
       "      <td>0.494683</td>\n",
       "      <td>0.491748</td>\n",
       "      <td>0.525652</td>\n",
       "      <td>0.495661</td>\n",
       "      <td>0.527622</td>\n",
       "      <td>0.494202</td>\n",
       "      <td>0.542919</td>\n",
       "      <td>0.558690</td>\n",
       "      <td>0.560023</td>\n",
       "      <td>0.557801</td>\n",
       "      <td>0.554874</td>\n",
       "      <td>0.550111</td>\n",
       "      <td>0.578472</td>\n",
       "      <td>0.554233</td>\n",
       "      <td>0.582676</td>\n",
       "      <td>0.554763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 10:00:00</th>\n",
       "      <td>0.542919</td>\n",
       "      <td>0.558690</td>\n",
       "      <td>0.560023</td>\n",
       "      <td>0.557801</td>\n",
       "      <td>0.554874</td>\n",
       "      <td>0.550111</td>\n",
       "      <td>0.578472</td>\n",
       "      <td>0.554233</td>\n",
       "      <td>0.582676</td>\n",
       "      <td>0.554763</td>\n",
       "      <td>0.595321</td>\n",
       "      <td>0.608926</td>\n",
       "      <td>0.607790</td>\n",
       "      <td>0.611526</td>\n",
       "      <td>0.611331</td>\n",
       "      <td>0.603248</td>\n",
       "      <td>0.622823</td>\n",
       "      <td>0.608380</td>\n",
       "      <td>0.629944</td>\n",
       "      <td>0.611545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 10:15:00</th>\n",
       "      <td>0.595321</td>\n",
       "      <td>0.608926</td>\n",
       "      <td>0.607790</td>\n",
       "      <td>0.611526</td>\n",
       "      <td>0.611331</td>\n",
       "      <td>0.603248</td>\n",
       "      <td>0.622823</td>\n",
       "      <td>0.608380</td>\n",
       "      <td>0.629944</td>\n",
       "      <td>0.611545</td>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.642814</td>\n",
       "      <td>0.637705</td>\n",
       "      <td>0.649916</td>\n",
       "      <td>0.653777</td>\n",
       "      <td>0.640627</td>\n",
       "      <td>0.647986</td>\n",
       "      <td>0.647784</td>\n",
       "      <td>0.658855</td>\n",
       "      <td>0.654735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 10:30:00</th>\n",
       "      <td>0.631988</td>\n",
       "      <td>0.642814</td>\n",
       "      <td>0.637705</td>\n",
       "      <td>0.649916</td>\n",
       "      <td>0.653777</td>\n",
       "      <td>0.640627</td>\n",
       "      <td>0.647986</td>\n",
       "      <td>0.647784</td>\n",
       "      <td>0.658855</td>\n",
       "      <td>0.654735</td>\n",
       "      <td>0.650558</td>\n",
       "      <td>0.657713</td>\n",
       "      <td>0.647136</td>\n",
       "      <td>0.670614</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.658599</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.669454</td>\n",
       "      <td>0.666735</td>\n",
       "      <td>0.680853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 10:45:00</th>\n",
       "      <td>0.650558</td>\n",
       "      <td>0.657713</td>\n",
       "      <td>0.647136</td>\n",
       "      <td>0.670614</td>\n",
       "      <td>0.679029</td>\n",
       "      <td>0.658599</td>\n",
       "      <td>0.651696</td>\n",
       "      <td>0.669454</td>\n",
       "      <td>0.666735</td>\n",
       "      <td>0.680853</td>\n",
       "      <td>0.653822</td>\n",
       "      <td>0.656733</td>\n",
       "      <td>0.640228</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.687173</td>\n",
       "      <td>0.660159</td>\n",
       "      <td>0.638698</td>\n",
       "      <td>0.675538</td>\n",
       "      <td>0.657439</td>\n",
       "      <td>0.689895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 11:00:00</th>\n",
       "      <td>0.653822</td>\n",
       "      <td>0.656733</td>\n",
       "      <td>0.640228</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.687173</td>\n",
       "      <td>0.660159</td>\n",
       "      <td>0.638698</td>\n",
       "      <td>0.675538</td>\n",
       "      <td>0.657439</td>\n",
       "      <td>0.689895</td>\n",
       "      <td>0.648692</td>\n",
       "      <td>0.647231</td>\n",
       "      <td>0.624605</td>\n",
       "      <td>0.671061</td>\n",
       "      <td>0.684814</td>\n",
       "      <td>0.652315</td>\n",
       "      <td>0.617460</td>\n",
       "      <td>0.671582</td>\n",
       "      <td>0.639492</td>\n",
       "      <td>0.688920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 11:15:00</th>\n",
       "      <td>0.648692</td>\n",
       "      <td>0.647231</td>\n",
       "      <td>0.624605</td>\n",
       "      <td>0.671061</td>\n",
       "      <td>0.684814</td>\n",
       "      <td>0.652315</td>\n",
       "      <td>0.617460</td>\n",
       "      <td>0.671582</td>\n",
       "      <td>0.639492</td>\n",
       "      <td>0.688920</td>\n",
       "      <td>0.637627</td>\n",
       "      <td>0.630693</td>\n",
       "      <td>0.602609</td>\n",
       "      <td>0.660946</td>\n",
       "      <td>0.678021</td>\n",
       "      <td>0.636703</td>\n",
       "      <td>0.589921</td>\n",
       "      <td>0.661056</td>\n",
       "      <td>0.614819</td>\n",
       "      <td>0.683304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 11:30:00</th>\n",
       "      <td>0.637627</td>\n",
       "      <td>0.630693</td>\n",
       "      <td>0.602609</td>\n",
       "      <td>0.660946</td>\n",
       "      <td>0.678021</td>\n",
       "      <td>0.636703</td>\n",
       "      <td>0.589921</td>\n",
       "      <td>0.661056</td>\n",
       "      <td>0.614819</td>\n",
       "      <td>0.683304</td>\n",
       "      <td>0.627008</td>\n",
       "      <td>0.615504</td>\n",
       "      <td>0.584307</td>\n",
       "      <td>0.650187</td>\n",
       "      <td>0.668598</td>\n",
       "      <td>0.620500</td>\n",
       "      <td>0.567993</td>\n",
       "      <td>0.649513</td>\n",
       "      <td>0.593752</td>\n",
       "      <td>0.675558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 11:45:00</th>\n",
       "      <td>0.627008</td>\n",
       "      <td>0.615504</td>\n",
       "      <td>0.584307</td>\n",
       "      <td>0.650187</td>\n",
       "      <td>0.668598</td>\n",
       "      <td>0.620500</td>\n",
       "      <td>0.567993</td>\n",
       "      <td>0.649513</td>\n",
       "      <td>0.593752</td>\n",
       "      <td>0.675558</td>\n",
       "      <td>0.626446</td>\n",
       "      <td>0.612340</td>\n",
       "      <td>0.580634</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.663098</td>\n",
       "      <td>0.616169</td>\n",
       "      <td>0.564492</td>\n",
       "      <td>0.646717</td>\n",
       "      <td>0.589524</td>\n",
       "      <td>0.671423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 12:00:00</th>\n",
       "      <td>0.626446</td>\n",
       "      <td>0.612340</td>\n",
       "      <td>0.580634</td>\n",
       "      <td>0.648092</td>\n",
       "      <td>0.663098</td>\n",
       "      <td>0.616169</td>\n",
       "      <td>0.564492</td>\n",
       "      <td>0.646717</td>\n",
       "      <td>0.589524</td>\n",
       "      <td>0.671423</td>\n",
       "      <td>0.644203</td>\n",
       "      <td>0.628898</td>\n",
       "      <td>0.598676</td>\n",
       "      <td>0.662596</td>\n",
       "      <td>0.670925</td>\n",
       "      <td>0.630641</td>\n",
       "      <td>0.584225</td>\n",
       "      <td>0.660114</td>\n",
       "      <td>0.606934</td>\n",
       "      <td>0.679641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 12:15:00</th>\n",
       "      <td>0.644203</td>\n",
       "      <td>0.628898</td>\n",
       "      <td>0.598676</td>\n",
       "      <td>0.662596</td>\n",
       "      <td>0.670925</td>\n",
       "      <td>0.630641</td>\n",
       "      <td>0.584225</td>\n",
       "      <td>0.660114</td>\n",
       "      <td>0.606934</td>\n",
       "      <td>0.679641</td>\n",
       "      <td>0.664259</td>\n",
       "      <td>0.652051</td>\n",
       "      <td>0.626036</td>\n",
       "      <td>0.678810</td>\n",
       "      <td>0.679951</td>\n",
       "      <td>0.651547</td>\n",
       "      <td>0.617110</td>\n",
       "      <td>0.675592</td>\n",
       "      <td>0.636412</td>\n",
       "      <td>0.689288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 12:30:00</th>\n",
       "      <td>0.664259</td>\n",
       "      <td>0.652051</td>\n",
       "      <td>0.626036</td>\n",
       "      <td>0.678810</td>\n",
       "      <td>0.679951</td>\n",
       "      <td>0.651547</td>\n",
       "      <td>0.617110</td>\n",
       "      <td>0.675592</td>\n",
       "      <td>0.636412</td>\n",
       "      <td>0.689288</td>\n",
       "      <td>0.675471</td>\n",
       "      <td>0.666924</td>\n",
       "      <td>0.645715</td>\n",
       "      <td>0.686586</td>\n",
       "      <td>0.681822</td>\n",
       "      <td>0.663536</td>\n",
       "      <td>0.640922</td>\n",
       "      <td>0.682967</td>\n",
       "      <td>0.655604</td>\n",
       "      <td>0.691882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-01 12:45:00</th>\n",
       "      <td>0.675471</td>\n",
       "      <td>0.666924</td>\n",
       "      <td>0.645715</td>\n",
       "      <td>0.686586</td>\n",
       "      <td>0.681822</td>\n",
       "      <td>0.663536</td>\n",
       "      <td>0.640922</td>\n",
       "      <td>0.682967</td>\n",
       "      <td>0.655604</td>\n",
       "      <td>0.691882</td>\n",
       "      <td>0.700399</td>\n",
       "      <td>0.693942</td>\n",
       "      <td>0.678915</td>\n",
       "      <td>0.708200</td>\n",
       "      <td>0.700004</td>\n",
       "      <td>0.688755</td>\n",
       "      <td>0.676937</td>\n",
       "      <td>0.703879</td>\n",
       "      <td>0.685637</td>\n",
       "      <td>0.709954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 12:45:00</th>\n",
       "      <td>0.831259</td>\n",
       "      <td>0.844365</td>\n",
       "      <td>0.848615</td>\n",
       "      <td>0.837815</td>\n",
       "      <td>0.829182</td>\n",
       "      <td>0.839503</td>\n",
       "      <td>0.882490</td>\n",
       "      <td>0.836366</td>\n",
       "      <td>0.880274</td>\n",
       "      <td>0.829498</td>\n",
       "      <td>0.830889</td>\n",
       "      <td>0.844071</td>\n",
       "      <td>0.848268</td>\n",
       "      <td>0.837580</td>\n",
       "      <td>0.828524</td>\n",
       "      <td>0.838962</td>\n",
       "      <td>0.882277</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.880046</td>\n",
       "      <td>0.829771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 13:00:00</th>\n",
       "      <td>0.830889</td>\n",
       "      <td>0.844071</td>\n",
       "      <td>0.848268</td>\n",
       "      <td>0.837580</td>\n",
       "      <td>0.828524</td>\n",
       "      <td>0.838962</td>\n",
       "      <td>0.882277</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.880046</td>\n",
       "      <td>0.829771</td>\n",
       "      <td>0.826181</td>\n",
       "      <td>0.839536</td>\n",
       "      <td>0.843591</td>\n",
       "      <td>0.833136</td>\n",
       "      <td>0.823531</td>\n",
       "      <td>0.833850</td>\n",
       "      <td>0.877550</td>\n",
       "      <td>0.832280</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.825873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 13:15:00</th>\n",
       "      <td>0.826181</td>\n",
       "      <td>0.839536</td>\n",
       "      <td>0.843591</td>\n",
       "      <td>0.833136</td>\n",
       "      <td>0.823531</td>\n",
       "      <td>0.833850</td>\n",
       "      <td>0.877550</td>\n",
       "      <td>0.832280</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.825873</td>\n",
       "      <td>0.816661</td>\n",
       "      <td>0.830235</td>\n",
       "      <td>0.834050</td>\n",
       "      <td>0.823996</td>\n",
       "      <td>0.813806</td>\n",
       "      <td>0.823643</td>\n",
       "      <td>0.867653</td>\n",
       "      <td>0.823369</td>\n",
       "      <td>0.865314</td>\n",
       "      <td>0.817358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 13:30:00</th>\n",
       "      <td>0.816661</td>\n",
       "      <td>0.830235</td>\n",
       "      <td>0.834050</td>\n",
       "      <td>0.823996</td>\n",
       "      <td>0.813806</td>\n",
       "      <td>0.823643</td>\n",
       "      <td>0.867653</td>\n",
       "      <td>0.823369</td>\n",
       "      <td>0.865314</td>\n",
       "      <td>0.817358</td>\n",
       "      <td>0.801900</td>\n",
       "      <td>0.815732</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.809697</td>\n",
       "      <td>0.798892</td>\n",
       "      <td>0.807801</td>\n",
       "      <td>0.852100</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.849697</td>\n",
       "      <td>0.803691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 13:45:00</th>\n",
       "      <td>0.801900</td>\n",
       "      <td>0.815732</td>\n",
       "      <td>0.819209</td>\n",
       "      <td>0.809697</td>\n",
       "      <td>0.798892</td>\n",
       "      <td>0.807801</td>\n",
       "      <td>0.852100</td>\n",
       "      <td>0.809160</td>\n",
       "      <td>0.849697</td>\n",
       "      <td>0.803691</td>\n",
       "      <td>0.781377</td>\n",
       "      <td>0.795449</td>\n",
       "      <td>0.798503</td>\n",
       "      <td>0.789701</td>\n",
       "      <td>0.778264</td>\n",
       "      <td>0.785758</td>\n",
       "      <td>0.830311</td>\n",
       "      <td>0.789046</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.784248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 14:00:00</th>\n",
       "      <td>0.781377</td>\n",
       "      <td>0.795449</td>\n",
       "      <td>0.798503</td>\n",
       "      <td>0.789701</td>\n",
       "      <td>0.778264</td>\n",
       "      <td>0.785758</td>\n",
       "      <td>0.830311</td>\n",
       "      <td>0.789046</td>\n",
       "      <td>0.827914</td>\n",
       "      <td>0.784248</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.768798</td>\n",
       "      <td>0.771392</td>\n",
       "      <td>0.763411</td>\n",
       "      <td>0.751486</td>\n",
       "      <td>0.756969</td>\n",
       "      <td>0.801697</td>\n",
       "      <td>0.762466</td>\n",
       "      <td>0.799369</td>\n",
       "      <td>0.758501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 14:15:00</th>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.768798</td>\n",
       "      <td>0.771392</td>\n",
       "      <td>0.763411</td>\n",
       "      <td>0.751486</td>\n",
       "      <td>0.756969</td>\n",
       "      <td>0.801697</td>\n",
       "      <td>0.762466</td>\n",
       "      <td>0.799369</td>\n",
       "      <td>0.758501</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>0.735552</td>\n",
       "      <td>0.737640</td>\n",
       "      <td>0.730580</td>\n",
       "      <td>0.718327</td>\n",
       "      <td>0.721276</td>\n",
       "      <td>0.766038</td>\n",
       "      <td>0.729190</td>\n",
       "      <td>0.763877</td>\n",
       "      <td>0.726187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 14:30:00</th>\n",
       "      <td>0.721195</td>\n",
       "      <td>0.735552</td>\n",
       "      <td>0.737640</td>\n",
       "      <td>0.730580</td>\n",
       "      <td>0.718327</td>\n",
       "      <td>0.721276</td>\n",
       "      <td>0.766038</td>\n",
       "      <td>0.729190</td>\n",
       "      <td>0.763877</td>\n",
       "      <td>0.726187</td>\n",
       "      <td>0.681259</td>\n",
       "      <td>0.695578</td>\n",
       "      <td>0.697162</td>\n",
       "      <td>0.691067</td>\n",
       "      <td>0.678693</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.723252</td>\n",
       "      <td>0.689099</td>\n",
       "      <td>0.721395</td>\n",
       "      <td>0.687145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 14:45:00</th>\n",
       "      <td>0.681259</td>\n",
       "      <td>0.695578</td>\n",
       "      <td>0.697162</td>\n",
       "      <td>0.691067</td>\n",
       "      <td>0.678693</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.723252</td>\n",
       "      <td>0.689099</td>\n",
       "      <td>0.721395</td>\n",
       "      <td>0.687145</td>\n",
       "      <td>0.634428</td>\n",
       "      <td>0.648474</td>\n",
       "      <td>0.649515</td>\n",
       "      <td>0.644538</td>\n",
       "      <td>0.632376</td>\n",
       "      <td>0.628923</td>\n",
       "      <td>0.672871</td>\n",
       "      <td>0.641898</td>\n",
       "      <td>0.671525</td>\n",
       "      <td>0.641111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 15:00:00</th>\n",
       "      <td>0.634428</td>\n",
       "      <td>0.648474</td>\n",
       "      <td>0.649515</td>\n",
       "      <td>0.644538</td>\n",
       "      <td>0.632376</td>\n",
       "      <td>0.628923</td>\n",
       "      <td>0.672871</td>\n",
       "      <td>0.641898</td>\n",
       "      <td>0.671525</td>\n",
       "      <td>0.641111</td>\n",
       "      <td>0.580264</td>\n",
       "      <td>0.593639</td>\n",
       "      <td>0.594099</td>\n",
       "      <td>0.590579</td>\n",
       "      <td>0.579062</td>\n",
       "      <td>0.571715</td>\n",
       "      <td>0.614276</td>\n",
       "      <td>0.587251</td>\n",
       "      <td>0.613812</td>\n",
       "      <td>0.587719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 15:15:00</th>\n",
       "      <td>0.580264</td>\n",
       "      <td>0.593639</td>\n",
       "      <td>0.594099</td>\n",
       "      <td>0.590579</td>\n",
       "      <td>0.579062</td>\n",
       "      <td>0.571715</td>\n",
       "      <td>0.614276</td>\n",
       "      <td>0.587251</td>\n",
       "      <td>0.613812</td>\n",
       "      <td>0.587719</td>\n",
       "      <td>0.518473</td>\n",
       "      <td>0.530706</td>\n",
       "      <td>0.530526</td>\n",
       "      <td>0.528834</td>\n",
       "      <td>0.518612</td>\n",
       "      <td>0.506758</td>\n",
       "      <td>0.547049</td>\n",
       "      <td>0.524771</td>\n",
       "      <td>0.547715</td>\n",
       "      <td>0.526810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 15:30:00</th>\n",
       "      <td>0.518473</td>\n",
       "      <td>0.530706</td>\n",
       "      <td>0.530526</td>\n",
       "      <td>0.528834</td>\n",
       "      <td>0.518612</td>\n",
       "      <td>0.506758</td>\n",
       "      <td>0.547049</td>\n",
       "      <td>0.524771</td>\n",
       "      <td>0.547715</td>\n",
       "      <td>0.526810</td>\n",
       "      <td>0.454806</td>\n",
       "      <td>0.466085</td>\n",
       "      <td>0.466172</td>\n",
       "      <td>0.464090</td>\n",
       "      <td>0.455214</td>\n",
       "      <td>0.440598</td>\n",
       "      <td>0.479367</td>\n",
       "      <td>0.459059</td>\n",
       "      <td>0.480702</td>\n",
       "      <td>0.461579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 15:45:00</th>\n",
       "      <td>0.454806</td>\n",
       "      <td>0.466085</td>\n",
       "      <td>0.466172</td>\n",
       "      <td>0.464090</td>\n",
       "      <td>0.455214</td>\n",
       "      <td>0.440598</td>\n",
       "      <td>0.479367</td>\n",
       "      <td>0.459059</td>\n",
       "      <td>0.480702</td>\n",
       "      <td>0.461579</td>\n",
       "      <td>0.393463</td>\n",
       "      <td>0.403563</td>\n",
       "      <td>0.404037</td>\n",
       "      <td>0.401697</td>\n",
       "      <td>0.395832</td>\n",
       "      <td>0.377529</td>\n",
       "      <td>0.414317</td>\n",
       "      <td>0.395962</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>0.399787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 16:00:00</th>\n",
       "      <td>0.393463</td>\n",
       "      <td>0.403563</td>\n",
       "      <td>0.404037</td>\n",
       "      <td>0.401697</td>\n",
       "      <td>0.395832</td>\n",
       "      <td>0.377529</td>\n",
       "      <td>0.414317</td>\n",
       "      <td>0.395962</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>0.399787</td>\n",
       "      <td>0.330415</td>\n",
       "      <td>0.338879</td>\n",
       "      <td>0.339534</td>\n",
       "      <td>0.337453</td>\n",
       "      <td>0.335208</td>\n",
       "      <td>0.314086</td>\n",
       "      <td>0.347778</td>\n",
       "      <td>0.331327</td>\n",
       "      <td>0.350816</td>\n",
       "      <td>0.336431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 16:15:00</th>\n",
       "      <td>0.330415</td>\n",
       "      <td>0.338879</td>\n",
       "      <td>0.339534</td>\n",
       "      <td>0.337453</td>\n",
       "      <td>0.335208</td>\n",
       "      <td>0.314086</td>\n",
       "      <td>0.347778</td>\n",
       "      <td>0.331327</td>\n",
       "      <td>0.350816</td>\n",
       "      <td>0.336431</td>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.276867</td>\n",
       "      <td>0.277869</td>\n",
       "      <td>0.275115</td>\n",
       "      <td>0.274588</td>\n",
       "      <td>0.253470</td>\n",
       "      <td>0.283687</td>\n",
       "      <td>0.269491</td>\n",
       "      <td>0.288092</td>\n",
       "      <td>0.273557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 16:30:00</th>\n",
       "      <td>0.269382</td>\n",
       "      <td>0.276867</td>\n",
       "      <td>0.277869</td>\n",
       "      <td>0.275115</td>\n",
       "      <td>0.274588</td>\n",
       "      <td>0.253470</td>\n",
       "      <td>0.283687</td>\n",
       "      <td>0.269491</td>\n",
       "      <td>0.288092</td>\n",
       "      <td>0.273557</td>\n",
       "      <td>0.213825</td>\n",
       "      <td>0.221035</td>\n",
       "      <td>0.221536</td>\n",
       "      <td>0.219797</td>\n",
       "      <td>0.219446</td>\n",
       "      <td>0.201190</td>\n",
       "      <td>0.226705</td>\n",
       "      <td>0.215409</td>\n",
       "      <td>0.232567</td>\n",
       "      <td>0.218136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 16:45:00</th>\n",
       "      <td>0.213825</td>\n",
       "      <td>0.221035</td>\n",
       "      <td>0.221536</td>\n",
       "      <td>0.219797</td>\n",
       "      <td>0.219446</td>\n",
       "      <td>0.201190</td>\n",
       "      <td>0.226705</td>\n",
       "      <td>0.215409</td>\n",
       "      <td>0.232567</td>\n",
       "      <td>0.218136</td>\n",
       "      <td>0.166550</td>\n",
       "      <td>0.173571</td>\n",
       "      <td>0.173649</td>\n",
       "      <td>0.172687</td>\n",
       "      <td>0.172524</td>\n",
       "      <td>0.157485</td>\n",
       "      <td>0.178910</td>\n",
       "      <td>0.169662</td>\n",
       "      <td>0.185293</td>\n",
       "      <td>0.171192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 17:00:00</th>\n",
       "      <td>0.166550</td>\n",
       "      <td>0.173571</td>\n",
       "      <td>0.173649</td>\n",
       "      <td>0.172687</td>\n",
       "      <td>0.172524</td>\n",
       "      <td>0.157485</td>\n",
       "      <td>0.178910</td>\n",
       "      <td>0.169662</td>\n",
       "      <td>0.185293</td>\n",
       "      <td>0.171192</td>\n",
       "      <td>0.128704</td>\n",
       "      <td>0.135523</td>\n",
       "      <td>0.135254</td>\n",
       "      <td>0.134891</td>\n",
       "      <td>0.134603</td>\n",
       "      <td>0.122977</td>\n",
       "      <td>0.140799</td>\n",
       "      <td>0.133091</td>\n",
       "      <td>0.147354</td>\n",
       "      <td>0.133483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 17:15:00</th>\n",
       "      <td>0.128704</td>\n",
       "      <td>0.135523</td>\n",
       "      <td>0.135254</td>\n",
       "      <td>0.134891</td>\n",
       "      <td>0.134603</td>\n",
       "      <td>0.122977</td>\n",
       "      <td>0.140799</td>\n",
       "      <td>0.133091</td>\n",
       "      <td>0.147354</td>\n",
       "      <td>0.133483</td>\n",
       "      <td>0.095405</td>\n",
       "      <td>0.101683</td>\n",
       "      <td>0.101253</td>\n",
       "      <td>0.101128</td>\n",
       "      <td>0.100593</td>\n",
       "      <td>0.092338</td>\n",
       "      <td>0.106809</td>\n",
       "      <td>0.100173</td>\n",
       "      <td>0.112979</td>\n",
       "      <td>0.099553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 17:30:00</th>\n",
       "      <td>0.095405</td>\n",
       "      <td>0.101683</td>\n",
       "      <td>0.101253</td>\n",
       "      <td>0.101128</td>\n",
       "      <td>0.100593</td>\n",
       "      <td>0.092338</td>\n",
       "      <td>0.106809</td>\n",
       "      <td>0.100173</td>\n",
       "      <td>0.112979</td>\n",
       "      <td>0.099553</td>\n",
       "      <td>0.066893</td>\n",
       "      <td>0.072181</td>\n",
       "      <td>0.071761</td>\n",
       "      <td>0.071742</td>\n",
       "      <td>0.071057</td>\n",
       "      <td>0.065788</td>\n",
       "      <td>0.076995</td>\n",
       "      <td>0.071346</td>\n",
       "      <td>0.082472</td>\n",
       "      <td>0.070115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 17:45:00</th>\n",
       "      <td>0.066893</td>\n",
       "      <td>0.072181</td>\n",
       "      <td>0.071761</td>\n",
       "      <td>0.071742</td>\n",
       "      <td>0.071057</td>\n",
       "      <td>0.065788</td>\n",
       "      <td>0.076995</td>\n",
       "      <td>0.071346</td>\n",
       "      <td>0.082472</td>\n",
       "      <td>0.070115</td>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.049465</td>\n",
       "      <td>0.049078</td>\n",
       "      <td>0.049172</td>\n",
       "      <td>0.048374</td>\n",
       "      <td>0.045582</td>\n",
       "      <td>0.053841</td>\n",
       "      <td>0.049141</td>\n",
       "      <td>0.058522</td>\n",
       "      <td>0.047628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 18:00:00</th>\n",
       "      <td>0.045264</td>\n",
       "      <td>0.049465</td>\n",
       "      <td>0.049078</td>\n",
       "      <td>0.049172</td>\n",
       "      <td>0.048374</td>\n",
       "      <td>0.045582</td>\n",
       "      <td>0.053841</td>\n",
       "      <td>0.049141</td>\n",
       "      <td>0.058522</td>\n",
       "      <td>0.047628</td>\n",
       "      <td>0.030025</td>\n",
       "      <td>0.033204</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.033013</td>\n",
       "      <td>0.032048</td>\n",
       "      <td>0.031299</td>\n",
       "      <td>0.037183</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.031576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 18:15:00</th>\n",
       "      <td>0.030025</td>\n",
       "      <td>0.033204</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.033013</td>\n",
       "      <td>0.032048</td>\n",
       "      <td>0.031299</td>\n",
       "      <td>0.037183</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>0.041071</td>\n",
       "      <td>0.031576</td>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.022193</td>\n",
       "      <td>0.022354</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.022628</td>\n",
       "      <td>0.029251</td>\n",
       "      <td>0.021007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 18:30:00</th>\n",
       "      <td>0.020198</td>\n",
       "      <td>0.022481</td>\n",
       "      <td>0.022193</td>\n",
       "      <td>0.022354</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.022628</td>\n",
       "      <td>0.029251</td>\n",
       "      <td>0.021007</td>\n",
       "      <td>0.014934</td>\n",
       "      <td>0.016492</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.016735</td>\n",
       "      <td>0.019755</td>\n",
       "      <td>0.016618</td>\n",
       "      <td>0.022255</td>\n",
       "      <td>0.015187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 18:45:00</th>\n",
       "      <td>0.014934</td>\n",
       "      <td>0.016492</td>\n",
       "      <td>0.016273</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.016735</td>\n",
       "      <td>0.019755</td>\n",
       "      <td>0.016618</td>\n",
       "      <td>0.022255</td>\n",
       "      <td>0.015187</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.012881</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>0.019160</td>\n",
       "      <td>0.012954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 19:00:00</th>\n",
       "      <td>0.013282</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.012881</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>0.019160</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>0.016782</td>\n",
       "      <td>0.013851</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>0.012751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 19:15:00</th>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.014150</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014037</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>0.016782</td>\n",
       "      <td>0.013851</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>0.012751</td>\n",
       "      <td>0.014692</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.014859</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.013344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 19:30:00</th>\n",
       "      <td>0.014692</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.014859</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.017116</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>0.018526</td>\n",
       "      <td>0.013344</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.015453</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.014144</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.017289</td>\n",
       "      <td>0.014504</td>\n",
       "      <td>0.018689</td>\n",
       "      <td>0.013880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 19:45:00</th>\n",
       "      <td>0.015591</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.015453</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.014144</td>\n",
       "      <td>0.015417</td>\n",
       "      <td>0.017289</td>\n",
       "      <td>0.014504</td>\n",
       "      <td>0.018689</td>\n",
       "      <td>0.013880</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.015111</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>0.014957</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>0.016961</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.018416</td>\n",
       "      <td>0.013707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-14 20:00:00</th>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.015111</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>0.014957</td>\n",
       "      <td>0.014172</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>0.016961</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.018416</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.014105</td>\n",
       "      <td>0.014446</td>\n",
       "      <td>0.013785</td>\n",
       "      <td>0.013312</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.015881</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>0.012731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>852 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  \\\n",
       "datetime                                                                     \n",
       "2010-11-01 05:30:00   0.032268   0.032775   0.033418   0.030716   0.029538   \n",
       "2010-11-01 05:45:00   0.032415   0.032403   0.033381   0.030563   0.029318   \n",
       "2010-11-01 06:00:00   0.030912   0.030643   0.031807   0.029033   0.027722   \n",
       "2010-11-01 06:15:00   0.026961   0.026518   0.027374   0.025704   0.025196   \n",
       "2010-11-01 06:30:00   0.020411   0.019889   0.020225   0.020467   0.020644   \n",
       "2010-11-01 06:45:00   0.014629   0.014738   0.014465   0.015727   0.015674   \n",
       "2010-11-01 07:00:00   0.011575   0.012350   0.011178   0.014047   0.014060   \n",
       "2010-11-01 07:15:00   0.012748   0.014152   0.012166   0.016840   0.017695   \n",
       "2010-11-01 07:30:00   0.020101   0.022542   0.020262   0.025921   0.027364   \n",
       "2010-11-01 07:45:00   0.040105   0.043592   0.041342   0.047447   0.048437   \n",
       "2010-11-01 08:00:00   0.073831   0.079248   0.077749   0.082244   0.081812   \n",
       "2010-11-01 08:15:00   0.116279   0.124425   0.124007   0.125547   0.123085   \n",
       "2010-11-01 08:30:00   0.164904   0.175740   0.176726   0.174910   0.170643   \n",
       "2010-11-01 08:45:00   0.221257   0.234301   0.236635   0.231856   0.226432   \n",
       "2010-11-01 09:00:00   0.284905   0.299676   0.303037   0.296080   0.289875   \n",
       "2010-11-01 09:15:00   0.353067   0.369163   0.373142   0.364907   0.358404   \n",
       "2010-11-01 09:30:00   0.421526   0.438338   0.442255   0.434234   0.428124   \n",
       "2010-11-01 09:45:00   0.485745   0.502506   0.505560   0.499493   0.494683   \n",
       "2010-11-01 10:00:00   0.542919   0.558690   0.560023   0.557801   0.554874   \n",
       "2010-11-01 10:15:00   0.595321   0.608926   0.607790   0.611526   0.611331   \n",
       "2010-11-01 10:30:00   0.631988   0.642814   0.637705   0.649916   0.653777   \n",
       "2010-11-01 10:45:00   0.650558   0.657713   0.647136   0.670614   0.679029   \n",
       "2010-11-01 11:00:00   0.653822   0.656733   0.640228   0.675676   0.687173   \n",
       "2010-11-01 11:15:00   0.648692   0.647231   0.624605   0.671061   0.684814   \n",
       "2010-11-01 11:30:00   0.637627   0.630693   0.602609   0.660946   0.678021   \n",
       "2010-11-01 11:45:00   0.627008   0.615504   0.584307   0.650187   0.668598   \n",
       "2010-11-01 12:00:00   0.626446   0.612340   0.580634   0.648092   0.663098   \n",
       "2010-11-01 12:15:00   0.644203   0.628898   0.598676   0.662596   0.670925   \n",
       "2010-11-01 12:30:00   0.664259   0.652051   0.626036   0.678810   0.679951   \n",
       "2010-11-01 12:45:00   0.675471   0.666924   0.645715   0.686586   0.681822   \n",
       "...                        ...        ...        ...        ...        ...   \n",
       "2010-11-14 12:45:00   0.831259   0.844365   0.848615   0.837815   0.829182   \n",
       "2010-11-14 13:00:00   0.830889   0.844071   0.848268   0.837580   0.828524   \n",
       "2010-11-14 13:15:00   0.826181   0.839536   0.843591   0.833136   0.823531   \n",
       "2010-11-14 13:30:00   0.816661   0.830235   0.834050   0.823996   0.813806   \n",
       "2010-11-14 13:45:00   0.801900   0.815732   0.819209   0.809697   0.798892   \n",
       "2010-11-14 14:00:00   0.781377   0.795449   0.798503   0.789701   0.778264   \n",
       "2010-11-14 14:15:00   0.754545   0.768798   0.771392   0.763411   0.751486   \n",
       "2010-11-14 14:30:00   0.721195   0.735552   0.737640   0.730580   0.718327   \n",
       "2010-11-14 14:45:00   0.681259   0.695578   0.697162   0.691067   0.678693   \n",
       "2010-11-14 15:00:00   0.634428   0.648474   0.649515   0.644538   0.632376   \n",
       "2010-11-14 15:15:00   0.580264   0.593639   0.594099   0.590579   0.579062   \n",
       "2010-11-14 15:30:00   0.518473   0.530706   0.530526   0.528834   0.518612   \n",
       "2010-11-14 15:45:00   0.454806   0.466085   0.466172   0.464090   0.455214   \n",
       "2010-11-14 16:00:00   0.393463   0.403563   0.404037   0.401697   0.395832   \n",
       "2010-11-14 16:15:00   0.330415   0.338879   0.339534   0.337453   0.335208   \n",
       "2010-11-14 16:30:00   0.269382   0.276867   0.277869   0.275115   0.274588   \n",
       "2010-11-14 16:45:00   0.213825   0.221035   0.221536   0.219797   0.219446   \n",
       "2010-11-14 17:00:00   0.166550   0.173571   0.173649   0.172687   0.172524   \n",
       "2010-11-14 17:15:00   0.128704   0.135523   0.135254   0.134891   0.134603   \n",
       "2010-11-14 17:30:00   0.095405   0.101683   0.101253   0.101128   0.100593   \n",
       "2010-11-14 17:45:00   0.066893   0.072181   0.071761   0.071742   0.071057   \n",
       "2010-11-14 18:00:00   0.045264   0.049465   0.049078   0.049172   0.048374   \n",
       "2010-11-14 18:15:00   0.030025   0.033204   0.032857   0.033013   0.032048   \n",
       "2010-11-14 18:30:00   0.020198   0.022481   0.022193   0.022354   0.021216   \n",
       "2010-11-14 18:45:00   0.014934   0.016492   0.016273   0.016407   0.015200   \n",
       "2010-11-14 19:00:00   0.013282   0.014271   0.014151   0.014183   0.012881   \n",
       "2010-11-14 19:15:00   0.013636   0.014150   0.014142   0.014037   0.012713   \n",
       "2010-11-14 19:30:00   0.014692   0.014779   0.014859   0.014645   0.013437   \n",
       "2010-11-14 19:45:00   0.015591   0.015304   0.015453   0.015202   0.014144   \n",
       "2010-11-14 20:00:00   0.015621   0.015111   0.015398   0.014957   0.014172   \n",
       "\n",
       "                     var6(t-2)  var7(t-2)  var8(t-2)  var9(t-2)  var10(t-2)  \\\n",
       "datetime                                                                      \n",
       "2010-11-01 05:30:00   0.034313   0.036917   0.031167   0.037800    0.029590   \n",
       "2010-11-01 05:45:00   0.033496   0.036665   0.030459   0.037285    0.028936   \n",
       "2010-11-01 06:00:00   0.031662   0.034615   0.028735   0.035647    0.027221   \n",
       "2010-11-01 06:15:00   0.027489   0.029438   0.025294   0.031331    0.024780   \n",
       "2010-11-01 06:30:00   0.020590   0.021382   0.020044   0.024133    0.020141   \n",
       "2010-11-01 06:45:00   0.014613   0.015152   0.015479   0.018371    0.015190   \n",
       "2010-11-01 07:00:00   0.011183   0.011505   0.013773   0.015211    0.013415   \n",
       "2010-11-01 07:15:00   0.011218   0.012115   0.016231   0.015978    0.016919   \n",
       "2010-11-01 07:30:00   0.017612   0.020780   0.024922   0.024400    0.026634   \n",
       "2010-11-01 07:45:00   0.036437   0.042836   0.045936   0.045803    0.047621   \n",
       "2010-11-01 08:00:00   0.069991   0.081825   0.080165   0.083828    0.080798   \n",
       "2010-11-01 08:15:00   0.113103   0.131692   0.122944   0.132828    0.121976   \n",
       "2010-11-01 08:30:00   0.162863   0.188161   0.171817   0.188591    0.169461   \n",
       "2010-11-01 08:45:00   0.220433   0.250997   0.228340   0.250682    0.225126   \n",
       "2010-11-01 09:00:00   0.285498   0.319654   0.292186   0.318916    0.288570   \n",
       "2010-11-01 09:15:00   0.355426   0.391699   0.360824   0.391097    0.357233   \n",
       "2010-11-01 09:30:00   0.425813   0.462135   0.430196   0.462465    0.427252   \n",
       "2010-11-01 09:45:00   0.491748   0.525652   0.495661   0.527622    0.494202   \n",
       "2010-11-01 10:00:00   0.550111   0.578472   0.554233   0.582676    0.554763   \n",
       "2010-11-01 10:15:00   0.603248   0.622823   0.608380   0.629944    0.611545   \n",
       "2010-11-01 10:30:00   0.640627   0.647986   0.647784   0.658855    0.654735   \n",
       "2010-11-01 10:45:00   0.658599   0.651696   0.669454   0.666735    0.680853   \n",
       "2010-11-01 11:00:00   0.660159   0.638698   0.675538   0.657439    0.689895   \n",
       "2010-11-01 11:15:00   0.652315   0.617460   0.671582   0.639492    0.688920   \n",
       "2010-11-01 11:30:00   0.636703   0.589921   0.661056   0.614819    0.683304   \n",
       "2010-11-01 11:45:00   0.620500   0.567993   0.649513   0.593752    0.675558   \n",
       "2010-11-01 12:00:00   0.616169   0.564492   0.646717   0.589524    0.671423   \n",
       "2010-11-01 12:15:00   0.630641   0.584225   0.660114   0.606934    0.679641   \n",
       "2010-11-01 12:30:00   0.651547   0.617110   0.675592   0.636412    0.689288   \n",
       "2010-11-01 12:45:00   0.663536   0.640922   0.682967   0.655604    0.691882   \n",
       "...                        ...        ...        ...        ...         ...   \n",
       "2010-11-14 12:45:00   0.839503   0.882490   0.836366   0.880274    0.829498   \n",
       "2010-11-14 13:00:00   0.838962   0.882277   0.836443   0.880046    0.829771   \n",
       "2010-11-14 13:15:00   0.833850   0.877550   0.832280   0.875271    0.825873   \n",
       "2010-11-14 13:30:00   0.823643   0.867653   0.823369   0.865314    0.817358   \n",
       "2010-11-14 13:45:00   0.807801   0.852100   0.809160   0.849697    0.803691   \n",
       "2010-11-14 14:00:00   0.785758   0.830311   0.789046   0.827914    0.784248   \n",
       "2010-11-14 14:15:00   0.756969   0.801697   0.762466   0.799369    0.758501   \n",
       "2010-11-14 14:30:00   0.721276   0.766038   0.729190   0.763877    0.726187   \n",
       "2010-11-14 14:45:00   0.678668   0.723252   0.689099   0.721395    0.687145   \n",
       "2010-11-14 15:00:00   0.628923   0.672871   0.641898   0.671525    0.641111   \n",
       "2010-11-14 15:15:00   0.571715   0.614276   0.587251   0.613812    0.587719   \n",
       "2010-11-14 15:30:00   0.506758   0.547049   0.524771   0.547715    0.526810   \n",
       "2010-11-14 15:45:00   0.440598   0.479367   0.459059   0.480702    0.461579   \n",
       "2010-11-14 16:00:00   0.377529   0.414317   0.395962   0.416145    0.399787   \n",
       "2010-11-14 16:15:00   0.314086   0.347778   0.331327   0.350816    0.336431   \n",
       "2010-11-14 16:30:00   0.253470   0.283687   0.269491   0.288092    0.273557   \n",
       "2010-11-14 16:45:00   0.201190   0.226705   0.215409   0.232567    0.218136   \n",
       "2010-11-14 17:00:00   0.157485   0.178910   0.169662   0.185293    0.171192   \n",
       "2010-11-14 17:15:00   0.122977   0.140799   0.133091   0.147354    0.133483   \n",
       "2010-11-14 17:30:00   0.092338   0.106809   0.100173   0.112979    0.099553   \n",
       "2010-11-14 17:45:00   0.065788   0.076995   0.071346   0.082472    0.070115   \n",
       "2010-11-14 18:00:00   0.045582   0.053841   0.049141   0.058522    0.047628   \n",
       "2010-11-14 18:15:00   0.031299   0.037183   0.033210   0.041071    0.031576   \n",
       "2010-11-14 18:30:00   0.021951   0.026101   0.022628   0.029251    0.021007   \n",
       "2010-11-14 18:45:00   0.016735   0.019755   0.016618   0.022255    0.015187   \n",
       "2010-11-14 19:00:00   0.014815   0.017200   0.014229   0.019160    0.012954   \n",
       "2010-11-14 19:15:00   0.014684   0.016782   0.013851   0.018370    0.012751   \n",
       "2010-11-14 19:30:00   0.015125   0.017116   0.014205   0.018526    0.013344   \n",
       "2010-11-14 19:45:00   0.015417   0.017289   0.014504   0.018689    0.013880   \n",
       "2010-11-14 20:00:00   0.015021   0.016961   0.014079   0.018416    0.013707   \n",
       "\n",
       "                     var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  \\\n",
       "datetime                                                                     \n",
       "2010-11-01 05:30:00   0.032415   0.032403   0.033381   0.030563   0.029318   \n",
       "2010-11-01 05:45:00   0.030912   0.030643   0.031807   0.029033   0.027722   \n",
       "2010-11-01 06:00:00   0.026961   0.026518   0.027374   0.025704   0.025196   \n",
       "2010-11-01 06:15:00   0.020411   0.019889   0.020225   0.020467   0.020644   \n",
       "2010-11-01 06:30:00   0.014629   0.014738   0.014465   0.015727   0.015674   \n",
       "2010-11-01 06:45:00   0.011575   0.012350   0.011178   0.014047   0.014060   \n",
       "2010-11-01 07:00:00   0.012748   0.014152   0.012166   0.016840   0.017695   \n",
       "2010-11-01 07:15:00   0.020101   0.022542   0.020262   0.025921   0.027364   \n",
       "2010-11-01 07:30:00   0.040105   0.043592   0.041342   0.047447   0.048437   \n",
       "2010-11-01 07:45:00   0.073831   0.079248   0.077749   0.082244   0.081812   \n",
       "2010-11-01 08:00:00   0.116279   0.124425   0.124007   0.125547   0.123085   \n",
       "2010-11-01 08:15:00   0.164904   0.175740   0.176726   0.174910   0.170643   \n",
       "2010-11-01 08:30:00   0.221257   0.234301   0.236635   0.231856   0.226432   \n",
       "2010-11-01 08:45:00   0.284905   0.299676   0.303037   0.296080   0.289875   \n",
       "2010-11-01 09:00:00   0.353067   0.369163   0.373142   0.364907   0.358404   \n",
       "2010-11-01 09:15:00   0.421526   0.438338   0.442255   0.434234   0.428124   \n",
       "2010-11-01 09:30:00   0.485745   0.502506   0.505560   0.499493   0.494683   \n",
       "2010-11-01 09:45:00   0.542919   0.558690   0.560023   0.557801   0.554874   \n",
       "2010-11-01 10:00:00   0.595321   0.608926   0.607790   0.611526   0.611331   \n",
       "2010-11-01 10:15:00   0.631988   0.642814   0.637705   0.649916   0.653777   \n",
       "2010-11-01 10:30:00   0.650558   0.657713   0.647136   0.670614   0.679029   \n",
       "2010-11-01 10:45:00   0.653822   0.656733   0.640228   0.675676   0.687173   \n",
       "2010-11-01 11:00:00   0.648692   0.647231   0.624605   0.671061   0.684814   \n",
       "2010-11-01 11:15:00   0.637627   0.630693   0.602609   0.660946   0.678021   \n",
       "2010-11-01 11:30:00   0.627008   0.615504   0.584307   0.650187   0.668598   \n",
       "2010-11-01 11:45:00   0.626446   0.612340   0.580634   0.648092   0.663098   \n",
       "2010-11-01 12:00:00   0.644203   0.628898   0.598676   0.662596   0.670925   \n",
       "2010-11-01 12:15:00   0.664259   0.652051   0.626036   0.678810   0.679951   \n",
       "2010-11-01 12:30:00   0.675471   0.666924   0.645715   0.686586   0.681822   \n",
       "2010-11-01 12:45:00   0.700399   0.693942   0.678915   0.708200   0.700004   \n",
       "...                        ...        ...        ...        ...        ...   \n",
       "2010-11-14 12:45:00   0.830889   0.844071   0.848268   0.837580   0.828524   \n",
       "2010-11-14 13:00:00   0.826181   0.839536   0.843591   0.833136   0.823531   \n",
       "2010-11-14 13:15:00   0.816661   0.830235   0.834050   0.823996   0.813806   \n",
       "2010-11-14 13:30:00   0.801900   0.815732   0.819209   0.809697   0.798892   \n",
       "2010-11-14 13:45:00   0.781377   0.795449   0.798503   0.789701   0.778264   \n",
       "2010-11-14 14:00:00   0.754545   0.768798   0.771392   0.763411   0.751486   \n",
       "2010-11-14 14:15:00   0.721195   0.735552   0.737640   0.730580   0.718327   \n",
       "2010-11-14 14:30:00   0.681259   0.695578   0.697162   0.691067   0.678693   \n",
       "2010-11-14 14:45:00   0.634428   0.648474   0.649515   0.644538   0.632376   \n",
       "2010-11-14 15:00:00   0.580264   0.593639   0.594099   0.590579   0.579062   \n",
       "2010-11-14 15:15:00   0.518473   0.530706   0.530526   0.528834   0.518612   \n",
       "2010-11-14 15:30:00   0.454806   0.466085   0.466172   0.464090   0.455214   \n",
       "2010-11-14 15:45:00   0.393463   0.403563   0.404037   0.401697   0.395832   \n",
       "2010-11-14 16:00:00   0.330415   0.338879   0.339534   0.337453   0.335208   \n",
       "2010-11-14 16:15:00   0.269382   0.276867   0.277869   0.275115   0.274588   \n",
       "2010-11-14 16:30:00   0.213825   0.221035   0.221536   0.219797   0.219446   \n",
       "2010-11-14 16:45:00   0.166550   0.173571   0.173649   0.172687   0.172524   \n",
       "2010-11-14 17:00:00   0.128704   0.135523   0.135254   0.134891   0.134603   \n",
       "2010-11-14 17:15:00   0.095405   0.101683   0.101253   0.101128   0.100593   \n",
       "2010-11-14 17:30:00   0.066893   0.072181   0.071761   0.071742   0.071057   \n",
       "2010-11-14 17:45:00   0.045264   0.049465   0.049078   0.049172   0.048374   \n",
       "2010-11-14 18:00:00   0.030025   0.033204   0.032857   0.033013   0.032048   \n",
       "2010-11-14 18:15:00   0.020198   0.022481   0.022193   0.022354   0.021216   \n",
       "2010-11-14 18:30:00   0.014934   0.016492   0.016273   0.016407   0.015200   \n",
       "2010-11-14 18:45:00   0.013282   0.014271   0.014151   0.014183   0.012881   \n",
       "2010-11-14 19:00:00   0.013636   0.014150   0.014142   0.014037   0.012713   \n",
       "2010-11-14 19:15:00   0.014692   0.014779   0.014859   0.014645   0.013437   \n",
       "2010-11-14 19:30:00   0.015591   0.015304   0.015453   0.015202   0.014144   \n",
       "2010-11-14 19:45:00   0.015621   0.015111   0.015398   0.014957   0.014172   \n",
       "2010-11-14 20:00:00   0.014709   0.014105   0.014446   0.013785   0.013312   \n",
       "\n",
       "                     var6(t-1)  var7(t-1)  var8(t-1)  var9(t-1)  var10(t-1)  \n",
       "datetime                                                                     \n",
       "2010-11-01 05:30:00   0.033496   0.036665   0.030459   0.037285    0.028936  \n",
       "2010-11-01 05:45:00   0.031662   0.034615   0.028735   0.035647    0.027221  \n",
       "2010-11-01 06:00:00   0.027489   0.029438   0.025294   0.031331    0.024780  \n",
       "2010-11-01 06:15:00   0.020590   0.021382   0.020044   0.024133    0.020141  \n",
       "2010-11-01 06:30:00   0.014613   0.015152   0.015479   0.018371    0.015190  \n",
       "2010-11-01 06:45:00   0.011183   0.011505   0.013773   0.015211    0.013415  \n",
       "2010-11-01 07:00:00   0.011218   0.012115   0.016231   0.015978    0.016919  \n",
       "2010-11-01 07:15:00   0.017612   0.020780   0.024922   0.024400    0.026634  \n",
       "2010-11-01 07:30:00   0.036437   0.042836   0.045936   0.045803    0.047621  \n",
       "2010-11-01 07:45:00   0.069991   0.081825   0.080165   0.083828    0.080798  \n",
       "2010-11-01 08:00:00   0.113103   0.131692   0.122944   0.132828    0.121976  \n",
       "2010-11-01 08:15:00   0.162863   0.188161   0.171817   0.188591    0.169461  \n",
       "2010-11-01 08:30:00   0.220433   0.250997   0.228340   0.250682    0.225126  \n",
       "2010-11-01 08:45:00   0.285498   0.319654   0.292186   0.318916    0.288570  \n",
       "2010-11-01 09:00:00   0.355426   0.391699   0.360824   0.391097    0.357233  \n",
       "2010-11-01 09:15:00   0.425813   0.462135   0.430196   0.462465    0.427252  \n",
       "2010-11-01 09:30:00   0.491748   0.525652   0.495661   0.527622    0.494202  \n",
       "2010-11-01 09:45:00   0.550111   0.578472   0.554233   0.582676    0.554763  \n",
       "2010-11-01 10:00:00   0.603248   0.622823   0.608380   0.629944    0.611545  \n",
       "2010-11-01 10:15:00   0.640627   0.647986   0.647784   0.658855    0.654735  \n",
       "2010-11-01 10:30:00   0.658599   0.651696   0.669454   0.666735    0.680853  \n",
       "2010-11-01 10:45:00   0.660159   0.638698   0.675538   0.657439    0.689895  \n",
       "2010-11-01 11:00:00   0.652315   0.617460   0.671582   0.639492    0.688920  \n",
       "2010-11-01 11:15:00   0.636703   0.589921   0.661056   0.614819    0.683304  \n",
       "2010-11-01 11:30:00   0.620500   0.567993   0.649513   0.593752    0.675558  \n",
       "2010-11-01 11:45:00   0.616169   0.564492   0.646717   0.589524    0.671423  \n",
       "2010-11-01 12:00:00   0.630641   0.584225   0.660114   0.606934    0.679641  \n",
       "2010-11-01 12:15:00   0.651547   0.617110   0.675592   0.636412    0.689288  \n",
       "2010-11-01 12:30:00   0.663536   0.640922   0.682967   0.655604    0.691882  \n",
       "2010-11-01 12:45:00   0.688755   0.676937   0.703879   0.685637    0.709954  \n",
       "...                        ...        ...        ...        ...         ...  \n",
       "2010-11-14 12:45:00   0.838962   0.882277   0.836443   0.880046    0.829771  \n",
       "2010-11-14 13:00:00   0.833850   0.877550   0.832280   0.875271    0.825873  \n",
       "2010-11-14 13:15:00   0.823643   0.867653   0.823369   0.865314    0.817358  \n",
       "2010-11-14 13:30:00   0.807801   0.852100   0.809160   0.849697    0.803691  \n",
       "2010-11-14 13:45:00   0.785758   0.830311   0.789046   0.827914    0.784248  \n",
       "2010-11-14 14:00:00   0.756969   0.801697   0.762466   0.799369    0.758501  \n",
       "2010-11-14 14:15:00   0.721276   0.766038   0.729190   0.763877    0.726187  \n",
       "2010-11-14 14:30:00   0.678668   0.723252   0.689099   0.721395    0.687145  \n",
       "2010-11-14 14:45:00   0.628923   0.672871   0.641898   0.671525    0.641111  \n",
       "2010-11-14 15:00:00   0.571715   0.614276   0.587251   0.613812    0.587719  \n",
       "2010-11-14 15:15:00   0.506758   0.547049   0.524771   0.547715    0.526810  \n",
       "2010-11-14 15:30:00   0.440598   0.479367   0.459059   0.480702    0.461579  \n",
       "2010-11-14 15:45:00   0.377529   0.414317   0.395962   0.416145    0.399787  \n",
       "2010-11-14 16:00:00   0.314086   0.347778   0.331327   0.350816    0.336431  \n",
       "2010-11-14 16:15:00   0.253470   0.283687   0.269491   0.288092    0.273557  \n",
       "2010-11-14 16:30:00   0.201190   0.226705   0.215409   0.232567    0.218136  \n",
       "2010-11-14 16:45:00   0.157485   0.178910   0.169662   0.185293    0.171192  \n",
       "2010-11-14 17:00:00   0.122977   0.140799   0.133091   0.147354    0.133483  \n",
       "2010-11-14 17:15:00   0.092338   0.106809   0.100173   0.112979    0.099553  \n",
       "2010-11-14 17:30:00   0.065788   0.076995   0.071346   0.082472    0.070115  \n",
       "2010-11-14 17:45:00   0.045582   0.053841   0.049141   0.058522    0.047628  \n",
       "2010-11-14 18:00:00   0.031299   0.037183   0.033210   0.041071    0.031576  \n",
       "2010-11-14 18:15:00   0.021951   0.026101   0.022628   0.029251    0.021007  \n",
       "2010-11-14 18:30:00   0.016735   0.019755   0.016618   0.022255    0.015187  \n",
       "2010-11-14 18:45:00   0.014815   0.017200   0.014229   0.019160    0.012954  \n",
       "2010-11-14 19:00:00   0.014684   0.016782   0.013851   0.018370    0.012751  \n",
       "2010-11-14 19:15:00   0.015125   0.017116   0.014205   0.018526    0.013344  \n",
       "2010-11-14 19:30:00   0.015417   0.017289   0.014504   0.018689    0.013880  \n",
       "2010-11-14 19:45:00   0.015021   0.016961   0.014079   0.018416    0.013707  \n",
       "2010-11-14 20:00:00   0.013956   0.015881   0.012898   0.017479    0.012731  \n",
       "\n",
       "[852 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobs = nlags * nfeat\n",
    "reshaped_df.iloc[:,:nobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = reshaped_df.iloc[:,:nobs].values, reshaped_df.iloc[:,-nfeat].values\n",
    "train_X = train_X.reshape((train_X.shape[0], nlags, nfeat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_reshaped_df = series_to_supervised(validation_clean_df[neighbor_stations_90], n_in=nlags, n_out=nsteps)\n",
    "validation_X, validation_Y = val_reshaped_df.iloc[:,:nobs].values, val_reshaped_df.iloc[:,-nfeat].values\n",
    "validation_X = validation_X.reshape((validation_X.shape[0], nlags, nfeat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 852 samples, validate on 425 samples\n",
      "Epoch 1/50\n",
      " - 8s - loss: 0.1812 - val_loss: 0.0784\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.0651 - val_loss: 0.0632\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.0486 - val_loss: 0.0471\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.0412 - val_loss: 0.0404\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.0379 - val_loss: 0.0390\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.0363 - val_loss: 0.0381\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.0358 - val_loss: 0.0381\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.0356 - val_loss: 0.0375\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.0350 - val_loss: 0.0373\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.0349 - val_loss: 0.0372\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.0346 - val_loss: 0.0368\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0343 - val_loss: 0.0368\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.0343 - val_loss: 0.0364\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.0339 - val_loss: 0.0362\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.0337 - val_loss: 0.0360\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.0336 - val_loss: 0.0358\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0335 - val_loss: 0.0356\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0332 - val_loss: 0.0352\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0329 - val_loss: 0.0350\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0327 - val_loss: 0.0347\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0324 - val_loss: 0.0343\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0321 - val_loss: 0.0339\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0317 - val_loss: 0.0334\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0311 - val_loss: 0.0329\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0306 - val_loss: 0.0325\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0302 - val_loss: 0.0319\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0296 - val_loss: 0.0312\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0290 - val_loss: 0.0307\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0285 - val_loss: 0.0299\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0276 - val_loss: 0.0287\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0267 - val_loss: 0.0275\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0260 - val_loss: 0.0261\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0250 - val_loss: 0.0246\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0245 - val_loss: 0.0233\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0242 - val_loss: 0.0222\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0231 - val_loss: 0.0207\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0213 - val_loss: 0.0201\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0193 - val_loss: 0.0182\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0169 - val_loss: 0.0162\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0173 - val_loss: 0.0158\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0169 - val_loss: 0.0133\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0158 - val_loss: 0.0154\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0157 - val_loss: 0.0118\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0143 - val_loss: 0.0135\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0139 - val_loss: 0.0103\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0144 - val_loss: 0.0105\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0127 - val_loss: 0.0104\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0129 - val_loss: 0.0094\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0122 - val_loss: 0.0099\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_Y, epochs=50, batch_size=72, validation_data=(validation_X, validation_Y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(validation_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XmQXGd97vHvr9eZ7tkXbTMaaSTLRrLl2CDLKxgSY0mQ2CRhMcE3pIp7FW6FutybC4mdFFA4lRQkVYTiFpu5cZGELQ7EFyWI2AbbGCwbW8JClmTZI1nbaLSMRprRLL33e/84Z0at0chqSTPT8unnU9V1Tp+l5z1y+zlvv+ec9zXnHCIiUh1ClS6AiIjMHoW+iEgVUeiLiFQRhb6ISBVR6IuIVBGFvohIFVHoi4hUEYW+iEgVUeiLiFSRSKULMFlbW5tbvHhxpYshIvKGsmXLluPOufbzbXfZhf7ixYvZvHlzpYshIvKGYmb7y9lOzTsiIlVEoS8iUkUU+iIiVeSya9MXEbkYuVyO3t5e0ul0pYsyo2pqaujs7CQajV7U/gp9EQmE3t5e6uvrWbx4MWZW6eLMCOccAwMD9Pb20t3dfVGfoeYdEQmEdDpNa2trYAMfwMxobW29pF8zCn0RCYwgB/64Sz3GwIT+cDrHFx5/la0HBytdFBGRy1ZgQj9fcHzppz28eOBkpYsiIlVocHCQr3zlKxe837ve9S4GB2evshqY0E/EwwCMZQsVLomIVKNzhX6h8PqZtHHjRpqammaqWGcJzN07sXCISMgYzeQrXRQRqUL33Xcfe/bs4brrriMajVJXV8f8+fPZunUrO3fu5D3veQ8HDx4knU7z8Y9/nPXr1wOnu54ZGRlh3bp13HbbbWzatImOjg5++MMfUltbO63lDEzomxm1sbBq+iLCZ/99Bzv7Tk3rZ65Y0MBnfufqc67/3Oc+x/bt29m6dStPPfUU7373u9m+ffvErZUPPfQQLS0tpFIpbrjhBn7/93+f1tbWMz6jp6eH7373u3zjG9/g/e9/Pz/4wQ+49957p/U4AhP6AMlYhLGsavoiUnmrV68+4176L33pSzzyyCMAHDx4kJ6enrNCv7u7m+uuuw6At7zlLezbt2/ayxWo0E/Ew4yqpi9S9V6vRj5bksnkxPxTTz3FT37yE5599lkSiQRvf/vbp7zXPh6PT8yHw2FSqdS0lyswF3LBr+mrTV9EKqC+vp7h4eEp1w0NDdHc3EwikWDXrl0899xzs1y604JV04+ppi8ildHa2sqtt97KNddcQ21tLXPnzp1Yt3btWr72ta9x7bXXctVVV3HTTTdVrJyBCv1kPMKx4WB3tiQil6/vfOc7Uy6Px+P8+Mc/nnLdeLt9W1sb27dvn1j+iU98YtrLBwFr3kno7h0RkdcVvNDPKPRFRM4lYKEfYVS3bIqInFOgQj8Z95p3nHOVLoqIyGWprNA3s7Vm9oqZ7Taz+6ZY/6dmttPMtpnZT81sUcm6gplt9V8bprPwkyViEQpFRyZfnMk/IyLyhnXeu3fMLAx8GXgn0Au8YGYbnHM7SzZ7EVjlnBszs/8O/C3wAX9dyjl33TSXe0rJ2OlO12qi4dn4kyIibyjl1PRXA7udc68557LA94C7Szdwzj3pnBvz3z4HdE5vMcuTiHvnMHW6JiKz7WK7Vgb44he/yNjY2Pk3nAblhH4HcLDkfa+/7Fw+ApTekFpjZpvN7Dkze89FlLFsCb+mn8rpDh4RmV1vlNAv5+GsqcbmmvJKqZndC6wCbi9Z3OWc6zOzJcATZvaSc27PpP3WA+sBurq6yir4VJIx1fRFpDJKu1Z+5zvfyZw5c3j44YfJZDL87u/+Lp/97GcZHR3l/e9/P729vRQKBT71qU9x9OhR+vr6eMc73kFbWxtPPvnkjJaznNDvBRaWvO8E+iZvZGZ3AH8J3O6cy4wvd871+dPXzOwp4HrgjNB3zj0IPAiwatWqi771JhHTQCoiAvz4Pjjy0vR+5ryVsO5z51xd2rXyY489xve//32ef/55nHPcddddPP300/T397NgwQJ+9KMfAV6fPI2NjXzhC1/gySefpK2tbXrLPIVymndeAJaZWbeZxYB7gDPuwjGz64GvA3c5546VLG82s7g/3wbcCpReAJ5WSbXpi8hl4LHHHuOxxx7j+uuv581vfjO7du2ip6eHlStX8pOf/IQ///M/5+c//zmNjY2zXrbz1vSdc3kz+xjwKBAGHnLO7TCzB4DNzrkNwN8BdcC/+iO1H3DO3QUsB75uZkW8E8znJt31M61U0xcR4HVr5LPBOcf999/PH//xH5+1bsuWLWzcuJH777+fO++8k09/+tOzWrayOlxzzm0ENk5a9umS+TvOsd8mYOWlFPBCTNT09VSuiMyy0q6V16xZw6c+9Sk+9KEPUVdXx6FDh4hGo+TzeVpaWrj33nupq6vjm9/85hn7zkbzTqB62Zy4e0c1fRGZZaVdK69bt44/+IM/4Oabbwagrq6Ob33rW+zevZtPfvKThEIhotEoX/3qVwFYv34969atY/78+TN+Idcuty4LVq1a5TZv3nxR+xaKjqV/sZH/dceVfPyOZdNcMhG5nL388sssX7680sWYFVMdq5ltcc6tOt++gep7Jxwy4pGQxskVETmHQIU+eO36atMXEZla4EJffeqLVK/Lrbl6JlzqMQYu9JPqU1+kKtXU1DAwMBDo4HfOMTAwQE1NzUV/RqDu3gFIxDVkokg16uzspLe3l/7+/koXZUbV1NTQ2XnxfVoGL/Q1Tq5IVYpGo3R3d1e6GJe9wDXvJGIRdcMgInIOgQv9pGr6IiLnFLjQT8Qjuk9fROQcAhf6yViYUd2yKSIypcCFfiIWIZUrUCwG97YtEZGLFcDQ15CJIiLnErzQV/fKIiLnFLjQT44PpKJ2fRGRswQu9BMx1fRFRM4lcKGfjGvIRBGRcwlc6E/U9PVUrojIWQIX+uM1fQ2ZKCJytsCFfiI63qav0BcRmSx4oT/Rpq/mHRGRyQIX+smJNn3V9EVEJgtc6NdEQ5ippi8iMpXAhb6ZeUMmqqYvInKWwIU+jI+epZq+iMhkAQ591fRFRCYLaOhrIBURkakEMvSTcQ2kIiIylbJC38zWmtkrZrbbzO6bYv2fmtlOM9tmZj81s0Ul6z5sZj3+68PTWfhzUU1fRGRq5w19MwsDXwbWASuAD5rZikmbvQiscs5dC3wf+Ft/3xbgM8CNwGrgM2bWPH3Fn1oyHtYTuSIiUyinpr8a2O2ce805lwW+B9xduoFz7knn3Jj/9jmg059fAzzunDvhnDsJPA6snZ6in1siFmFMHa6JiJylnNDvAA6WvO/1l53LR4AfX8i+ZrbezDab2eb+/v4yivT6krEwYxouUUTkLOWEvk2xbMpRx83sXmAV8HcXsq9z7kHn3Crn3Kr29vYyivT6amMRjZwlIjKFckK/F1hY8r4T6Ju8kZndAfwlcJdzLnMh+063ZCxMtlAkmy/O9J8SEXlDKSf0XwCWmVm3mcWAe4ANpRuY2fXA1/EC/1jJqkeBO82s2b+Ae6e/bEaND46uPvVFRM4UOd8Gzrm8mX0ML6zDwEPOuR1m9gCw2Tm3Aa85pw74VzMDOOCcu8s5d8LM/grvxAHwgHPuxIwcSYnxwdFHs3kaE9GZ/nMiIm8Y5w19AOfcRmDjpGWfLpm/43X2fQh46GILeDHGa/q6V19E5EzBfCJ3vKavi7kiImcIZOjXxsZHz1Loi4iUCmToj4+epeYdEZEzBTP04+MXclXTFxEpFcjQT4zX9NUVg4jIGQIZ+hODo6umLyJyhkCG/sSFXNX0RUTOEMjQj0VCRMOmTtdERCYJZOiDulcWEZlKYEM/GdNAKiIikwU29BNxDZkoIjJZYEM/GdPg6CIikwU29DU4uojI2QIb+sm4avoiIpMFNvRrYxFSumVTROQMgQ19r01fzTsiIqUCG/pem75q+iIipQIb+sl4mNFsHudcpYsiInLZCGzoJ2IRnIN0rljpooiIXDYCG/qn+9RXu76IyLjAhn5t1Av9lNr1RUQmBDb0k/HxPvVV0xcRGRfY0E/4ferrAS0RkdMCG/rjNX11xSAiclpgQ181fRGRswU29MfHyVVNX0TktMCGfsK/ZVNP5YqInBbc0FdNX0TkLGWFvpmtNbNXzGy3md03xfq3mdmvzCxvZu+dtK5gZlv914bpKvj5jN+nrzZ9EZHTIufbwMzCwJeBdwK9wAtmtsE5t7NkswPAHwGfmOIjUs6566ahrBckHDJqo2HV9EVESpw39IHVwG7n3GsAZvY94G5gIvSdc/v8dZdVRzdep2uq6YuIjCuneacDOFjyvtdfVq4aM9tsZs+Z2XsuqHQXIjUIT/4N9G6ZWJSIRRhTn/oiIhPKqenbFMsupL/iLudcn5ktAZ4ws5ecc3vO+ANm64H1AF1dXRfw0ZP87PMQq4POtwDevfqq6YuInFZOTb8XWFjyvhPoK/cPOOf6/OlrwFPA9VNs86BzbpVzblV7e3u5H32mmkaI1cOpQxOLErGwOlwTESlRTui/ACwzs24ziwH3AGXdhWNmzWYW9+fbgFspuRYwrcygsQOGeicWJeMRdbgmIlLivKHvnMsDHwMeBV4GHnbO7TCzB8zsLgAzu8HMeoH3AV83sx3+7suBzWb2a+BJ4HOT7vqZXg1nhn4iFmZMt2yKiEwop00f59xGYOOkZZ8umX8Br9ln8n6bgJWXWMbyNXbCkW0Tb5Mx1fRFREoF64ncxk4Y7YdcGvC6YlA3DCIipwUr9Bv8O0n9i7nJWIRR3bIpIjIhWKHf6Lcw+aGfiEXI5IsUihdyh6mISHAFM/T9i7njfeqrKwYREU+wQr9hgTcd8mv66l5ZROQMwQr9aC0k2uCUV9MfH0hF7foiIp5ghT6c8YDW6eYd1fRFRCCIod/QOdG8Mz44umr6IiKe4IV+Y2fJ3Tuq6YuIlApg6HdA5hSkh0qGTFToi4hAIEN//LbNQxM1fXXFICLiCV7oN5y+V3+8TV8DqYiIeIIX+o3jXTH0ltT01bwjIgJBDP26eWBhGDpEPBIiHDI9kSsi4gte6IcjUD8fhnoxM2/IRPWpLyICBDH0wWviKbltU0Mmioh4Ahr6nRNP5WogFRGR04IZ+g1+Tb9Y1EAqIiIlghn6jZ1QyMLYcRIaSEVEZEJwQx+8e/VjqumLiIwLZuiPD5s41EsirjZ9EZFxwQz9kmETk7EwY7plU0QECGroJ1ohUuPV9GMRPZwlIuILZuibeU08Q15XDGPZAs5pcHQRkWCGPkw8oJWMR8gXHdlCsdIlEhGpuACH/sIzuldWu76ISJBDv6EDhg9TF/GadXQHj4hIkEO/sQNwtLgBQKNniYhAoEPfu22zKXcMUOiLiECZoW9ma83sFTPbbWb3TbH+bWb2KzPLm9l7J637sJn1+K8PT1fBz8sfQashcxTQ6FkiIlBG6JtZGPgysA5YAXzQzFZM2uwA8EfAdybt2wJ8BrgRWA18xsyaL73YZfBH0KrzQ1+jZ4mIlFfTXw3sds695pzLAt8D7i7dwDm3zzm3DZh8X+Qa4HHn3Ann3EngcWDtNJT7/OL1UNNIIn0EQA9oiYhQXuh3AAdL3vf6y8pR1r5mtt7MNpvZ5v7+/jI/ugwNncRH+wA0epaICOWFvk2xrNzHW8va1zn3oHNulXNuVXt7e5kfXYbGDqIjhwHV9EVEoLzQ7wUWlrzvBPrK/PxL2ffSNXYSGvaGTdTdOyIi5YX+C8AyM+s2sxhwD7ChzM9/FLjTzJr9C7h3+stmR0MHljpBQySnh7NERCgj9J1zeeBjeGH9MvCwc26HmT1gZncBmNkNZtYLvA/4upnt8Pc9AfwV3onjBeABf9ns8O/VXxI9qW4YRESASDkbOec2AhsnLft0yfwLeE03U+37EPDQJZTx4vmhvzQ+xPGRTEWKICJyOQnuE7kwMYLWDc2jPL/3BMWiulcWkeoW8NBfAMC19aMMjGbZdWS4wgUSEamsYId+JA51c1kcOwnAM7uPV7hAIiKVFezQB2joIDF2mKXtSZ7Zo9AXkeoW/NBv7IRTh7jtijZ++doJsnmNoCUi1as6Qn/oELcsbSWVK7D14GClSyQiUjHBD/2GDsiNcvOCMCGDX6hdX0SqWPBD379XvyF7lJWdTbqYKyJVrWpCn6FD3HZFK1sPDjKczlW2TCIiFRL80Pcf0GLoILde0Uah6Hh+7+z1BCEicjkJfujXzYVQFE4d4s1dzcQjIbXri0jVCn7oh0LQ1AX9r1ATDbO6u4VNuwcqXSoRkYoIfugDLLkdXvsZ5DPcsrSNV44Oc2w4XelSiYjMuuoI/WVrIDcK+5/htivaAHh2j2r7IlJ9qiP0u98GkRp49VFWLGigKRHlFz1q1xeR6lMdoR9LeMH/6qOEDW5e0sozu4/jnLpaFpHqUh2hD7DsTji5FwZ2c+sVbfQNpdk3MFbpUomIzKrqCf0r13jTVx/lVr9dX7duiki1qZ7Qb+qC9uXQ8yiLWxN0NNWySaEvIlWmekIf4Mo7Yf8mLDPMLUtb2bRngIKGUBSRKlJdob9sDRTzsOcJblvWxlAqx46+oUqXSkRk1lRX6C+8EWoaoecxblnqtes/o6dzRaSKVFfohyNwxR3Q8xjtyShXza3n5z39lS6ViMisqa7QB6+JZ7QfDr/Imqvn8uxrA+zpH6l0qUREZkX1hf4VdwAGrz7GH96ymFg4xIM/e63SpRIRmRXVF/rJVui8AV79T9rq4rxvVSePvHiIo6fUAZuIBF/1hT54t24e3grDR1j/1qXki0Ue+sXeSpdKRGTGVWnor/WmPY/T1ZrgXSvn8+1fHmAopWEURSTYygp9M1trZq+Y2W4zu2+K9XEz+xd//S/NbLG/fLGZpcxsq//62vQW/yLNvcYbRrHnUQA+evtSRjJ5vv3L/RUumIjIzDpv6JtZGPgysA5YAXzQzFZM2uwjwEnn3BXA3wOfL1m3xzl3nf/66DSV+9KYwbJ3wp4nIZ/lmo5G3rqsjYd+sY90rlDp0omIzJhyavqrgd3Oudecc1nge8Ddk7a5G/hHf/77wG+ZmU1fMWfAsjWQHYH9zwBebf/4SIZ/+9WhChdMRGTmlBP6HcDBkve9/rIpt3HO5YEhoNVf121mL5rZz8zsrZdY3umz5HYIx6HnMQBuWdrKtZ2NPPj0HvXHIyKBVU7oT1Vjn5yK59rmMNDlnLse+FPgO2bWcNYfMFtvZpvNbHN//yw9IRtLegOrbHsYBg9gZnz09qXsGxjj0R1HZqcMIiKzrJzQ7wUWlrzvBPrOtY2ZRYBG4IRzLuOcGwBwzm0B9gBXTv4DzrkHnXOrnHOr2tvbL/woLtadfwWFHHz7fZAaZM3V8+huS/LVp/ZoVC0RCaRyQv8FYJmZdZtZDLgH2DBpmw3Ah/359wJPOOecmbX7F4IxsyXAMuDyefx1znL4wD/DwB54+L8QLub4b29dwkuHhtikgdNFJIDOG/p+G/3HgEeBl4GHnXM7zOwBM7vL3+wfgFYz243XjDN+W+fbgG1m9mu8C7wfdc6dmO6DuCRLboe7/g/sfRr+/X/we9cvoK0uzlee2q3avogEjl1uwbZq1Sq3efPm2f/DT30envobuP0+vhH+AH+98WV+601z+Nv3XktrXXz2yyMicgHMbItzbtX5tqvOJ3KncvufwXUfgp99jv9a/yyf+Z0V/Hz3cdZ88ef87FV1vywiwaCafql8Fr79Xu/e/Q98i725Rv5p49OEhg7yzo4sNzSNEB47DvOugUW3wuLboH5eZcoqIlKi3Jq+Qn+y9BA8tBaO7Txj8YiroT88j7lz55IY2AnZYW9Fy1JYfCt03QKJVsCBK/ovfz4c824RjSUhVudPExBNeOsu8+fYROTyV27oR2ajMG8oNY3whz+ElzdAcg40dUFTFy/sz/HJH2zj5P4c8+siXF93kNWhl7k2vYNlv36ExK/+6eL/ZijqhX94fBqDUAgsDKEIhEqm4ThEa71XpOb0NBL3thn/jFDUGyls/PPGX5Hx+ThEayBSe/Y04q8PR3VCEgkY1fQvQP9whm9u2suxUxkGUzmGxnIMprIMjWZoTe0jWkzhMIoYDiMUCtGSjNNSG6IxlKEhkqXe0tSHMtRZhoRlqAkViYcK1FiBmOWJW4EoOUIUCbkiYYoYBcKuSMjlCRUzhPJpQoU0ls9401wKK2ahmMcKOShOY2+h4XjJySI+xbSmZL7kNX5SidV5v2gmfuUkvBPVxIkoeuZ8vAHi9d5niEjZVNOfAe31cT655k1TrnPOMTiWo28oxeHBNIdPpTk8mOLwUJqhVI4j2QKpXIF0tkA6582PZQqMZvNMZ68PsUiI2kiI+hg0xBy1/kklRoF4KE+MnDdvOZKWoyaUpdZyJMhQYzlqyBK3PDXmbeOdiPLEyBNxOf+VJVrMEs7nCGczhN0I4WKWUCFDqJgjVMxihQyhXAorXOTgNOG4F/414yeBmpKTRPz0ySJaA9FkSfOZ/4rXQ21zyavFW65fLlLlFPrTxMxoTsZoTsa4ekFj2fs558jki4xlC4xm8t40m6dQdOQKRfIFd3q+6M0Xio580VH0p/likUzO+4yxXJ5UtsBYtkAqWyBbKOKct0/awZhzFJ0jX/D2zRWK5Arj0yK5fJFMvkg6VyCT9/7mpQhRpJYMCdI0RXI0RXI0RrIkIo5EqEAiUqQ2VKQ2XCBheeosTZIxkqRIujESbpTa9ChR8kTdGBHyRFyWiMsTdlnChQyh/Bjh3Bjm8ucpTNRrvouM/3opmUZqvHWJFu8EUTpNtp9+xesu6d9DpNIU+hVmZtREw9REw7QkY5UuzlnyhdMngfGTQ3biBOHIFrzl2Xxx4sSRyXsnkky+QDrnn0ByBdL5ojfNFUnnC5zMFTjif/b4dtlCkax/4sn4J55MvlhWWaPkSZAmQYZ6G6OJEVrDoyyIpZgTHaMtPEZTKEUteWqKeeI57xWzHDE3Qk2+j3huiHh2kNA5TiAumsCS7VA3xz+B1HjNV+PXWaK13i+PiV8pDafna5uhodO71iJSIfr2yeuKhENEwiGS8cp9VUp/DY1lT/+SGcsW/F9AJb+Iio5CsUgqW2QolZt4bfOnp9I5b990nlH/19XZv2YcSdI02whNDNNmp2izIdoYor1wio78MHNHTlFvB6glS5wscZch6jJEi2nCr/OLw1kY19iFtXZjzd3QsgRauqF+vnf7b3KOTgoyo/TtksveTP8ayuaLjGXzZP3mtHzBefNF79fMUCrHwGiG4yNZToxm6BnJcnwkw1Aqx3A6z3A6z6l0jpFMHue8Xxx1jFFnKRpIUUeKehuj2YbpsmMsGjhK98l9LLLnaWDkjLI4jFxNK65uLpHG+YQTLaeva8Tr/V8ODdAwH+ZdC7VN0/7vIcGm0JeqF4uEiEUu/WRSLDpGs3lGMwW/iep081Qm7124PzGWpW80y0sjGQZGs6SHjhMdPkB45Ag1mePMsZPMGRlkzuhJ5hzbQ5Nto97S1DFGlLN/QYwmOsm2ryTa+Rskut5CaN7V3q+GkB62l6kp9EWmSShk1NdEqa+JXtT+6VyBY6cy9A2lODKU5tWhFENjOU6l84xk8qRTo+RTp3CpIZJjvSzK9LBieB9Xj/yK7v0/Bm8QOHJEGIjMZTC+gLHaBWTqOyk2LiY6fzkNncuZ39xIQ22Ey31wO5kZCn2Ry0RNNExXa4Ku1kRZ249m8hwaTLHvZIpfHjtK/vBLxE68SmLsEE2ZPlrGjrB4ZBctx/2nx7dCzoXZ6+bxDAs5UrOEweRSUk3LsNZu2hvqmNMQp70+ztyGGjqaaqmJhmfwiKUS9HCWSMClR4cY6uthtHc7xSM7iQ7somF4N82Z0+NBZ12YvW4+Pa6DPa6DnmIHvTaXSNNC5s7vYNm8Rq6aW8+V8+pZ3JokHNKvhMuN+t4RkdeXGYHjr0D/q7j+XeSP7sL17yJ66gDmTt8mmyXCYdfCYddKn2vliLWTqVtItLWbho5ldCxcypXzm+hoqiWkk0HFKPRF5OLk0jCwGwb3w9AhONVL/mQvmYEDcOoQtamjhChMbJ51YQ65NnptHgO1i0k3LSMydzlNi1ayuHMBi1qTRMO6sDzTFPoiMjMKeTjVCyf3MXZ0D0N9PWSPv0ZscC8t6f3EXWZi0yOumR63kIMtN5FYeRc3rbqBeY01FSx8cCn0RWT2FQsweIB0305O7n+J7JGd1B5/iTkpb2jsV4sd/Dp5K+7Kd7HyxnfQVl/rdytS9Lsb8R6ym9sQpylx+T2hfjlT6IvIZcOd2Ev/lh+S3fEfzB/cQpgix1wTzxevYnuxm21uCduLiznF6b6NlrYneXNXM29e1MxbFjVzRXsdoZCRyhbY0z/Cq0eHefXoCD1HhxlM5Xj7le2sWzmfK+ZUZ/9ICn0RuTylTjK0bSND2/6D5hPbqE/1TqwaTXYx1HQ1R0Jz2D9s9AzB8WyUUVdLMZZkpGYBvxhqwTnvgnE0bHS3JamNhvl17xAAV82tZ93Kebx75XyWza0H4ORolr0Do+ztH2XfwCj7B8ZoScZYsaCBFfMbWDa3jnjkjX17qkJfRN4Yxk7A4a3QtxX6XvSmI0egkJ1y8xO1XZzsWkPsmruZt/wWon5YHxlK85/bD7PxpSO8sP8EzkFncy0jmTyDY6fHmAiHjAVNNQyMZBnLehekIyFjaXsdKxY0sLg1SXt9/IxXW13ssj8pKPRF5I0tn4XsCGRHvWlmBI6+BC//O+x9Gop5aOiAN/02LH2HN8ZCsQiuwOBoiq37T/DykRFGm5fTtOAKutvr6G5LsrAlQTQcolh07D8xxs6+U+w8PORPT3H0VGbK4sxtiLO6u5Ubu1u4aUkrS9uTF/xUczpXYNOe44RDIa6cW8e8hpppezJaoS8iwZU6Ca/8p3cC2PNTyJ9nsJ76BbDoZui6GRbdCu1vOmf/RNl8kYHRDP3Dp1/HRzL0HBvhudcGJk4KbXVxblzSwo3dLayY38CV8+ppmKILjlS2wFOvHONHLx3miV3HJn5dANTHIyybW8eyOfUsm1vH1fPrufmK9ov6J1Hoi0ggIyYmAAAGPUlEQVR1yIzA0R3efCgMFvKnYa+J6NAWOPAs7N8Ew4e97WqaYM5yaFoEzYuheZE/vwgwGOr1bksd6vWeVRjqhewwrraZEWvgQLqGnuEo2wbC7E/FGKOGlItTV1fP/PZWOue10d7ayjP7xnhi1zFSuQKtyRhrrpnHumvmEQ2H6DnmXYQ+2neArmNP8rb8JiKJBm6+/8cX9c+g0BcRKeUcnNznnQAOPAvH/QfQTvUBr5OD8UZo7PC6tk6d9K5BpE6CK5x7H99h2jjZuJy6xW+h4003Eu64zusFdfiI9ytl5w/hwCZwRQrNSxha9nu0vOtTF3V4Cn0RkXLkM15N/uQ+7yQA0LgQGju9awY1DWfvUyxC5hSMDUB6ELJjkBvzrj/kUhQyIwwPnaBheDehw7/2nnAeP7HUtkDqhDffvhxW3A0r7oI5Ky5pDGcNjC4iUo5IHFqXeq9yhULeADbnGMQmDJyxJjMCR7fD4W3exejGLi/s26+8lJJfFIW+iMhMi9dB103eq8LUC5KISBUpK/TNbK2ZvWJmu83svinWx83sX/z1vzSzxSXr7veXv2Jma6av6CIicqHOG/pmFga+DKwDVgAfNLMVkzb7CHDSOXcF8PfA5/19VwD3AFcDa4Gv+J8nIiIVUE5NfzWw2zn3mnMuC3wPuHvSNncD/+jPfx/4LfMeM7sb+J5zLuOc2wvs9j9PREQqoJzQ7wAOlrzv9ZdNuY1zLg8MAa1l7isiIrOknNCf6sbRyTf3n2ubcvbFzNab2WYz29zf319GkURE5GKUE/q9wMKS951A37m2MbMI0AicKHNfnHMPOudWOedWtbdfXL8TIiJyfuWE/gvAMjPrNrMY3oXZDZO22QB82J9/L/CE8x713QDc49/d0w0sA56fnqKLiMiFOu/DWc65vJl9DHgU70Gzh5xzO8zsAWCzc24D8A/AP5vZbrwa/j3+vjvM7GFgJ5AH/sS51++wYsuWLcfNbP8lHFMbcPwS9n+j0nFXFx13dSnnuBeV80GXXd87l8rMNpfT/0TQ6Liri467ukznceuJXBGRKqLQFxGpIkEM/QcrXYAK0XFXFx13dZm24w5cm76IiJxbEGv6IiJyDoEJ/fP1BBokZvaQmR0zs+0ly1rM7HEz6/GnzZUs43Qzs4Vm9qSZvWxmO8zs4/7yoB93jZk9b2a/9o/7s/7ybr9H2x6/h9tYpcs6E8wsbGYvmtl/+O+r5bj3mdlLZrbVzDb7y6blux6I0C+zJ9Ag+SZer6Wl7gN+6pxbBvzUfx8keeB/O+eWAzcBf+L/Nw76cWeA33TO/QZwHbDWzG7C68n27/3jPonX020QfRx4ueR9tRw3wDucc9eV3Ko5Ld/1QIQ+5fUEGhjOuafxHoIrVdrT6T8C75nVQs0w59xh59yv/PlhvCDoIPjH7ZxzI/7bqP9ywG/i9WgLATxuADPrBN4N/F//vVEFx/06puW7HpTQV2+eMNc5dxi8gATmVLg8M8YfpOd64JdUwXH7TRxbgWPA48AeYNDv0RaC+33/IvBnQNF/30p1HDd4J/bHzGyLma33l03Ldz0oY+SW1ZunvPGZWR3wA+B/OudOeZW/YPO7LrnOzJqAR4DlU202u6WaWWb228Ax59wWM3v7+OIpNg3UcZe41TnXZ2ZzgMfNbNd0fXBQavpl9eYZcEfNbD6APz1W4fJMOzOL4gX+t51z/+YvDvxxj3PODQJP4V3TaPJ7tIVgft9vBe4ys314zbW/iVfzD/pxA+Cc6/Onx/BO9KuZpu96UEK/nJ5Ag660p9MPAz+sYFmmnd+e+w/Ay865L5SsCvpxt/s1fMysFrgD73rGk3g92kIAj9s5d79zrtM5txjv/+cnnHMfIuDHDWBmSTOrH58H7gS2M03f9cA8nGVm78KrCYz3BPrXFS7SjDGz7wJvx+t57yjwGeD/AQ8DXcAB4H3OuckXe9+wzOw24OfAS5xu4/0LvHb9IB/3tXgX7cJ4lbSHnXMPmNkSvBpwC/AicK9zLlO5ks4cv3nnE865366G4/aP8RH/bQT4jnPur82slWn4rgcm9EVE5PyC0rwjIiJlUOiLiFQRhb6ISBVR6IuIVBGFvohIFVHoi4hUEYW+iEgVUeiLiFSR/w814RdyTHN7/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a6aee48d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Multiple Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat = len(train_clean_df[neighbor_stations_90].columns)\n",
    "nlags = 2\n",
    "nsteps = 1\n",
    "reshaped_df = series_to_supervised(train_clean_df[neighbor_stations_90], n_in=nlags, n_out=nsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = nlags * nfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = reshaped_df.iloc[:,:nobs].values, reshaped_df.iloc[:,-nfeat].values\n",
    "train_X = train_X.reshape((train_X.shape[0], nlags, nfeat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_reshaped_df = series_to_supervised(validation_clean_df[neighbor_stations_90], n_in=nlags, n_out=nsteps)\n",
    "validation_X, validation_Y = val_reshaped_df.iloc[:,:nobs].values, val_reshaped_df.iloc[:,-nfeat].values\n",
    "validation_X = validation_X.reshape((validation_X.shape[0], nlags, nfeat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(neurons, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2]), kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(LSTM(neurons, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2]), kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(LSTM(neurons, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2]), kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(LSTM(neurons, input_shape=(train_X.shape[1], train_X.shape[2]), kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_Y, epochs=50, batch_size=72, validation_data=(validation_X, validation_Y), verbose=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(validation_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027720579041285703"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(validation_Y, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a269321d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeat = len(train_clean_df[neighbor_stations_90].columns)\n",
    "nlags = 2\n",
    "nsteps = 1\n",
    "neurons = 50\n",
    "\n",
    "train_reshaped_df = series_to_supervised(train_clean_df[neighbor_stations_90], n_in=nlags, n_out=nsteps)\n",
    "train_X, train_Y = train_reshaped_df.iloc[:,:nobs].values, train_reshaped_df.iloc[:,-nfeat].values\n",
    "\n",
    "val_reshaped_df = series_to_supervised(validation_clean_df[neighbor_stations_90], n_in=nlags, n_out=nsteps)\n",
    "validation_X, validation_Y = val_reshaped_df.iloc[:,:nobs].values, val_reshaped_df.iloc[:,-nfeat].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "852/852 [==============================] - 10s 11ms/step - loss: 0.0101\n",
      "Epoch 2/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 0.0025\n",
      "Epoch 3/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 0.0018\n",
      "Epoch 4/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 0.0014\n",
      "Epoch 5/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 0.0013\n",
      "Epoch 6/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 0.0012\n",
      "Epoch 7/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 0.0011\n",
      "Epoch 8/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 0.0011\n",
      "Epoch 9/50\n",
      "852/852 [==============================] - 0s 36us/step - loss: 0.0010\n",
      "Epoch 10/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 9.5929e-04\n",
      "Epoch 11/50\n",
      "852/852 [==============================] - 0s 32us/step - loss: 8.9954e-04\n",
      "Epoch 12/50\n",
      "852/852 [==============================] - 0s 36us/step - loss: 8.4042e-04\n",
      "Epoch 13/50\n",
      "852/852 [==============================] - 0s 36us/step - loss: 7.8270e-04\n",
      "Epoch 14/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 7.2624e-04\n",
      "Epoch 15/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 6.7029e-04\n",
      "Epoch 16/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 6.1304e-04\n",
      "Epoch 17/50\n",
      "852/852 [==============================] - 0s 33us/step - loss: 5.4696e-04\n",
      "Epoch 18/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 4.6182e-04\n",
      "Epoch 19/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 4.1409e-04\n",
      "Epoch 20/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 3.8472e-04\n",
      "Epoch 21/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 3.5708e-04\n",
      "Epoch 22/50\n",
      "852/852 [==============================] - 0s 36us/step - loss: 3.3118e-04\n",
      "Epoch 23/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 3.0669e-04\n",
      "Epoch 24/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 2.8354e-04\n",
      "Epoch 25/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 2.6162e-04\n",
      "Epoch 26/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 2.4116e-04\n",
      "Epoch 27/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 2.2253e-04\n",
      "Epoch 28/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 2.0592e-04\n",
      "Epoch 29/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 1.9108e-04\n",
      "Epoch 30/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 1.7791e-04\n",
      "Epoch 31/50\n",
      "852/852 [==============================] - 0s 55us/step - loss: 1.6614e-04\n",
      "Epoch 32/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 1.5557e-04\n",
      "Epoch 33/50\n",
      "852/852 [==============================] - 0s 36us/step - loss: 1.4606e-04\n",
      "Epoch 34/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 1.3760e-04\n",
      "Epoch 35/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 1.3006e-04\n",
      "Epoch 36/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 1.2330e-04\n",
      "Epoch 37/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 1.1727e-04\n",
      "Epoch 38/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 1.1194e-04\n",
      "Epoch 39/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 1.0717e-04\n",
      "Epoch 40/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 1.0291e-04\n",
      "Epoch 41/50\n",
      "852/852 [==============================] - 0s 33us/step - loss: 9.9124e-05\n",
      "Epoch 42/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 9.5748e-05\n",
      "Epoch 43/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 9.2705e-05\n",
      "Epoch 44/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 8.9936e-05\n",
      "Epoch 45/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 8.7409e-05\n",
      "Epoch 46/50\n",
      "852/852 [==============================] - 0s 35us/step - loss: 8.5015e-05\n",
      "Epoch 47/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 8.2820e-05\n",
      "Epoch 48/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 8.0636e-05\n",
      "Epoch 49/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 7.8502e-05\n",
      "Epoch 50/50\n",
      "852/852 [==============================] - 0s 34us/step - loss: 7.6350e-05\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(Dense(neurons, activation='relu', input_dim=train_X.shape[1]))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_Y, epochs=50, batch_size=72, verbose=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(validation_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-16b435b16438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a6c0df780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
