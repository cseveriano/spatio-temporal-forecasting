{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "from pyFTS.benchmarks import Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/petroniocandido/pyFTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    mindf = df.min()\n",
    "    maxdf = df.max()\n",
    "    return (df-mindf)/(maxdf-mindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(norm, _min, _max):\n",
    "    return [(n * (_max-_min)) + _min for n in norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open( name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target and input variables \n",
    "target_station = 'WTG01'\n",
    "\n",
    "#All neighbor stations with residual correlation greater than .90\n",
    "neighbor_stations_90 = ['WTG01','WTG02','WTG03','WTG05','WTG06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"df_wind_speed.pkl\")\n",
    "df_ssa_clean = pd.read_pickle(\"df_wind_speed_ssa_clean.pkl\")\n",
    "df_ssa_residual = pd.read_pickle(\"df_wind_speed_ssa_residual.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data form the interval of interest\n",
    "interval = ((df.index >= '2017-05') & (df.index <= '2018-05'))\n",
    "df = df.loc[interval]\n",
    "df_ssa_clean = df_ssa_clean.loc[interval]\n",
    "df_ssa_residual = df_ssa_residual.loc[interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize Data\n",
    "\n",
    "# Save Min-Max for Denorm\n",
    "min_raw = df[target_station].min()\n",
    "min_clean = df_ssa_clean[target_station].min()\n",
    "min_residual = df_ssa_residual[target_station].min()\n",
    "\n",
    "max_raw = df[target_station].max()\n",
    "max_clean = df_ssa_clean[target_station].max()\n",
    "max_residual = df_ssa_residual[target_station].max()\n",
    "\n",
    "# Perform Normalization\n",
    "norm_df_ssa_clean = normalize(df_ssa_clean)\n",
    "norm_df_ssa_residual = normalize(df_ssa_residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling window Validation\n",
    "\n",
    "Training: 4 weeks\n",
    "Validation: 1 week\n",
    "Test: 1 week\n",
    "\n",
    "Roliing weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRollingWindow(index):\n",
    "    pivot = index\n",
    "    train_start = pivot.strftime('%Y-%m-%d')\n",
    "    pivot = pivot + datetime.timedelta(days=27)\n",
    "    train_end = pivot.strftime('%Y-%m-%d')\n",
    "\n",
    "    pivot = pivot + datetime.timedelta(days=1)\n",
    "    validation_start = pivot.strftime('%Y-%m-%d')\n",
    "    pivot = pivot + datetime.timedelta(days=6)\n",
    "    validation_end = pivot.strftime('%Y-%m-%d')\n",
    "\n",
    "    pivot = pivot + datetime.timedelta(days=1)\n",
    "    test_start = pivot.strftime('%Y-%m-%d')\n",
    "    pivot = pivot + datetime.timedelta(days=6)\n",
    "    test_end = pivot.strftime('%Y-%m-%d')\n",
    "    \n",
    "    return train_start, train_end, validation_start, validation_end, test_start, test_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_error(cv_name, df, forecasts, order_list):\n",
    "    cv_results = pd.DataFrame(columns=['Split', 'RMSE', 'SMAPE', 'U'])\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    for i in np.arange(len(forecasts)):\n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        test = df[test_start : test_end]\n",
    "    \n",
    "        yhat = forecasts[i]\n",
    "        order = order_list[i]\n",
    "        \n",
    "        rmse = Measures.rmse(test[target_station].iloc[order:], yhat[:-1])\n",
    "        \n",
    "        smape = Measures.smape(test[target_station].iloc[order:], yhat[:-1])\n",
    "        \n",
    "        u = Measures.UStatistic(test[target_station].iloc[order:], yhat[:-1])\n",
    "       \n",
    "        res = {'Split' : index.strftime('%Y-%m-%d') ,'RMSE' : rmse, 'SMAPE' : smape, 'U' : u}\n",
    "        cv_results = cv_results.append(res, ignore_index=True)\n",
    "        cv_results.to_csv(cv_name+\".csv\")        \n",
    "\n",
    "        index = index + datetime.timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_ssa_series(clean, residual):\n",
    "    return [r + c for r, c in zip(residual,clean)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual):\n",
    "    \n",
    "    forecasts_final = []\n",
    "    order_list = []\n",
    "    \n",
    "    for i in np.arange(len(forecasts_clean)):\n",
    "        f_clean = denormalize(forecasts_clean[i], min_clean, max_clean)\n",
    "        f_residual = denormalize(forecasts_residual[i], min_residual, max_residual)\n",
    "\n",
    "        o_clean = order_list_clean[i]\n",
    "        o_residual = order_list_residual[i]\n",
    "\n",
    "        max_order = max(o_clean, o_residual)\n",
    "\n",
    "        f_final = reconstruct_ssa_series(f_clean[max_order-o_clean:], f_residual[max_order-o_residual:])\n",
    "        \n",
    "        forecasts_final.append(f_final)\n",
    "        order_list.append(max_order)\n",
    "        \n",
    "    return forecasts_final, order_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persistence_forecast(train, test, step):\n",
    "    predictions = []\n",
    "    \n",
    "    for t in np.arange(0,len(test), step):\n",
    "        yhat = [test.iloc[t]]  * step\n",
    "        predictions.extend(yhat)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv_persistence(df, step):\n",
    "\n",
    "    forecasts = []\n",
    "    lags_list = []\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    while test_end < limit :\n",
    "        print(\"Index: \", index.strftime('%Y-%m-%d'))  \n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        index = index + datetime.timedelta(days=7)\n",
    "        \n",
    "        train = df[train_start : train_end]\n",
    "        validation = df[validation_start : validation_end]\n",
    "        test = df[test_start : test_end]\n",
    "    \n",
    "        # Concat train & validation for test\n",
    "        train = train.append(validation)\n",
    "        yhat = persistence_forecast(train[target_station], test[target_station], step)        \n",
    "        \n",
    "        lags_list.append(1)\n",
    "        forecasts.append(yhat)\n",
    "\n",
    "    return forecasts, lags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_clean, order_list_clean = rolling_cv_persistence(norm_df_ssa_clean, 1)\n",
    "forecasts_residual, order_list_residual = rolling_cv_persistence(norm_df_ssa_residual, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_final, order_list = get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_rolling_error(\"rolling_cv_wind_ssa_persistence\", df, forecasts_final, order_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from itertools import product\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_SARIMA_models(test_name, train, validation, parameters_list, period_length):\n",
    "\n",
    "    sarima_results = pd.DataFrame(columns=['Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "    for param in parameters_list:\n",
    "        arima_order = (param[0],param[1],param[2])\n",
    "        sarima_order = (param[3],param[4],param[5],period_length)\n",
    "        print('Testing SARIMA%s %s ' % (str(arima_order),str(sarima_order)))\n",
    "        try:\n",
    "            fcst = sarima_forecast(train, validation, arima_order, sarima_order)\n",
    "            rmse = Measures.rmse(validation.values, fcst)\n",
    "            \n",
    "            if rmse < best_score:\n",
    "                best_score, best_cfg = rmse, (arima_order, sarima_order)\n",
    "\n",
    "            res = {'Parameters' : str(param) ,'RMSE' : rmse}\n",
    "            print('SARIMA%s %s RMSE=%.3f' % (str(arima_order),str(sarima_order),rmse))\n",
    "            sarima_results = sarima_results.append(res, ignore_index=True)\n",
    "            sarima_results.to_csv(test_name+\".csv\")\n",
    "        except:\n",
    "            print(sys.exc_info())\n",
    "            print('Invalid model%s %s ' % (str(arima_order),str(sarima_order)))\n",
    "            continue\n",
    "    \n",
    "    print('Best SARIMA(%s) RMSE=%.3f' % (best_cfg, best_score))\n",
    "    return best_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarima_forecast(train, test, arima_order, sarima_order):\n",
    "\n",
    "    predictions = []\n",
    "    window_size = sarima_order[3] * 5\n",
    "    step = 5\n",
    "    \n",
    "    history = list(train.iloc[-window_size:])\n",
    "\n",
    "    print(\"Fitting model at:\", datetime.datetime.now())\n",
    "    model = SARIMAX(history, order=arima_order, seasonal_order=sarima_order,enforce_invertibility=False,enforce_stationarity=False)\n",
    "    model_fit = model.fit(disp=True,enforce_invertibility=False,enforce_stationarity=False, maxiter=100)\n",
    "\n",
    "    #save the state parameter\n",
    "    est_params = model_fit.params\n",
    "    est_state = model_fit.predicted_state[:, -1]\n",
    "    est_state_cov = model_fit.predicted_state_cov[:, :, -1]\n",
    "\n",
    "    st = 0\n",
    "        \n",
    "    print(\"Forecasting at:\", datetime.datetime.now())\n",
    "    for t in np.arange(1,len(test)+1,step):\n",
    "        obs = test.iloc[st:t].values\n",
    "        history.extend(obs)\n",
    "        history = history[-window_size:]\n",
    "        \n",
    "        mod_updated = SARIMAX(history, order=arima_order, seasonal_order=sarima_order,enforce_invertibility=False,enforce_stationarity=False)\n",
    "        mod_updated.initialize_known(est_state, est_state_cov)\n",
    "        mod_frcst = mod_updated.smooth(est_params)\n",
    "        \n",
    "        yhat = mod_frcst.forecast(step)   \n",
    "        predictions.extend(yhat)\n",
    "            \n",
    "        est_params = mod_frcst.params\n",
    "        est_state = mod_frcst.predicted_state[:, -1]\n",
    "        est_state_cov = mod_frcst.predicted_state_cov[:, :, -1]\n",
    "            \n",
    "        st = t\n",
    "    print(\"Forecasting complete at:\", datetime.datetime.now())\n",
    "                \n",
    "    return predictions[:len(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv_SARIMA(df, step):\n",
    "\n",
    "#    p_values = [0,1,2]\n",
    "#    d_values = [0,1]\n",
    "#    q_values = [0,1,2]\n",
    "#    P_values = [0,1]\n",
    "#    D_Values = [0,1]\n",
    "#    Q_Values = [0,1]\n",
    "\n",
    "    p_values = [2]\n",
    "    d_values = [0,1]\n",
    "    q_values = [2]\n",
    "    P_values = [1]\n",
    "    D_Values = [1]\n",
    "    Q_Values = [1]\n",
    "\n",
    "    parameters = product(p_values, d_values, q_values, P_values, D_Values, Q_Values)\n",
    "    parameters_list = list(parameters)\n",
    "    period_length = 144 #de 00:00 as 23:50\n",
    "\n",
    "    \n",
    "    forecasts = []\n",
    "    lags_list = []\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    while test_end < limit :\n",
    "        print(\"Index: \", index.strftime('%Y-%m-%d'))  \n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        index = index + datetime.timedelta(days=7)\n",
    "        \n",
    "        train = df[train_start : train_end]\n",
    "        validation = df[validation_start : validation_end]\n",
    "        test = df[test_start : test_end]\n",
    "    \n",
    "        # Perform grid search\n",
    "        (arima_params, sarima_params) = evaluate_SARIMA_models(\"nested_test_sarima_oahu\", train[target_station], validation[target_station], parameters_list, period_length)\n",
    "        \n",
    "        # Concat train & validation for test\n",
    "        train = train.append(validation)\n",
    "        yhat = sarima_forecast(train[target_station], test[target_station], arima_params, sarima_params)        \n",
    "        \n",
    "        lags_list.append(1)\n",
    "        forecasts.append(yhat)\n",
    "        save_obj(forecasts,\"temp_fcst\")\n",
    "    return forecasts, lags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_clean, order_list_clean = rolling_cv_SARIMA(norm_df_ssa_clean, 1)\n",
    "forecasts_residual, order_list_residual = rolling_cv_SARIMA(norm_df_ssa_residual, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_final, order_list = get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_rolling_error(\"rolling_cv_wind_ssa_sarima\", df, forecasts_final, order_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cseve\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import VAR, DynamicVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_VAR_models(test_name, train, validation,target, maxlags_list):\n",
    "    var_results = pd.DataFrame(columns=['Order','RMSE'])\n",
    "    best_score, best_cfg, best_model = float(\"inf\"), None, None\n",
    "    \n",
    "    for lgs in maxlags_list:\n",
    "        model = VAR(train)\n",
    "        results = model.fit(maxlags=lgs, ic='aic')\n",
    "        \n",
    "        order = results.k_ar\n",
    "        forecast = []\n",
    "\n",
    "        for i in range(len(validation)-order) :\n",
    "            forecast.extend(results.forecast(validation.values[i:i+order],1))\n",
    "\n",
    "        forecast_df = pd.DataFrame(columns=validation.columns, data=forecast)\n",
    "        rmse = Measures.rmse(validation[target].iloc[order:], forecast_df[target].values)\n",
    "\n",
    "        if rmse < best_score:\n",
    "            best_score, best_cfg, best_model = rmse, order, results\n",
    "\n",
    "        res = {'Order' : str(order) ,'RMSE' : rmse}\n",
    "        print('VAR (%s)  RMSE=%.3f' % (str(order),rmse))\n",
    "        var_results = var_results.append(res, ignore_index=True)\n",
    "        var_results.to_csv(test_name+\".csv\")\n",
    "        \n",
    "    print('Best VAR(%s) RMSE=%.3f' % (best_cfg, best_score))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def var_forecast(train, test, target, order, step):\n",
    "    model = VAR(train.values)\n",
    "    results = model.fit(maxlags=order)\n",
    "    lag_order = results.k_ar\n",
    "    print(\"Lag order:\" + str(lag_order))\n",
    "    forecast = []\n",
    "\n",
    "    for i in np.arange(0,len(test)-lag_order+1,step) :\n",
    "        forecast.extend(results.forecast(test.values[i:i+lag_order],step))\n",
    "\n",
    "    forecast_df = pd.DataFrame(columns=test.columns, data=forecast)\n",
    "    return forecast_df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv_var(df, step):\n",
    "    maxlags_list = [1,2,4,6,8,10,20,40]\n",
    "    forecasts = []\n",
    "    order_list = []\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    while test_end < limit :\n",
    "        print(\"Index: \", index.strftime('%Y-%m-%d'))  \n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        index = index + datetime.timedelta(days=7)\n",
    "        \n",
    "        train = df[train_start : train_end]\n",
    "        validation = df[validation_start : validation_end]\n",
    "        test = df[test_start : test_end]\n",
    "    \n",
    "        # Perform grid search\n",
    "        best_model = evaluate_VAR_models(\"nested_test_var_oahu\", train[neighbor_stations_90], validation[neighbor_stations_90],target_station, maxlags_list)\n",
    "\n",
    "        # Concat train & validation for test\n",
    "        train = train.append(validation)\n",
    "        order = best_model.k_ar\n",
    "        yhat = var_forecast(train[neighbor_stations_90], test[neighbor_stations_90], target_station, order, step)\n",
    "        \n",
    "        order_list.append(order)\n",
    "        forecasts.append(yhat)\n",
    "\n",
    "    return forecasts, order_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  2017-05-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cseve\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py:461: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  params = np.linalg.lstsq(z, y_sample)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAR (1)  RMSE=0.010\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (40)  RMSE=0.003\n",
      "Best VAR(10) RMSE=0.002\n",
      "Lag order:10\n",
      "Index:  2017-05-08\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.004\n",
      "VAR (6)  RMSE=0.004\n",
      "VAR (8)  RMSE=0.004\n",
      "VAR (10)  RMSE=0.004\n",
      "VAR (20)  RMSE=0.004\n",
      "VAR (39)  RMSE=0.007\n",
      "Best VAR(2) RMSE=0.004\n",
      "Lag order:2\n",
      "Index:  2017-05-15\n",
      "VAR (1)  RMSE=0.008\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-05-22\n",
      "VAR (1)  RMSE=0.010\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (33)  RMSE=0.003\n",
      "Best VAR(20) RMSE=0.003\n",
      "Lag order:20\n",
      "Index:  2017-05-29\n",
      "VAR (1)  RMSE=0.011\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (39)  RMSE=0.004\n",
      "Best VAR(10) RMSE=0.003\n",
      "Lag order:10\n",
      "Index:  2017-06-05\n",
      "VAR (1)  RMSE=0.010\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.004\n",
      "VAR (6)  RMSE=0.004\n",
      "VAR (8)  RMSE=0.004\n",
      "VAR (10)  RMSE=0.004\n",
      "VAR (20)  RMSE=0.004\n",
      "VAR (34)  RMSE=0.004\n",
      "Best VAR(20) RMSE=0.004\n",
      "Lag order:20\n",
      "Index:  2017-06-12\n",
      "VAR (1)  RMSE=0.010\n",
      "VAR (2)  RMSE=0.005\n",
      "VAR (4)  RMSE=0.004\n",
      "VAR (6)  RMSE=0.004\n",
      "VAR (8)  RMSE=0.004\n",
      "VAR (10)  RMSE=0.004\n",
      "VAR (20)  RMSE=0.004\n",
      "VAR (38)  RMSE=0.005\n",
      "Best VAR(8) RMSE=0.004\n",
      "Lag order:8\n",
      "Index:  2017-06-19\n",
      "VAR (1)  RMSE=0.011\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (38)  RMSE=0.003\n",
      "Best VAR(20) RMSE=0.003\n",
      "Lag order:20\n",
      "Index:  2017-06-26\n",
      "VAR (1)  RMSE=0.009\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (38)  RMSE=0.004\n",
      "Best VAR(8) RMSE=0.003\n",
      "Lag order:8\n",
      "Index:  2017-07-03\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (38)  RMSE=0.003\n",
      "Best VAR(8) RMSE=0.002\n",
      "Lag order:8\n",
      "Index:  2017-07-10\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-07-17\n",
      "VAR (1)  RMSE=0.008\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-07-24\n",
      "VAR (1)  RMSE=0.009\n",
      "VAR (2)  RMSE=0.005\n",
      "VAR (4)  RMSE=0.004\n",
      "VAR (6)  RMSE=0.004\n",
      "VAR (8)  RMSE=0.004\n",
      "VAR (10)  RMSE=0.004\n",
      "VAR (20)  RMSE=0.004\n",
      "VAR (39)  RMSE=0.005\n",
      "Best VAR(8) RMSE=0.004\n",
      "Lag order:8\n",
      "Index:  2017-07-31\n",
      "VAR (1)  RMSE=0.009\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-08-07\n",
      "VAR (1)  RMSE=0.008\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (38)  RMSE=0.004\n",
      "Best VAR(8) RMSE=0.003\n",
      "Lag order:8\n",
      "Index:  2017-08-14\n",
      "VAR (1)  RMSE=0.010\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (39)  RMSE=0.004\n",
      "Best VAR(10) RMSE=0.003\n",
      "Lag order:10\n",
      "Index:  2017-08-21\n",
      "VAR (1)  RMSE=0.009\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-08-28\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.002\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-09-04\n",
      "VAR (1)  RMSE=0.008\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(8) RMSE=0.003\n",
      "Lag order:8\n",
      "Index:  2017-09-11\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.002\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-09-18\n",
      "VAR (1)  RMSE=0.008\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (40)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-09-25\n",
      "VAR (1)  RMSE=0.006\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(8) RMSE=0.003\n",
      "Lag order:8\n",
      "Index:  2017-10-02\n",
      "VAR (1)  RMSE=0.006\n",
      "VAR (2)  RMSE=0.002\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-10-09\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.002\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-10-16\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(8) RMSE=0.002\n",
      "Lag order:8\n",
      "Index:  2017-10-23\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.002\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-10-30\n",
      "VAR (1)  RMSE=0.006\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.004\n",
      "VAR (38)  RMSE=0.004\n",
      "Best VAR(6) RMSE=0.003\n",
      "Lag order:6\n",
      "Index:  2017-11-06\n",
      "VAR (1)  RMSE=0.006\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (38)  RMSE=0.002\n",
      "Best VAR(10) RMSE=0.002\n",
      "Lag order:10\n",
      "Index:  2017-11-13\n",
      "VAR (1)  RMSE=0.008\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.004\n",
      "VAR (6)  RMSE=0.004\n",
      "VAR (8)  RMSE=0.004\n",
      "VAR (10)  RMSE=0.004\n",
      "VAR (20)  RMSE=0.004\n",
      "VAR (38)  RMSE=0.004\n",
      "Best VAR(10) RMSE=0.004\n",
      "Lag order:10\n",
      "Index:  2017-11-20\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(10) RMSE=0.002\n",
      "Lag order:10\n",
      "Index:  2017-11-27\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(8) RMSE=0.002\n",
      "Lag order:8\n",
      "Index:  2017-12-04\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.002\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-12-11\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (38)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-12-18\n",
      "VAR (1)  RMSE=0.008\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (39)  RMSE=0.004\n",
      "Best VAR(8) RMSE=0.003\n",
      "Lag order:8\n",
      "Index:  2017-12-25\n",
      "VAR (1)  RMSE=0.008\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(39) RMSE=0.002\n",
      "Lag order:39\n",
      "Index:  2018-01-01\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.004\n",
      "VAR (40)  RMSE=0.006\n",
      "Best VAR(6) RMSE=0.003\n",
      "Lag order:6\n",
      "Index:  2018-01-08\n",
      "VAR (1)  RMSE=0.009\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (39)  RMSE=0.004\n",
      "Best VAR(10) RMSE=0.002\n",
      "Lag order:10\n",
      "Index:  2018-01-15\n",
      "VAR (1)  RMSE=0.010\n",
      "VAR (2)  RMSE=0.006\n",
      "VAR (4)  RMSE=0.006\n",
      "VAR (6)  RMSE=0.006\n",
      "VAR (8)  RMSE=0.006\n",
      "VAR (10)  RMSE=0.006\n",
      "VAR (20)  RMSE=0.007\n",
      "VAR (40)  RMSE=0.008\n",
      "Best VAR(2) RMSE=0.006\n",
      "Lag order:2\n",
      "Index:  2018-01-22\n",
      "VAR (1)  RMSE=0.009\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(10) RMSE=0.003\n",
      "Lag order:10\n",
      "Index:  2018-01-29\n",
      "VAR (1)  RMSE=0.009\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.003\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (39)  RMSE=0.006\n",
      "Best VAR(8) RMSE=0.003\n",
      "Lag order:8\n",
      "Index:  2018-02-05\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (38)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2018-02-12\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(10) RMSE=0.002\n",
      "Lag order:10\n",
      "Index:  2018-02-19\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.004\n",
      "VAR (6)  RMSE=0.004\n",
      "VAR (8)  RMSE=0.004\n",
      "VAR (10)  RMSE=0.004\n",
      "VAR (20)  RMSE=0.004\n",
      "VAR (39)  RMSE=0.005\n",
      "Best VAR(2) RMSE=0.003\n",
      "Lag order:2\n",
      "Index:  2018-02-26\n",
      "VAR (1)  RMSE=0.010\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.003\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.003\n",
      "VAR (39)  RMSE=0.003\n",
      "Best VAR(10) RMSE=0.002\n",
      "Lag order:10\n",
      "Index:  2018-03-05\n",
      "VAR (1)  RMSE=0.008\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (39)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2018-03-12\n",
      "VAR (1)  RMSE=0.009\n",
      "VAR (2)  RMSE=0.004\n",
      "VAR (4)  RMSE=0.003\n",
      "VAR (6)  RMSE=0.003\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (38)  RMSE=0.002\n",
      "Best VAR(10) RMSE=0.002\n",
      "Lag order:10\n",
      "Index:  2018-03-19\n",
      "VAR (1)  RMSE=0.007\n",
      "VAR (2)  RMSE=0.003\n",
      "VAR (4)  RMSE=0.002\n",
      "VAR (6)  RMSE=0.002\n",
      "VAR (8)  RMSE=0.002\n",
      "VAR (10)  RMSE=0.002\n",
      "VAR (20)  RMSE=0.002\n",
      "VAR (40)  RMSE=0.002\n",
      "Best VAR(20) RMSE=0.002\n",
      "Lag order:20\n",
      "Index:  2017-05-01\n",
      "VAR (1)  RMSE=0.070\n",
      "VAR (2)  RMSE=0.067\n",
      "VAR (4)  RMSE=0.065\n",
      "VAR (6)  RMSE=0.064\n",
      "VAR (8)  RMSE=0.064\n",
      "VAR (10)  RMSE=0.063\n",
      "VAR (20)  RMSE=0.062\n",
      "VAR (28)  RMSE=0.063\n",
      "Best VAR(20) RMSE=0.062\n",
      "Lag order:20\n",
      "Index:  2017-05-08\n",
      "VAR (1)  RMSE=0.060\n",
      "VAR (2)  RMSE=0.059\n",
      "VAR (4)  RMSE=0.058\n",
      "VAR (6)  RMSE=0.057\n",
      "VAR (8)  RMSE=0.057\n",
      "VAR (10)  RMSE=0.056\n",
      "VAR (20)  RMSE=0.056\n",
      "VAR (31)  RMSE=0.057\n",
      "Best VAR(20) RMSE=0.056\n",
      "Lag order:20\n",
      "Index:  2017-05-15\n",
      "VAR (1)  RMSE=0.064\n",
      "VAR (2)  RMSE=0.063\n",
      "VAR (4)  RMSE=0.061\n",
      "VAR (6)  RMSE=0.060\n",
      "VAR (8)  RMSE=0.059\n",
      "VAR (10)  RMSE=0.059\n",
      "VAR (20)  RMSE=0.058\n",
      "VAR (31)  RMSE=0.058\n",
      "Best VAR(31) RMSE=0.058\n",
      "Lag order:31\n",
      "Index:  2017-05-22\n",
      "VAR (1)  RMSE=0.069\n",
      "VAR (2)  RMSE=0.067\n",
      "VAR (4)  RMSE=0.066\n",
      "VAR (6)  RMSE=0.065\n",
      "VAR (8)  RMSE=0.065\n",
      "VAR (10)  RMSE=0.065\n",
      "VAR (20)  RMSE=0.064\n",
      "VAR (32)  RMSE=0.066\n",
      "Best VAR(20) RMSE=0.064\n",
      "Lag order:20\n",
      "Index:  2017-05-29\n",
      "VAR (1)  RMSE=0.078\n",
      "VAR (2)  RMSE=0.076\n",
      "VAR (4)  RMSE=0.072\n",
      "VAR (6)  RMSE=0.071\n",
      "VAR (8)  RMSE=0.070\n",
      "VAR (10)  RMSE=0.070\n",
      "VAR (20)  RMSE=0.071\n",
      "VAR (33)  RMSE=0.071\n",
      "Best VAR(10) RMSE=0.070\n",
      "Lag order:10\n",
      "Index:  2017-06-05\n",
      "VAR (1)  RMSE=0.079\n",
      "VAR (2)  RMSE=0.077\n",
      "VAR (4)  RMSE=0.074\n",
      "VAR (6)  RMSE=0.073\n",
      "VAR (8)  RMSE=0.072\n",
      "VAR (10)  RMSE=0.072\n",
      "VAR (20)  RMSE=0.071\n",
      "VAR (31)  RMSE=0.072\n",
      "Best VAR(20) RMSE=0.071\n",
      "Lag order:20\n",
      "Index:  2017-06-12\n",
      "VAR (1)  RMSE=0.078\n",
      "VAR (2)  RMSE=0.075\n",
      "VAR (4)  RMSE=0.072\n",
      "VAR (6)  RMSE=0.070\n",
      "VAR (8)  RMSE=0.070\n",
      "VAR (10)  RMSE=0.069\n",
      "VAR (20)  RMSE=0.069\n",
      "VAR (27)  RMSE=0.068\n",
      "Best VAR(27) RMSE=0.068\n",
      "Lag order:27\n",
      "Index:  2017-06-19\n",
      "VAR (1)  RMSE=0.070\n",
      "VAR (2)  RMSE=0.069\n",
      "VAR (4)  RMSE=0.067\n",
      "VAR (6)  RMSE=0.066\n",
      "VAR (8)  RMSE=0.066\n",
      "VAR (10)  RMSE=0.066\n",
      "VAR (20)  RMSE=0.064\n",
      "VAR (24)  RMSE=0.064\n",
      "Best VAR(20) RMSE=0.064\n",
      "Lag order:20\n",
      "Index:  2017-06-26\n",
      "VAR (1)  RMSE=0.080\n",
      "VAR (2)  RMSE=0.077\n",
      "VAR (4)  RMSE=0.075\n",
      "VAR (6)  RMSE=0.073\n",
      "VAR (8)  RMSE=0.072\n",
      "VAR (10)  RMSE=0.072\n",
      "VAR (20)  RMSE=0.071\n",
      "VAR (26)  RMSE=0.072\n",
      "Best VAR(20) RMSE=0.071\n",
      "Lag order:20\n",
      "Index:  2017-07-03\n",
      "VAR (1)  RMSE=0.057\n",
      "VAR (2)  RMSE=0.056\n",
      "VAR (4)  RMSE=0.055\n",
      "VAR (6)  RMSE=0.054\n",
      "VAR (8)  RMSE=0.054\n",
      "VAR (10)  RMSE=0.053\n",
      "VAR (20)  RMSE=0.052\n",
      "VAR (26)  RMSE=0.052\n",
      "Best VAR(20) RMSE=0.052\n",
      "Lag order:20\n",
      "Index:  2017-07-10\n",
      "VAR (1)  RMSE=0.055\n",
      "VAR (2)  RMSE=0.055\n",
      "VAR (4)  RMSE=0.053\n",
      "VAR (6)  RMSE=0.052\n",
      "VAR (8)  RMSE=0.052\n",
      "VAR (10)  RMSE=0.051\n",
      "VAR (20)  RMSE=0.051\n",
      "VAR (26)  RMSE=0.051\n",
      "Best VAR(26) RMSE=0.051\n",
      "Lag order:26\n",
      "Index:  2017-07-17\n",
      "VAR (1)  RMSE=0.063\n",
      "VAR (2)  RMSE=0.061\n",
      "VAR (4)  RMSE=0.060\n",
      "VAR (6)  RMSE=0.059\n",
      "VAR (8)  RMSE=0.058\n",
      "VAR (10)  RMSE=0.058\n",
      "VAR (20)  RMSE=0.057\n",
      "VAR (32)  RMSE=0.057\n",
      "Best VAR(20) RMSE=0.057\n",
      "Lag order:20\n",
      "Index:  2017-07-24\n",
      "VAR (1)  RMSE=0.068\n",
      "VAR (2)  RMSE=0.067\n",
      "VAR (4)  RMSE=0.064\n",
      "VAR (6)  RMSE=0.063\n",
      "VAR (8)  RMSE=0.063\n",
      "VAR (10)  RMSE=0.063\n",
      "VAR (20)  RMSE=0.063\n",
      "VAR (35)  RMSE=0.064\n",
      "Best VAR(8) RMSE=0.063\n",
      "Lag order:8\n",
      "Index:  2017-07-31\n",
      "VAR (1)  RMSE=0.061\n",
      "VAR (2)  RMSE=0.060\n",
      "VAR (4)  RMSE=0.058\n",
      "VAR (6)  RMSE=0.058\n",
      "VAR (8)  RMSE=0.057\n",
      "VAR (10)  RMSE=0.057\n",
      "VAR (20)  RMSE=0.056\n",
      "VAR (30)  RMSE=0.056\n",
      "Best VAR(20) RMSE=0.056\n",
      "Lag order:20\n",
      "Index:  2017-08-07\n",
      "VAR (1)  RMSE=0.069\n",
      "VAR (2)  RMSE=0.066\n",
      "VAR (4)  RMSE=0.064\n",
      "VAR (6)  RMSE=0.063\n",
      "VAR (8)  RMSE=0.063\n",
      "VAR (10)  RMSE=0.062\n",
      "VAR (20)  RMSE=0.062\n",
      "VAR (29)  RMSE=0.061\n",
      "Best VAR(29) RMSE=0.061\n",
      "Lag order:29\n",
      "Index:  2017-08-14\n",
      "VAR (1)  RMSE=0.075\n",
      "VAR (2)  RMSE=0.073\n",
      "VAR (4)  RMSE=0.070\n",
      "VAR (6)  RMSE=0.069\n",
      "VAR (8)  RMSE=0.068\n",
      "VAR (10)  RMSE=0.068\n",
      "VAR (20)  RMSE=0.067\n",
      "VAR (28)  RMSE=0.067\n",
      "Best VAR(20) RMSE=0.067\n",
      "Lag order:20\n",
      "Index:  2017-08-21\n",
      "VAR (1)  RMSE=0.066\n",
      "VAR (2)  RMSE=0.064\n",
      "VAR (4)  RMSE=0.062\n",
      "VAR (6)  RMSE=0.061\n",
      "VAR (8)  RMSE=0.060\n",
      "VAR (10)  RMSE=0.060\n",
      "VAR (20)  RMSE=0.060\n",
      "VAR (28)  RMSE=0.061\n",
      "Best VAR(10) RMSE=0.060\n",
      "Lag order:10\n",
      "Index:  2017-08-28\n",
      "VAR (1)  RMSE=0.053\n",
      "VAR (2)  RMSE=0.052\n",
      "VAR (4)  RMSE=0.050\n",
      "VAR (6)  RMSE=0.050\n",
      "VAR (8)  RMSE=0.049\n",
      "VAR (10)  RMSE=0.049\n",
      "VAR (20)  RMSE=0.049\n",
      "VAR (28)  RMSE=0.049\n",
      "Best VAR(20) RMSE=0.049\n",
      "Lag order:20\n",
      "Index:  2017-09-04\n",
      "VAR (1)  RMSE=0.059\n",
      "VAR (2)  RMSE=0.057\n",
      "VAR (4)  RMSE=0.055\n",
      "VAR (6)  RMSE=0.055\n",
      "VAR (8)  RMSE=0.055\n",
      "VAR (10)  RMSE=0.054\n",
      "VAR (20)  RMSE=0.054\n",
      "VAR (28)  RMSE=0.054\n",
      "Best VAR(28) RMSE=0.054\n",
      "Lag order:28\n",
      "Index:  2017-09-11\n",
      "VAR (1)  RMSE=0.054\n",
      "VAR (2)  RMSE=0.053\n",
      "VAR (4)  RMSE=0.051\n",
      "VAR (6)  RMSE=0.051\n",
      "VAR (8)  RMSE=0.050\n",
      "VAR (10)  RMSE=0.050\n",
      "VAR (20)  RMSE=0.050\n",
      "VAR (28)  RMSE=0.050\n",
      "Best VAR(28) RMSE=0.050\n",
      "Lag order:28\n",
      "Index:  2017-09-18\n",
      "VAR (1)  RMSE=0.058\n",
      "VAR (2)  RMSE=0.057\n",
      "VAR (4)  RMSE=0.056\n",
      "VAR (6)  RMSE=0.055\n",
      "VAR (8)  RMSE=0.054\n",
      "VAR (10)  RMSE=0.054\n",
      "VAR (20)  RMSE=0.054\n",
      "VAR (32)  RMSE=0.054\n",
      "Best VAR(32) RMSE=0.054\n",
      "Lag order:32\n",
      "Index:  2017-09-25\n",
      "VAR (1)  RMSE=0.053\n",
      "VAR (2)  RMSE=0.052\n",
      "VAR (4)  RMSE=0.049\n",
      "VAR (6)  RMSE=0.049\n",
      "VAR (8)  RMSE=0.049\n",
      "VAR (10)  RMSE=0.048\n",
      "VAR (20)  RMSE=0.048\n",
      "VAR (32)  RMSE=0.048\n",
      "Best VAR(32) RMSE=0.048\n",
      "Lag order:32\n",
      "Index:  2017-10-02\n",
      "VAR (1)  RMSE=0.046\n",
      "VAR (2)  RMSE=0.045\n",
      "VAR (4)  RMSE=0.044\n",
      "VAR (6)  RMSE=0.043\n",
      "VAR (8)  RMSE=0.043\n",
      "VAR (10)  RMSE=0.042\n",
      "VAR (20)  RMSE=0.042\n",
      "VAR (32)  RMSE=0.042\n",
      "Best VAR(32) RMSE=0.042\n",
      "Lag order:32\n",
      "Index:  2017-10-09\n",
      "VAR (1)  RMSE=0.049\n",
      "VAR (2)  RMSE=0.048\n",
      "VAR (4)  RMSE=0.047\n",
      "VAR (6)  RMSE=0.046\n",
      "VAR (8)  RMSE=0.046\n",
      "VAR (10)  RMSE=0.045\n",
      "VAR (20)  RMSE=0.045\n",
      "VAR (32)  RMSE=0.045\n",
      "Best VAR(32) RMSE=0.045\n",
      "Lag order:32\n",
      "Index:  2017-10-16\n",
      "VAR (1)  RMSE=0.050\n",
      "VAR (2)  RMSE=0.049\n",
      "VAR (4)  RMSE=0.048\n",
      "VAR (6)  RMSE=0.047\n",
      "VAR (8)  RMSE=0.047\n",
      "VAR (10)  RMSE=0.047\n",
      "VAR (20)  RMSE=0.046\n",
      "VAR (32)  RMSE=0.046\n",
      "Best VAR(20) RMSE=0.046\n",
      "Lag order:20\n",
      "Index:  2017-10-23\n",
      "VAR (1)  RMSE=0.048\n",
      "VAR (2)  RMSE=0.047\n",
      "VAR (4)  RMSE=0.046\n",
      "VAR (6)  RMSE=0.045\n",
      "VAR (8)  RMSE=0.044\n",
      "VAR (10)  RMSE=0.044\n",
      "VAR (20)  RMSE=0.043\n",
      "VAR (30)  RMSE=0.043\n",
      "Best VAR(30) RMSE=0.043\n",
      "Lag order:30\n",
      "Index:  2017-10-30\n",
      "VAR (1)  RMSE=0.050\n",
      "VAR (2)  RMSE=0.049\n",
      "VAR (4)  RMSE=0.047\n",
      "VAR (6)  RMSE=0.046\n",
      "VAR (8)  RMSE=0.046\n",
      "VAR (10)  RMSE=0.045\n",
      "VAR (20)  RMSE=0.044\n",
      "VAR (28)  RMSE=0.044\n",
      "Best VAR(28) RMSE=0.044\n",
      "Lag order:28\n",
      "Index:  2017-11-06\n",
      "VAR (1)  RMSE=0.047\n",
      "VAR (2)  RMSE=0.046\n",
      "VAR (4)  RMSE=0.045\n",
      "VAR (6)  RMSE=0.044\n",
      "VAR (8)  RMSE=0.044\n",
      "VAR (10)  RMSE=0.043\n",
      "VAR (20)  RMSE=0.043\n",
      "VAR (28)  RMSE=0.043\n",
      "Best VAR(28) RMSE=0.043\n",
      "Lag order:28\n",
      "Index:  2017-11-13\n",
      "VAR (1)  RMSE=0.053\n",
      "VAR (2)  RMSE=0.052\n",
      "VAR (4)  RMSE=0.051\n",
      "VAR (6)  RMSE=0.051\n",
      "VAR (8)  RMSE=0.050\n",
      "VAR (10)  RMSE=0.050\n",
      "VAR (20)  RMSE=0.049\n",
      "VAR (28)  RMSE=0.049\n",
      "Best VAR(20) RMSE=0.049\n",
      "Lag order:20\n",
      "Index:  2017-11-20\n",
      "VAR (1)  RMSE=0.051\n",
      "VAR (2)  RMSE=0.050\n",
      "VAR (4)  RMSE=0.048\n",
      "VAR (6)  RMSE=0.047\n",
      "VAR (8)  RMSE=0.047\n",
      "VAR (10)  RMSE=0.046\n",
      "VAR (20)  RMSE=0.046\n",
      "VAR (27)  RMSE=0.047\n",
      "Best VAR(10) RMSE=0.046\n",
      "Lag order:10\n",
      "Index:  2017-11-27\n",
      "VAR (1)  RMSE=0.053\n",
      "VAR (2)  RMSE=0.052\n",
      "VAR (4)  RMSE=0.050\n",
      "VAR (6)  RMSE=0.050\n",
      "VAR (8)  RMSE=0.049\n",
      "VAR (10)  RMSE=0.048\n",
      "VAR (20)  RMSE=0.048\n",
      "VAR (28)  RMSE=0.048\n",
      "Best VAR(28) RMSE=0.048\n",
      "Lag order:28\n",
      "Index:  2017-12-04\n",
      "VAR (1)  RMSE=0.051\n",
      "VAR (2)  RMSE=0.051\n",
      "VAR (4)  RMSE=0.049\n",
      "VAR (6)  RMSE=0.049\n",
      "VAR (8)  RMSE=0.048\n",
      "VAR (10)  RMSE=0.048\n",
      "VAR (20)  RMSE=0.047\n",
      "VAR (29)  RMSE=0.047\n",
      "Best VAR(29) RMSE=0.047\n",
      "Lag order:29\n",
      "Index:  2017-12-11\n",
      "VAR (1)  RMSE=0.054\n",
      "VAR (2)  RMSE=0.053\n",
      "VAR (4)  RMSE=0.051\n",
      "VAR (6)  RMSE=0.050\n",
      "VAR (8)  RMSE=0.050\n",
      "VAR (10)  RMSE=0.049\n",
      "VAR (20)  RMSE=0.048\n",
      "VAR (30)  RMSE=0.050\n",
      "Best VAR(20) RMSE=0.048\n",
      "Lag order:20\n",
      "Index:  2017-12-18\n",
      "VAR (1)  RMSE=0.066\n",
      "VAR (2)  RMSE=0.064\n",
      "VAR (4)  RMSE=0.062\n",
      "VAR (6)  RMSE=0.062\n",
      "VAR (8)  RMSE=0.061\n",
      "VAR (10)  RMSE=0.060\n",
      "VAR (20)  RMSE=0.058\n",
      "VAR (28)  RMSE=0.058\n",
      "Best VAR(28) RMSE=0.058\n",
      "Lag order:28\n",
      "Index:  2017-12-25\n",
      "VAR (1)  RMSE=0.057\n",
      "VAR (2)  RMSE=0.055\n",
      "VAR (4)  RMSE=0.054\n",
      "VAR (6)  RMSE=0.054\n",
      "VAR (8)  RMSE=0.053\n",
      "VAR (10)  RMSE=0.052\n",
      "VAR (20)  RMSE=0.051\n",
      "VAR (35)  RMSE=0.051\n",
      "Best VAR(35) RMSE=0.051\n",
      "Lag order:35\n",
      "Index:  2018-01-01\n",
      "VAR (1)  RMSE=0.046\n",
      "VAR (2)  RMSE=0.046\n",
      "VAR (4)  RMSE=0.044\n",
      "VAR (6)  RMSE=0.043\n",
      "VAR (8)  RMSE=0.043\n",
      "VAR (10)  RMSE=0.043\n",
      "VAR (20)  RMSE=0.043\n",
      "VAR (35)  RMSE=0.043\n",
      "Best VAR(20) RMSE=0.043\n",
      "Lag order:20\n",
      "Index:  2018-01-08\n",
      "VAR (1)  RMSE=0.055\n",
      "VAR (2)  RMSE=0.054\n",
      "VAR (4)  RMSE=0.053\n",
      "VAR (6)  RMSE=0.052\n",
      "VAR (8)  RMSE=0.052\n",
      "VAR (10)  RMSE=0.051\n",
      "VAR (20)  RMSE=0.051\n",
      "VAR (35)  RMSE=0.051\n",
      "Best VAR(20) RMSE=0.051\n",
      "Lag order:20\n",
      "Index:  2018-01-15\n",
      "VAR (1)  RMSE=0.065\n",
      "VAR (2)  RMSE=0.063\n",
      "VAR (4)  RMSE=0.060\n",
      "VAR (6)  RMSE=0.059\n",
      "VAR (8)  RMSE=0.059\n",
      "VAR (10)  RMSE=0.058\n",
      "VAR (20)  RMSE=0.058\n",
      "VAR (30)  RMSE=0.059\n",
      "Best VAR(10) RMSE=0.058\n",
      "Lag order:10\n",
      "Index:  2018-01-22\n",
      "VAR (1)  RMSE=0.067\n",
      "VAR (2)  RMSE=0.064\n",
      "VAR (4)  RMSE=0.062\n",
      "VAR (6)  RMSE=0.061\n",
      "VAR (8)  RMSE=0.060\n",
      "VAR (10)  RMSE=0.060\n",
      "VAR (20)  RMSE=0.059\n",
      "VAR (32)  RMSE=0.060\n",
      "Best VAR(20) RMSE=0.059\n",
      "Lag order:20\n",
      "Index:  2018-01-29\n",
      "VAR (1)  RMSE=0.059\n",
      "VAR (2)  RMSE=0.057\n",
      "VAR (4)  RMSE=0.056\n",
      "VAR (6)  RMSE=0.055\n",
      "VAR (8)  RMSE=0.055\n",
      "VAR (10)  RMSE=0.055\n",
      "VAR (20)  RMSE=0.055\n",
      "VAR (30)  RMSE=0.055\n",
      "Best VAR(8) RMSE=0.055\n",
      "Lag order:8\n",
      "Index:  2018-02-05\n",
      "VAR (1)  RMSE=0.048\n",
      "VAR (2)  RMSE=0.048\n",
      "VAR (4)  RMSE=0.047\n",
      "VAR (6)  RMSE=0.046\n",
      "VAR (8)  RMSE=0.045\n",
      "VAR (10)  RMSE=0.045\n",
      "VAR (20)  RMSE=0.044\n",
      "VAR (30)  RMSE=0.044\n",
      "Best VAR(30) RMSE=0.044\n",
      "Lag order:30\n",
      "Index:  2018-02-12\n",
      "VAR (1)  RMSE=0.049\n",
      "VAR (2)  RMSE=0.047\n",
      "VAR (4)  RMSE=0.046\n",
      "VAR (6)  RMSE=0.046\n",
      "VAR (8)  RMSE=0.045\n",
      "VAR (10)  RMSE=0.045\n",
      "VAR (20)  RMSE=0.045\n",
      "VAR (32)  RMSE=0.046\n",
      "Best VAR(10) RMSE=0.045\n",
      "Lag order:10\n",
      "Index:  2018-02-19\n",
      "VAR (1)  RMSE=0.046\n",
      "VAR (2)  RMSE=0.046\n",
      "VAR (4)  RMSE=0.044\n",
      "VAR (6)  RMSE=0.044\n",
      "VAR (8)  RMSE=0.043\n",
      "VAR (10)  RMSE=0.043\n",
      "VAR (20)  RMSE=0.042\n",
      "VAR (30)  RMSE=0.043\n",
      "Best VAR(20) RMSE=0.042\n",
      "Lag order:20\n",
      "Index:  2018-02-26\n",
      "VAR (1)  RMSE=0.068\n",
      "VAR (2)  RMSE=0.065\n",
      "VAR (4)  RMSE=0.063\n",
      "VAR (6)  RMSE=0.062\n",
      "VAR (8)  RMSE=0.062\n",
      "VAR (10)  RMSE=0.061\n",
      "VAR (20)  RMSE=0.061\n",
      "VAR (29)  RMSE=0.060\n",
      "Best VAR(29) RMSE=0.060\n",
      "Lag order:29\n",
      "Index:  2018-03-05\n",
      "VAR (1)  RMSE=0.051\n",
      "VAR (2)  RMSE=0.049\n",
      "VAR (4)  RMSE=0.047\n",
      "VAR (6)  RMSE=0.048\n",
      "VAR (8)  RMSE=0.048\n",
      "VAR (10)  RMSE=0.047\n",
      "VAR (20)  RMSE=0.046\n",
      "VAR (30)  RMSE=0.046\n",
      "Best VAR(20) RMSE=0.046\n",
      "Lag order:20\n",
      "Index:  2018-03-12\n",
      "VAR (1)  RMSE=0.065\n",
      "VAR (2)  RMSE=0.063\n",
      "VAR (4)  RMSE=0.061\n",
      "VAR (6)  RMSE=0.059\n",
      "VAR (8)  RMSE=0.058\n",
      "VAR (10)  RMSE=0.058\n",
      "VAR (19)  RMSE=0.058\n",
      "VAR (30)  RMSE=0.058\n",
      "Best VAR(10) RMSE=0.058\n",
      "Lag order:10\n",
      "Index:  2018-03-19\n",
      "VAR (1)  RMSE=0.059\n",
      "VAR (2)  RMSE=0.057\n",
      "VAR (4)  RMSE=0.055\n",
      "VAR (6)  RMSE=0.054\n",
      "VAR (8)  RMSE=0.054\n",
      "VAR (10)  RMSE=0.053\n",
      "VAR (19)  RMSE=0.053\n",
      "VAR (30)  RMSE=0.053\n",
      "Best VAR(30) RMSE=0.053\n",
      "Lag order:30\n"
     ]
    }
   ],
   "source": [
    "forecasts_clean, order_list_clean = rolling_cv_var(norm_df_ssa_clean, 1)\n",
    "forecasts_residual, order_list_residual = rolling_cv_var(norm_df_ssa_residual, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forecasts_final, order_list = get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot VAR Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(df.index[0])\n",
    "y_pred_wind = forecasts_final[0]\n",
    "y_obs_wind = df[test_start : test_end].WTG01.values\n",
    "\n",
    "#x_date = pd.date_range(\"00:00\", \"24:00\", freq=\"10min\").strftime('%H:%M')\n",
    "\n",
    "#xn = np.arange(len(x_date))\n",
    "xn = np.arange(0,len(y_clean_wind)-1)\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(xn, y_obs_wind[order_list[0]:], label='Observed')\n",
    "plt.plot(xn, y_pred_wind[:-1], color ='orange', label='Predicted')\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Wind Speed [m/s]')\n",
    "ax.legend(loc='best')\n",
    "ticks = [72,216,360,504,648,792,936]\n",
    "ax.set_xticks(ticks)\n",
    "#ax.set_xticklabels(x_date[ticks])\n",
    "ax.set_xticklabels(['05-Jun','06-Jun','07-Jun','08-Jun','09-Jun','10-Jun','11-Jun'])\n",
    "plt.show()\n",
    "fig.savefig(\"plot_wind_ssa\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculate_rolling_error(\"rolling_cv_wind_ssa_var\", df, forecasts_final, order_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Order FTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFTS.partitioners import Grid, Entropy, Util as pUtil\n",
    "from pyFTS.models import hofts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hofts_models(test_name, train, validation, partitioners_list, order_list, partitions_list):\n",
    "    \n",
    "    hofts_results = pd.DataFrame(columns=['Partitioner','Partitions','Order','RMSE'])\n",
    "    best_score, best_cfg, best_model = float(\"inf\"), None, None\n",
    "\n",
    "    for _partitioner in partitioners_list:\n",
    "        for _order in order_list:\n",
    "            for npartitions in partitions_list:\n",
    "                fuzzy_sets = _partitioner(data=train.values, npart=npartitions)\n",
    "                model_simple_hofts = hofts.HighOrderFTS(order=_order)\n",
    "\n",
    "                model_simple_hofts.fit(train.values, order=_order, partitioner=fuzzy_sets, num_batches=100)\n",
    "                \n",
    "                forecast = model_simple_hofts.predict(validation.values)\n",
    "                rmse = Measures.rmse(validation.iloc[_order:], forecast[:-1])\n",
    "\n",
    "                if rmse < best_score:\n",
    "                    best_score, best_cfg = rmse, (_order,npartitions,_partitioner)\n",
    "                    best_model = model_simple_hofts\n",
    "\n",
    "                res = {'Partitioner':str(_partitioner), 'Partitions':npartitions, 'Order' : str(_order) ,'RMSE' : rmse}\n",
    "                print('HOFTS %s - %s - %s  RMSE=%.3f' % (str(_partitioner), npartitions, str(_order),rmse))\n",
    "                hofts_results = hofts_results.append(res, ignore_index=True)\n",
    "                hofts_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best HOFTS(%s) RMSE=%.3f' % (best_cfg, best_score))\n",
    "    \n",
    "    return best_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hofts_forecast(train_df, test_df, _order, _partitioner, _npartitions):\n",
    "    \n",
    "    fuzzy_sets = _partitioner(data=train_df.values, npart=_npartitions)\n",
    "    model_simple_hofts = hofts.HighOrderFTS()\n",
    "    \n",
    "\n",
    "    model_simple_hofts.fit(train_df.values, order=_order, partitioner=fuzzy_sets)\n",
    "\n",
    "    \n",
    "    forecast = model_simple_hofts.predict(test_df.values)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv_hofts(df, step):\n",
    "    \n",
    "#    partitioners_list = [Grid.GridPartitioner, Entropy.EntropyPartitioner]\n",
    "    partitioners_list = [Grid.GridPartitioner]\n",
    "    eval_order_list = np.arange(2,3)\n",
    "    partitions_list = np.arange(80,110,10)\n",
    "    \n",
    "    forecasts = []\n",
    "    order_list = []\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    while test_end < limit :\n",
    "        print(\"Index: \", index.strftime('%Y-%m-%d'))  \n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        index = index + datetime.timedelta(days=7)\n",
    "        \n",
    "        train = df[train_start : train_end]\n",
    "        validation = df[validation_start : validation_end]\n",
    "        test = df[test_start : test_end]\n",
    "\n",
    "        # Perform grid search\n",
    "        (order,nparts,partitioner) = evaluate_hofts_models(\"nested_eval_hofts_oahu\", train[target_station], validation[target_station], partitioners_list, eval_order_list, partitions_list)\n",
    "\n",
    "        # Concat train & validation for test\n",
    "        train = train.append(validation)\n",
    "\n",
    "        # Perform forecast\n",
    "        yhat = hofts_forecast(train[target_station], test[target_station], order, partitioner, nparts)\n",
    "        \n",
    "        order_list.append(order)\n",
    "        forecasts.append(yhat)\n",
    "\n",
    "    return forecasts, order_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_clean, order_list_clean = rolling_cv_hofts(norm_df_ssa_clean, 1)\n",
    "forecasts_residual, order_list_residual = rolling_cv_hofts(norm_df_ssa_residual, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_final, order_list = get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_rolling_error(\"rolling_cv_wind_ssa_hofts\", df, forecasts_final, order_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Variance FTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyFTS.models.nonstationary import cvfts\n",
    "from pyFTS.models.nonstationary import partitioners as nspartitioners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cvfts_models(test_name, train, validation, partitions_list):\n",
    "    \n",
    "    cvfts_results = pd.DataFrame(columns=['Partitions','RMSE'])\n",
    "    best_score, best_cfg, best_model = float(\"inf\"), None, None\n",
    "\n",
    "    for npartitions in partitions_list:\n",
    "                \n",
    "        fuzzy_sets =  nspartitioners.PolynomialNonStationaryPartitioner(data=train.values, part=Grid.GridPartitioner(data=train.values, npart=npartitions), degree=2)\n",
    "                \n",
    "        model_cvfts = cvfts.ConditionalVarianceFTS()\n",
    "        model_cvfts.fit(train.values, parameters=1, partitioner=fuzzy_sets, num_batches=1000)\n",
    "                                \n",
    "        forecast = model_cvfts.predict(validation.values)\n",
    "        rmse = Measures.rmse(validation.iloc[1:], forecast[:-1])\n",
    "\n",
    "        if rmse < best_score:\n",
    "            best_score, best_cfg = rmse, npartitions\n",
    "            best_model = model_cvfts\n",
    "\n",
    "        res = {'Partitions':npartitions, 'RMSE' : rmse}\n",
    "        print('CVFTS %s -  RMSE=%.3f' % (npartitions, rmse))\n",
    "        cvfts_results = cvfts_results.append(res, ignore_index=True)\n",
    "        cvfts_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best CVFTS(%s) RMSE=%.3f' % (best_cfg, best_score))\n",
    "    \n",
    "    return best_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvfts_forecast(train, test, _partitions):\n",
    "    \n",
    "    fuzzy_sets =  nspartitioners.PolynomialNonStationaryPartitioner(data=train.values, part=Grid.GridPartitioner(data=train.values, npart=_partitions), degree=2)\n",
    "                    \n",
    "    model_cvfts = cvfts.ConditionalVarianceFTS()\n",
    "    model_cvfts.fit(train.values, parameters=1, partitioner=fuzzy_sets, num_batches=1000)\n",
    "\n",
    "    forecast = model_cvfts.predict(test.values)\n",
    "\n",
    "    return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv_cvfts(df, step):\n",
    "    \n",
    "    partitions_list = np.arange(70,90,10)\n",
    "    \n",
    "    lags_list = []\n",
    "    forecasts = []\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    while test_end < limit :\n",
    "        print(\"Index: \", index.strftime('%Y-%m-%d'))  \n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        index = index + datetime.timedelta(days=7)\n",
    "        \n",
    "        train = df[train_start : train_end]\n",
    "        validation = df[validation_start : validation_end]\n",
    "        test = df[test_start : test_end]\n",
    "\n",
    "        # Perform grid search\n",
    "        nparts = evaluate_cvfts_models(\"nested_eval_cvfts_oahu\", train[target_station], validation[target_station], partitions_list)\n",
    "\n",
    "        # Concat train & validation for test\n",
    "        train = train.append(validation)\n",
    "\n",
    "        # Perform forecast\n",
    "        yhat = cvfts_forecast(train[target_station], test[target_station],nparts)\n",
    "        \n",
    "        lags_list.append(1)\n",
    "        forecasts.append(yhat)\n",
    "\n",
    "    return forecasts, lags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_clean, order_list_clean = rolling_cv_cvfts(norm_df_ssa_clean, 1)\n",
    "forecasts_residual, order_list_residual = rolling_cv_cvfts(norm_df_ssa_residual, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_final, order_list = get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvfts_order_list = [1] * len(order_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_rolling_error(\"rolling_cv_wind_ssa_cvfts\", df, forecasts_final, cvfts_order_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustered Multivariate FTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/cseveriano/spatio-temporal-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import KMeansPartitioner\n",
    "from models import sthofts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmvfts_forecast(train_df, test_df, target, _order, npartitions):\n",
    "    \n",
    "    print(\"KMean Partition at:\", datetime.datetime.now())\n",
    "\n",
    "    _partitioner = KMeansPartitioner.KMeansPartitioner(data=train_df.values, npart=npartitions, batch_size=1000, init_size=npartitions*3)\n",
    "\n",
    "    model_sthofts = sthofts.SpatioTemporalHighOrderFTS()\n",
    "    \n",
    "    print(\"CMVFTS fit at:\", datetime.datetime.now())\n",
    "    model_sthofts.fit(train_df.values, order=_order, partitioner=_partitioner)\n",
    "    \n",
    "    print(\"CMVFTS prediction at:\", datetime.datetime.now())\n",
    "    forecast = model_sthofts.predict(test_df.values)\n",
    "    forecast_df = pd.DataFrame(data=forecast, columns=test_df.columns)\n",
    "    return forecast_df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cmvfts_models(test_name, train, validation, order_list, partitions_list):\n",
    "    \n",
    "    cmvfts_results = pd.DataFrame(columns=['Partitions','Order','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "    for _order in order_list:\n",
    "        for npartitions in partitions_list:\n",
    "            \n",
    "            forecast = cmvfts_forecast(train, validation, target_station, _order, npartitions)\n",
    "            rmse = Measures.rmse(validation[target_station].iloc[_order:], forecast[:-1])\n",
    "\n",
    "            if rmse < best_score:\n",
    "                best_score, best_cfg = rmse, (_order,npartitions)\n",
    "\n",
    "            res = {'Partitions':npartitions, 'Order' : str(_order) ,'RMSE' : rmse}\n",
    "            print('CMVFTS %s - %s  RMSE=%.3f' % (npartitions, str(_order),rmse))\n",
    "            cmvfts_results = cmvfts_results.append(res, ignore_index=True)\n",
    "            cmvfts_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best CMVFTS(%s) RMSE=%.3f' % (best_cfg, best_score))\n",
    "    \n",
    "    return best_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv_cmvfts(df, step):\n",
    "    \n",
    "    #eval_order_list = np.arange(1,3)\n",
    "    eval_order_list = [2]\n",
    "#    partitions_list = np.arange(80,110,10)\n",
    "    partitions_list = [20,30]\n",
    "    \n",
    "    forecasts = []\n",
    "    order_list = []\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    while test_end < limit :\n",
    "        print(\"Index: \", index.strftime('%Y-%m-%d'))  \n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        index = index + datetime.timedelta(days=7)\n",
    "        \n",
    "        train = df[train_start : train_end]\n",
    "        validation = df[validation_start : validation_end]\n",
    "        test = df[test_start : test_end]\n",
    "\n",
    "        # Perform grid search\n",
    "        (order,nparts) = evaluate_cmvfts_models(\"nested_eval_cmvfts_oahu\", train[neighbor_stations_90], validation[neighbor_stations_90], eval_order_list, partitions_list)\n",
    "\n",
    "        # Concat train & validation for test\n",
    "        train = train.append(validation)\n",
    "\n",
    "        # Perform forecast\n",
    "        yhat = cmvfts_forecast(train[neighbor_stations_90], test[neighbor_stations_90],target_station, order, nparts)\n",
    "        \n",
    "        order_list.append(order)\n",
    "        forecasts.append(yhat)\n",
    "\n",
    "    return forecasts, order_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_clean, order_list_clean = rolling_cv_cmvfts(norm_df_ssa_clean, 1)\n",
    "forecasts_residual, order_list_residual = rolling_cv_cmvfts(norm_df_ssa_residual, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_final, order_list = get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_rolling_error(\"rolling_cv_wind_ssa_cmvfts\", df, forecasts_final, order_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_multi_forecast(train_df, test_df, _order, _steps, _neurons, _epochs):\n",
    "\n",
    "    \n",
    "    nfeat = len(train_df.columns)\n",
    "    nlags = _order\n",
    "    nsteps = _steps\n",
    "    nobs = nlags * nfeat\n",
    "    \n",
    "    train_reshaped_df = series_to_supervised(train_df, n_in=nlags, n_out=nsteps)\n",
    "    train_X, train_Y = train_reshaped_df.iloc[:,:nobs].values, train_reshaped_df.iloc[:,-nfeat].values\n",
    "    train_X = train_X.reshape((train_X.shape[0], nlags, nfeat))\n",
    "\n",
    "    test_reshaped_df = series_to_supervised(test_df, n_in=nlags, n_out=nsteps)\n",
    "    test_X, test_Y = test_reshaped_df.iloc[:,:nobs].values, test_reshaped_df.iloc[:,-nfeat].values\n",
    "    test_X = test_X.reshape((test_X.shape[0], nlags, nfeat))\n",
    "    \n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(_neurons, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "    # fit network\n",
    "    model.fit(train_X, train_Y, epochs=_epochs, batch_size=1000, verbose=False, shuffle=False)\n",
    "    \n",
    "    forecast = model.predict(test_X)\n",
    "    fcst = [f[0] for f in forecast]\n",
    "    \n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multivariate_lstm_models(test_name, train_df, validation_df, neurons_list, order_list, epochs_list):\n",
    "    \n",
    "    lstm_results = pd.DataFrame(columns=['Neurons','Order','Epochs','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    \n",
    "    nfeat = len(train_df.columns)\n",
    "    nsteps = 1\n",
    "    \n",
    "    for _neurons in neurons_list:\n",
    "        for _order in order_list:\n",
    "            for epochs in epochs_list:\n",
    "                    \n",
    "                    nobs = nfeat * _order\n",
    "                    \n",
    "                    train_reshaped_df = series_to_supervised(train_df, n_in=_order, n_out=nsteps)\n",
    "                    train_X, train_Y = train_reshaped_df.iloc[:,:nobs].values, train_reshaped_df.iloc[:,-nfeat].values\n",
    "                    train_X = train_X.reshape((train_X.shape[0], _order, nfeat))                    \n",
    "                    \n",
    "                    val_reshaped_df = series_to_supervised(validation_df, n_in=_order, n_out=nsteps)\n",
    "                    validation_X, validation_Y = val_reshaped_df.iloc[:,:nobs].values, val_reshaped_df.iloc[:,-nfeat].values\n",
    "                    validation_X = validation_X.reshape((validation_X.shape[0], _order, nfeat))\n",
    "                    \n",
    "                    # design network\n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(_neurons, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "                    model.add(Dense(1))\n",
    "                    model.compile(loss='mae', optimizer='adam')\n",
    "                    \n",
    "                    # fit network\n",
    "                    history = model.fit(train_X, train_Y, epochs=epochs, batch_size=1000, verbose=False, shuffle=False)\n",
    "                    forecast = model.predict(validation_X)\n",
    "                    fcst = [f[0] for f in forecast]\n",
    "                    \n",
    "                    \n",
    "                    rmse = Measures.rmse(validation_Y, fcst)\n",
    "                    \n",
    "                    params = (_neurons, _order,epochs)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, params\n",
    "\n",
    "                    res = {'Neurons':_neurons, 'Order':_order, 'Epochs' : epochs ,'RMSE' : rmse}\n",
    "                    print('LSTM %s  RMSE=%.3f' % (params,rmse))\n",
    "                    lstm_results = lstm_results.append(res, ignore_index=True)\n",
    "                    lstm_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best LSTM(%s) RMSE=%.3f' % (best_cfg, best_score))\n",
    "    return best_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv_lstm_multi(df, step):\n",
    "    \n",
    "    neurons_list = [50]\n",
    "    order_list = [2,4]\n",
    "    epochs_list = [500]\n",
    "\n",
    "    lags_list = []\n",
    "    forecasts = []\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    while test_end < limit :\n",
    "        print(\"Index: \", index.strftime('%Y-%m-%d'))  \n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        index = index + datetime.timedelta(days=7)\n",
    "        \n",
    "        train = df[train_start : train_end]\n",
    "        validation = df[validation_start : validation_end]\n",
    "        test = df[test_start : test_end]\n",
    "\n",
    "        # Perform grid search\n",
    "        (_neurons, _order,epochs) = evaluate_multivariate_lstm_models(\"nested_eval_lstm_multi_oahu\", train[neighbor_stations_90], validation[neighbor_stations_90], neurons_list, order_list, epochs_list)\n",
    "\n",
    "        # Concat train & validation for test\n",
    "        train = train.append(validation)\n",
    "\n",
    "        # Perform forecast\n",
    "        yhat = lstm_multi_forecast(train[neighbor_stations_90], test[neighbor_stations_90], _order, 1, _neurons,epochs)\n",
    "        yhat.append(0) #para manter o formato do vetor de metricas\n",
    "        \n",
    "        lags_list.append(_order)\n",
    "        forecasts.append(yhat)\n",
    "\n",
    "    return forecasts, lags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_clean, order_list_clean = rolling_cv_lstm_multi(norm_df_ssa_clean, 1)\n",
    "forecasts_residual, order_list_residual = rolling_cv_lstm_multi(norm_df_ssa_residual, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_final, order_list = get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_rolling_error(\"rolling_cv_wind_ssa_lstm_multi\", df, forecasts_final, order_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv_lstm_uni(df, step):\n",
    "    \n",
    "    neurons_list = [50]\n",
    "    order_list = [2,4]\n",
    "    epochs_list = [500]\n",
    "\n",
    "    lags_list = []\n",
    "    forecasts = []\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    while test_end < limit :\n",
    "        print(\"Index: \", index.strftime('%Y-%m-%d'))  \n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        index = index + datetime.timedelta(days=7)\n",
    "        \n",
    "        train = df[train_start : train_end]\n",
    "        validation = df[validation_start : validation_end]\n",
    "        test = df[test_start : test_end]\n",
    "\n",
    "        # Perform grid search\n",
    "        (_neurons, _order,epochs) = evaluate_multivariate_lstm_models(\"nested_eval_lstm_multi_oahu\", train[[target_station]], validation[[target_station]], neurons_list, order_list, epochs_list)\n",
    "\n",
    "        # Concat train & validation for test\n",
    "        train = train.append(validation)\n",
    "\n",
    "        # Perform forecast\n",
    "        yhat = lstm_multi_forecast(train[[target_station]], test[[target_station]], _order, 1, _neurons,epochs)\n",
    "        \n",
    "        yhat.append(0) #para manter o formato do vetor de metricas\n",
    "        \n",
    "        lags_list.append(_order)\n",
    "        forecasts.append(yhat)\n",
    "\n",
    "    return forecasts, lags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_clean, order_list_clean = rolling_cv_lstm_uni(norm_df_ssa_clean, 1)\n",
    "forecasts_residual, order_list_residual = rolling_cv_lstm_uni(norm_df_ssa_residual, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_final, order_list = get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_rolling_error(\"rolling_cv_wind_ssa_lstm_uni\", df, forecasts_final, order_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_multi_forecast(train_df, test_df, _order, _steps, _neurons, _epochs):\n",
    "\n",
    "    \n",
    "    nfeat = len(train_df.columns)\n",
    "    nlags = _order\n",
    "    nsteps = _steps\n",
    "    nobs = nlags * nfeat\n",
    "    \n",
    "    train_reshaped_df = series_to_supervised(train_df, n_in=nlags, n_out=nsteps)\n",
    "    train_X, train_Y = train_reshaped_df.iloc[:,:nobs].values, train_reshaped_df.iloc[:,-nfeat].values\n",
    "    \n",
    "    test_reshaped_df = series_to_supervised(test_df, n_in=nlags, n_out=nsteps)\n",
    "    test_X, test_Y = test_reshaped_df.iloc[:,:nobs].values, test_reshaped_df.iloc[:,-nfeat].values\n",
    "    \n",
    "    # design network\n",
    "    model = designMLPNetwork(_neurons,train_X.shape[1])\n",
    "    \n",
    "    # fit network\n",
    "    model.fit(train_X, train_Y, epochs=_epochs, batch_size=1000, verbose=False, shuffle=False)\n",
    "    \n",
    "    forecast = model.predict(test_X)\n",
    "    \n",
    "    fcst = [f[0] for f in forecast]\n",
    "\n",
    "    return fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_multivariate_mlp_models(test_name, train_df, validation_df, neurons_list, order_list, epochs_list):\n",
    "    \n",
    "    lstm_results = pd.DataFrame(columns=['Neurons','Order','Epochs','RMSE'])\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    \n",
    "    nfeat = len(train_df.columns)\n",
    "    nsteps = 1\n",
    "    \n",
    "    for _neurons in neurons_list:\n",
    "        for _order in order_list:\n",
    "            for epochs in epochs_list:\n",
    "                    \n",
    "                    nobs = nfeat * _order\n",
    "                    \n",
    "                    train_reshaped_df = series_to_supervised(train_df, n_in=_order, n_out=nsteps)\n",
    "                    train_X, train_Y = train_reshaped_df.iloc[:,:nobs].values, train_reshaped_df.iloc[:,-nfeat].values\n",
    "                    \n",
    "                    val_reshaped_df = series_to_supervised(validation_df, n_in=_order, n_out=nsteps)\n",
    "                    validation_X, validation_Y = val_reshaped_df.iloc[:,:nobs].values, val_reshaped_df.iloc[:,-nfeat].values\n",
    "                   \n",
    "                    model = designMLPNetwork(_neurons,train_X.shape[1])\n",
    "                                        \n",
    "                    # fit network\n",
    "                    history = model.fit(train_X, train_Y, epochs=epochs, batch_size=1000, verbose=False, shuffle=False)\n",
    "                    forecast = model.predict(validation_X)\n",
    "                    fcst = [f[0] for f in forecast]\n",
    "                    \n",
    "                    \n",
    "                    rmse = Measures.rmse(validation_Y, fcst)\n",
    "                    #rmse = math.sqrt(mean_squared_error(validation_Y, forecast))\n",
    "                    \n",
    "                    params = (_neurons, _order,epochs)\n",
    "                    if rmse < best_score:\n",
    "                        best_score, best_cfg = rmse, params\n",
    "\n",
    "                    res = {'Neurons':_neurons, 'Order':_order, 'Epochs' : epochs ,'RMSE' : rmse}\n",
    "                    print('LSTM %s  RMSE=%.3f' % (params,rmse))\n",
    "                    lstm_results = lstm_results.append(res, ignore_index=True)\n",
    "                    lstm_results.to_csv(test_name+\".csv\")\n",
    "\n",
    "    print('Best MLP(%s) RMSE=%.3f' % (best_cfg, best_score))\n",
    "    return best_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def designMLPNetwork(neurons, shape):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_dim=shape))\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(neurons, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv_mlp_multi(df, step):\n",
    "    \n",
    "#    neurons_list = np.arange(50,110,50)\n",
    "#    order_list = np.arange(2,4)\n",
    "#    epochs_list = [100]\n",
    "\n",
    "    neurons_list = [50]\n",
    "    order_list = [2,4]\n",
    "    epochs_list = [500]\n",
    "\n",
    "    lags_list = []\n",
    "    forecasts = []\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    while test_end < limit :\n",
    "        print(\"Index: \", index.strftime('%Y-%m-%d'))  \n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        index = index + datetime.timedelta(days=7)\n",
    "        \n",
    "        train = df[train_start : train_end]\n",
    "        validation = df[validation_start : validation_end]\n",
    "        test = df[test_start : test_end]\n",
    "\n",
    "        # Perform grid search\n",
    "        (_neurons, _order,epochs) = evaluate_multivariate_mlp_models(\"nested_eval_mlp_multi_oahu\", train[neighbor_stations_90], validation[neighbor_stations_90], neurons_list, order_list, epochs_list)\n",
    "\n",
    "        # Concat train & validation for test\n",
    "        train = train.append(validation)\n",
    "\n",
    "        # Perform forecast\n",
    "        yhat = mlp_multi_forecast(train[neighbor_stations_90], test[neighbor_stations_90], _order, 1, _neurons,epochs)\n",
    "        \n",
    "        yhat.append(0) #para manter o formato do vetor de metricas\n",
    "        \n",
    "        lags_list.append(_order)\n",
    "        forecasts.append(yhat)\n",
    "\n",
    "    return forecasts, lags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_clean, order_list_clean = rolling_cv_mlp_multi(norm_df_ssa_clean, 1)\n",
    "forecasts_residual, order_list_residual = rolling_cv_mlp_multi(norm_df_ssa_residual, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_final, order_list = get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual)\n",
    "calculate_rolling_error(\"rolling_cv_wind_ssa_mlp_multi\", df, forecasts_final, order_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_cv_mlp_uni(df, step):\n",
    "    \n",
    "    neurons_list = [50]\n",
    "    order_list = [2,4]\n",
    "    epochs_list = [500]\n",
    "\n",
    "    lags_list = []\n",
    "    forecasts = []\n",
    "\n",
    "    limit = df.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    test_end = \"\"\n",
    "    index = df.index[0]\n",
    "\n",
    "    while test_end < limit :\n",
    "        print(\"Index: \", index.strftime('%Y-%m-%d'))  \n",
    "\n",
    "        train_start, train_end, validation_start, validation_end, test_start, test_end = getRollingWindow(index)\n",
    "        index = index + datetime.timedelta(days=7)\n",
    "        \n",
    "        train = df[train_start : train_end]\n",
    "        validation = df[validation_start : validation_end]\n",
    "        test = df[test_start : test_end]\n",
    "\n",
    "        # Perform grid search\n",
    "        (_neurons, _order,epochs) = evaluate_multivariate_mlp_models(\"nested_eval_mlp_uni_oahu\", train[[target_station]], validation[[target_station]], neurons_list, order_list, epochs_list)\n",
    "\n",
    "        # Concat train & validation for test\n",
    "        train = train.append(validation)\n",
    "\n",
    "        # Perform forecast\n",
    "        yhat = mlp_multi_forecast(train[[target_station]], test[[target_station]], _order, 1, _neurons,epochs)\n",
    "        \n",
    "        yhat.append(0) #para manter o formato do vetor de metricas\n",
    "        \n",
    "        lags_list.append(_order)\n",
    "        forecasts.append(yhat)\n",
    "\n",
    "    return forecasts, lags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_clean, order_list_clean = rolling_cv_mlp_uni(norm_df_ssa_clean, 1)\n",
    "forecasts_residual, order_list_residual = rolling_cv_mlp_uni(norm_df_ssa_residual, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_final, order_list = get_final_forecast(forecasts_clean, forecasts_residual, order_list_clean, order_list_residual)\n",
    "calculate_rolling_error(\"rolling_cv_wind_ssa_mlp_uni\", df, forecasts_final, order_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
