{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import required libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bulidng a class to convert time series to images\n",
    "\n",
    "class MakeImage:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self._df = None \n",
    "        self._size_width = None \n",
    "        self._index_of_columns_2_be_batched = None \n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        \n",
    "        return self._df\n",
    "    \n",
    "    @property\n",
    "    def size_width(self):\n",
    "        return self._size_width\t\n",
    "\n",
    "    @property\n",
    "    def index_of_columns_2_be_batched(self):\n",
    "        return self._index_of_columns_2_be_batched\n",
    "\n",
    "    @df.setter\n",
    "    def df(self, value):\n",
    "        self._df = value\n",
    "\n",
    "    @size_width.setter\n",
    "    def size_width(self, value):\n",
    "        self._size_width = value \n",
    "\n",
    "    @index_of_columns_2_be_batched.setter\n",
    "    def index_of_columns_2_be_batched(self, value):\n",
    "        self._index_of_columns_2_be_batched = value\n",
    "\n",
    "    def add_label(self):\n",
    "        df = self.df\n",
    "        df.ix[0,'label'] = 0.0\n",
    "        df.ix[1:,'label'] = [1.0 if df.ix[i,'load_data'] > df.ix[i-1,'load_data'] else 0.0  for i in range(1,len(df.index))]\n",
    "\n",
    "    def chunk_features_and_label(self, col_name, col_label):\n",
    "        df = self.df\n",
    "        image_width = self.size_width\n",
    "        nparray_features = np.zeros(shape = (len(df.index) - image_width, image_width))\n",
    "        nparray_label = np.zeros(shape = (len(df.index) - image_width, 1))\n",
    "                \n",
    "        for i in range(len(df.index) - image_width):\n",
    "            nparray_features[i, :]  = df.ix[i: i + image_width - 1, col_name].as_matrix().reshape(image_width)\n",
    "            nparray_label[i, :] = df.ix[i + image_width, col_label].reshape(-1,1)\n",
    "        return  nparray_features, nparray_label\n",
    "\n",
    "    def features_2_images(self, x):\n",
    "        size_width = self.size_width\n",
    "        x_image = np.zeros(shape = (x.shape[0], x.shape[1]*x.shape[1]))\n",
    "\n",
    "        print(x.shape[0])\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            x_temp = x[i, :].copy()\n",
    "            x_copy = np.copy(x[i,:])\n",
    "            x_int = np.zeros(shape = (x_copy.shape), dtype = int)\n",
    "            \n",
    "            x_copy2 = np.copy(x[i,:])\n",
    "            x_copy.sort()\n",
    "\n",
    "            for j in range(np.size(x_copy)):\n",
    "                for k in range(np.size(x_copy)):\n",
    "                    if x_copy2[j] == x_copy[k]:\n",
    "                        x[i, j] = int(k) \n",
    "            \n",
    "            n_values = np.max(x[i,:].astype(int)) + 1\n",
    "            squared = np.eye(n_values)[x[i,:].astype(int)]\n",
    "            flatten = squared.flatten()\n",
    "            x_image[i, :] = flatten\n",
    "        return x_image\n",
    "\n",
    "    def convert_2_onehot_encoding(self, vector_of_one_dim):\n",
    "\n",
    "        nparray_lab_onehot = np.zeros(shape = (vector_of_one_dim.shape[0], 2))\n",
    "        \n",
    "        for i in range(vector_of_one_dim.shape[0]):\n",
    "            n_values = 2\n",
    "\n",
    "            nparray_lab_onehot[i, :] = np.eye(n_values)[vector_of_one_dim[i,:].astype(int)]\n",
    "        \n",
    "        return nparray_lab_onehot\n",
    "\n",
    "    def number_of_batches(self, x, batch_size):\n",
    "        return   int(x.shape[0]/batch_size)\n",
    "\n",
    "    def next_batch(self, x, y, batch_size):\n",
    "        index_for_batch = self.index_of_columns_2_be_batched\n",
    "\n",
    "        if len(index_for_batch) >= batch_size:\n",
    "            selected_index = random.sample(index_for_batch, batch_size)\n",
    "\n",
    "        else:\n",
    "            selected_index = random.sample(index_for_batch, len(index_for_batch))\n",
    " \n",
    "        x_batch = [x[i] for i in selected_index]\n",
    "        y_batch = [y[i] for i in selected_index]\n",
    "\n",
    "        self.index_of_columns_2_be_batched = [i for i in index_for_batch if i not in selected_index]\n",
    "        return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "\n",
    "# building computation graph\n",
    "\n",
    "    x = tf.placeholder(tf.float32, [None, 1024])   # 32*32\n",
    "    y = tf.placeholder(tf.float32, [None, 2])\n",
    "    input_layer_of_load_images = tf.reshape(x, [-1, 32, 32, 1])\n",
    "\n",
    "    convolute_layer_1 = tf.layers.conv2d(\n",
    "    inputs = input_layer_of_load_images,\n",
    "    filters = 32,\n",
    "    kernel_size = [5, 5],\n",
    "    padding = \"same\",\n",
    "    activation = tf.nn.relu)\n",
    "\n",
    "    pool_layer_1 = tf.layers.max_pooling2d(\n",
    "    inputs=convolute_layer_1,\n",
    "    pool_size=[2, 2],\n",
    "    strides=2)\n",
    "\n",
    "    convolute_layer_2 = tf.layers.conv2d(\n",
    "    inputs=pool_layer_1,\n",
    "    filters=64,\n",
    "    kernel_size=[5, 5],\n",
    "    padding=\"same\",\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "    pool_layer_2 = tf.layers.max_pooling2d(inputs = convolute_layer_2 , \n",
    "    pool_size=[2, 2], \n",
    "    strides=2)\n",
    "\n",
    "    pool_layer_2_flat = tf.reshape(pool_layer_2,\n",
    "    [-1, 8 * 8 * 64])\n",
    "\n",
    "    dense_layer_1 = tf.layers.dense(inputs = pool_layer_2_flat,\n",
    "    units=1024,\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "    dense_layer_2 = tf.layers.dense(inputs = dense_layer_1,\n",
    "    units = 600,\n",
    "    activation=tf.nn.relu)\n",
    "\n",
    "    dropout = tf.layers.dropout(\n",
    "    inputs = dense_layer_2, rate = 0.4)\n",
    "\n",
    "    dense_layer_3 = tf.layers.dense(inputs = dropout,\n",
    "    units=400)\n",
    "\n",
    "    prediction = tf.layers.dense(dense_layer_3, activation=tf.nn.softmax, units = 2)\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(prediction), reduction_indices=[1]))  \n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "    number_of_epochs = 15\n",
    "\n",
    "# creating  session for running computation graph\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(number_of_epochs):\n",
    "            epoch_loss = 0\n",
    "            makeImage.index_of_columns_2_be_batched = [i for i in range(0, X_train.shape[0])]\n",
    "\n",
    "            for _ in range(number_of_batches):\n",
    "                epoch_x, epoch_y = makeImage.next_batch(X_train, y_train, batch_size)\n",
    "                _, c = sess.run([train_step, cross_entropy], feed_dict={x: epoch_x, y: epoch_y})\n",
    "\n",
    "                epoch_loss += c\n",
    "            print('Epoch', epoch + 1, 'completed out of', number_of_epochs,' with loss:',epoch_loss)\n",
    "\n",
    "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "\n",
    "            print('Accuracy in epoch', epoch + 1, 'is:',accuracy.eval({x:X_test, y:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Oahu Data\n",
    "df = pd.read_pickle(\"df_oahu.pkl\")\n",
    "\n",
    "#Set target and input variables \n",
    "target_station = 'DHHL_3'\n",
    "\n",
    "## Remove columns with many corrupted or missing values\n",
    "df.drop(columns=['AP_1', 'AP_7'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "interval = ((df.index >= '2010-06') & (df.index < '2011-06'))\n",
    "#interval = ((df.index >= '2010-11') & (df.index <= '2010-12'))\n",
    "\n",
    "(train_df, validation_df, test_df) = split_data(df, interval)\n",
    "(norm_train_df, norm_validation_df, norm_test_df) = split_data(norm_df, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = ((df.index >= '2010-06') & (df.index < '2011-06'))\n",
    "\n",
    "cnn_df = pd.DataFrame({\"load_data\": df[target_station].iloc[interval].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cseveriano/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# create a class and initlize an instance of it\n",
    "makeImage = MakeImage()\n",
    "# Setter instance variables\n",
    "makeImage.df = cnn_df\n",
    "makeImage.size_width = 32\n",
    "makeImage.add_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process load data to be proper for the model\n",
    "X_not_ready_yet, Y_not_ready_yet = makeImage.chunk_features_and_label('load_data', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22233\n"
     ]
    }
   ],
   "source": [
    "X_ready = makeImage.features_2_images(X_not_ready_yet)\n",
    "Y_ready = makeImage.convert_2_onehot_encoding(Y_not_ready_yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 70% of data for training the model and 30% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ready, Y_ready, test_size = 0.3)\n",
    "\n",
    "# the batch size is selected to be 100, it is possible to adjust it based on problem requirment\n",
    "batch_size = 100\n",
    "number_of_batches = makeImage.number_of_batches(X_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed out of 15  with loss: 89.1873759329\n",
      "Accuracy in epoch 1 is: 0.726237\n",
      "Epoch 2 completed out of 15  with loss: 81.4176984727\n",
      "Accuracy in epoch 2 is: 0.725337\n",
      "Epoch 3 completed out of 15  with loss: 77.3923944831\n",
      "Accuracy in epoch 3 is: 0.726237\n",
      "Epoch 4 completed out of 15  with loss: 74.5954051316\n",
      "Accuracy in epoch 4 is: 0.727436\n",
      "Epoch 5 completed out of 15  with loss: 70.1307245195\n",
      "Accuracy in epoch 5 is: 0.724738\n",
      "Epoch 6 completed out of 15  with loss: 64.573341459\n",
      "Accuracy in epoch 6 is: 0.725487\n",
      "Epoch 7 completed out of 15  with loss: 55.7144174725\n",
      "Accuracy in epoch 7 is: 0.704048\n",
      "Epoch 8 completed out of 15  with loss: 45.6330631524\n",
      "Accuracy in epoch 8 is: 0.698051\n",
      "Epoch 9 completed out of 15  with loss: 34.9945664108\n",
      "Accuracy in epoch 9 is: 0.682759\n",
      "Epoch 10 completed out of 15  with loss: 24.2743060961\n",
      "Accuracy in epoch 10 is: 0.684708\n",
      "Epoch 11 completed out of 15  with loss: 17.0319530889\n",
      "Accuracy in epoch 11 is: 0.695652\n",
      "Epoch 12 completed out of 15  with loss: 11.6183588663\n",
      "Accuracy in epoch 12 is: 0.695652\n",
      "Epoch 13 completed out of 15  with loss: 8.14807596523\n",
      "Accuracy in epoch 13 is: 0.692054\n",
      "Epoch 14 completed out of 15  with loss: 5.95159941586\n",
      "Accuracy in epoch 14 is: 0.692354\n",
      "Epoch 15 completed out of 15  with loss: nan\n",
      "Accuracy in epoch 15 is: 0.503298\n"
     ]
    }
   ],
   "source": [
    "cnn_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
